{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95cc4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymupdf # imports the pymupdf library\n",
    "import pandas as pd \n",
    "import fitz  # import PyMuPDF\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ce03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "###The Next Section is totally Decicated on Parsing of PDF to extract the text,images,tables.####\n",
    "###After the PDF is parsed it is transformed to Dictionary Object for the storage of the parsed content.####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f322a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(item, title=\"\"):\n",
    "    \"\"\"Display a pixmap.\n",
    "\n",
    "    Just to display Pixmap image of \"item\" - ignore the man behind the curtain.\n",
    "\n",
    "    Args:\n",
    "        item: any PyMuPDF object having a \"get_pixmap\" method.\n",
    "        title: a string to be used as image title\n",
    "\n",
    "    Generates an RGB Pixmap from item using a constant DPI and using matplotlib\n",
    "    to show it inline of the notebook.\n",
    "    \"\"\"\n",
    "    DPI = 300  # use this resolution\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # %matplotlib inline\n",
    "    pix = item.get_pixmap(dpi=DPI)\n",
    "    img = np.ndarray([pix.h, pix.w, 3], dtype=np.uint8, buffer=pix.samples_mv)\n",
    "    plt.figure(dpi=DPI)  # set the figure's DPI\n",
    "    plt.title(title)  # set title of image\n",
    "    _ = plt.imshow(img, extent=(0, pix.w * 72 / DPI, pix.h * 72 / DPI, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "318fefda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images_per_page(doc,doc_name,page,page_index,DPI):\n",
    "    image_list = page.get_images()\n",
    "    # print the number of images found on the page\n",
    "    if image_list:\n",
    "        print(f\"Found {len(image_list)} images on page {page_index}\")\n",
    "    else:\n",
    "        print(\"No images found on page\", page_index)\n",
    "\n",
    "    for image_index, img in enumerate(image_list, start=1): # enumerate the image list\n",
    "        xref = img[0] # get the XREF of the image\n",
    "        pix = pymupdf.Pixmap(doc, xref) # create a Pixmap\n",
    "        #pix = pymupdf.Pixmap(doc.extract_image(xref)[\"image\"])\n",
    "        #mask = pymupdf.Pixmap(doc.extract_image(smask)[\"image\"])\n",
    "        #pix = pymupdf.Pixmap(pix1, mask)\n",
    "\n",
    "        ### Commented Out Section for showing images################################\n",
    "        #if pix.n - pix.alpha > 3: # CMYK: convert to RGB first\n",
    "        #    pix = pymupdf.Pixmap(pymupdf.csRGB, pix)            \n",
    "        # %matplotlib inline\n",
    "        #pix = item.get_pixmap(dpi=DPI)\n",
    "        #img = np.ndarray([pix.h, pix.w, 3], dtype=np.uint8, buffer=pix.samples_mv)\n",
    "        #plt.figure(dpi=DPI)  # set the figure's DPI\n",
    "        #plt.title(title)  # set title of image\n",
    "        #_ = plt.imshow(img, extent=(0, pix.w * 72 / DPI, pix.h * 72 / DPI, 0))\n",
    "        \n",
    "        #############################################################################\n",
    "            \n",
    "        print('Image:')\n",
    "        print(type(img))\n",
    "            \n",
    "        pix.save(\"./parsed_pdf_output/\"+doc_name+\"/\"+\"page_\"+str(page_index+1)+\"/image_%s.jpg\" % (image_index)) # save the image as png\n",
    "        pix = None\n",
    "        \n",
    "    return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d321ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_images_per_page(doc,doc_name,page_index,download):\n",
    "    print(\"IN extract_images_per_page\")\n",
    "    page_image_dict={}\n",
    "    page_number=page_index+1\n",
    "    page = doc[page_index] # get the page by index\n",
    "    \n",
    "    ####Get Images along with the metadata of it in the following order:\n",
    "    #(xref, smask, width, height, bpc, colorspace, alt. colorspace, name, filter, referencer)\n",
    "    #xref (int) is the image object number\n",
    "    #smask (int) is the object number of its soft-mask image\n",
    "    #width and height (ints) are the image dimensions\n",
    "    #bpc (int) denotes the number of bits per component (normally 8)\n",
    "    #colorspace (str) a string naming the colorspace (like DeviceRGB)\n",
    "    #alt. colorspace (str) is any alternate colorspace depending on the value of colorspace\n",
    "    #name (str) is the symbolic name by which the image is referenced\n",
    "    #filter (str) is the decode filter of the image (Adobe PDF References, pp. 22).\n",
    "    #referencer (int) the xref of the referencer. Zero if directly referenced by the page. Only present if full=True.\n",
    "    \n",
    "    image_list = page.get_images(full=True) #full=True as it will give the if any other pages are referencing\n",
    "                                            #the image.\n",
    "    \n",
    "    #for image in image_list:\n",
    "    #    xref, smask, width, height, bpc, colorspace, alt_colorspace, name, filter, referencer=image\n",
    "    #    print(\"width\")\n",
    "    #    print(width)\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    img_cnt=len(image_list)\n",
    "    npy_img_lst=[]\n",
    "    DPI=150\n",
    "    title=\"\"\n",
    "    ###########Extraction Of Images in Numpy Format############\n",
    "    \n",
    "    for image_index, img in enumerate(image_list, start=1): # enumerate the image list\n",
    "        \n",
    "            img_meta_dict={}\n",
    "            \n",
    "            xref = img[0] # get the XREF of the image\n",
    "            \n",
    "            smask= img[1] # Get Object number of the Soft Mask of the Image\n",
    "            \n",
    "            width = img[2]\n",
    "            print(\"width\")\n",
    "            print(width)\n",
    "            \n",
    "            height = img[3]\n",
    "            print(\"height\")\n",
    "            print(height)\n",
    "            \n",
    "            num_bits = img[4] # Nuber of bits that is being used to represent the smallest component of the image\n",
    "            colorspace = img[5] #colorspace of the image\n",
    "            alt_colorspace = img[6] #colorspace of the image\n",
    "            sym_name = img[7] #Symbolic name of the image\n",
    "            img_filter = img[8] #decode filter of the image (Adobe PDF References, pp. 22)\n",
    "            img_ref = img[9] #xref of the referencer. Zero if directly referenced by the page. \n",
    "                             #Only present if full=True.\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            img_meta_dict[\"img_obj_num\"]=xref\n",
    "            img_meta_dict[\"smask_obj_num\"]=smask\n",
    "            img_meta_dict[\"width\"]=width\n",
    "            img_meta_dict[\"height\"]=height\n",
    "            img_meta_dict[\"num_bits\"]=num_bits\n",
    "            img_meta_dict[\"colorspace\"]=colorspace\n",
    "            img_meta_dict[\"alt_colorspace\"]=alt_colorspace\n",
    "            img_meta_dict[\"sym_name\"]=sym_name\n",
    "            img_meta_dict[\"filter\"]=img_filter\n",
    "            img_meta_dict[\"referencer\"]=img_ref\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            pix = pymupdf.Pixmap(doc, xref) # create a Pixmap\n",
    "            \n",
    "            #pix = pymupdf.Pixmap(doc.extract_image(xref)[\"image\"])\n",
    "            #mask = pymupdf.Pixmap(doc.extract_image(smask)[\"image\"])\n",
    "            #pix = pymupdf.Pixmap(pix1, mask)\n",
    "            \n",
    "            #pix.set_alpha(premultiply=False)\n",
    "            \n",
    "            ### Commented Out Section for showing images#############################\n",
    "\n",
    "            if pix.n - pix.alpha > 3: # CMYK: convert to RGB first\n",
    "                pix = pymupdf.Pixmap(pymupdf.csRGB, pix)\n",
    "            # %matplotlib inline\n",
    "            #pix = item.get_pixmap(dpi=DPI)\n",
    "            \n",
    "            print(\"PIX BUFFER SIZE\")\n",
    "            print(len(pix.samples_mv))\n",
    "            \n",
    "            \n",
    "            image_size=(pix.h*pix.w*3)\n",
    "            print('Original IMG_BUFFER_SIZE')\n",
    "            print(image_size)\n",
    "            \n",
    "            print('Page Image Buffer Size')\n",
    "            print(pix.samples_mv)\n",
    "            \n",
    "            #pix.size()=image_size\n",
    "            \n",
    "            try:\n",
    "                img = np.ndarray([pix.h, pix.w, 3], dtype=np.uint8, buffer=pix.samples_mv)\n",
    "            except:\n",
    "                print('Image too large for Picture')\n",
    "            finally:\n",
    "                #img = np.ndarray([pix.h, pix.w, 3], dtype=np.uint8, buffer=pix.samples_mv)\n",
    "                continue\n",
    "            \n",
    "            #plt.figure(dpi=DPI)  # set the figure's DPI\n",
    "            #plt.title(title)  # set title of image\n",
    "            #_ = plt.imshow(img, extent=(0, pix.w * 18 / DPI, pix.h * 18 / DPI, 0))\n",
    "            \n",
    "            #############################################################################\n",
    "            \n",
    "            #print('Image:')\n",
    "            #print(type(img))\n",
    "            \n",
    "            #Encode the Image into Base64\n",
    "\n",
    "            #img_enc = base64.b64encode(img)\n",
    "            \n",
    "            #For Decoding use the following statement \n",
    "            \n",
    "            #decoded_image = base64.decodestring(img_enc)\n",
    "            \n",
    "            img_meta_dict[\"img_matrix\"]=img\n",
    "            \n",
    "            npy_img_lst.append(img_meta_dict)\n",
    "            \n",
    "            #pix.save(\"page_%s-image_%s.png\" % (page_index, image_index)) # save the image as png\n",
    "            #pix = None\n",
    "            \n",
    "    \n",
    "    ###########################################################\n",
    "    \n",
    "    page_image_dict['page']=page_number\n",
    "    #page_image_dict['img_lst']=image_list\n",
    "    page_image_dict['img_cnt']=len(image_list)\n",
    "    page_image_dict['img_npy_lst']=npy_img_lst\n",
    "    \n",
    "    if download:\n",
    "        download_images_per_page(doc,doc_name,page,page_index,DPI)\n",
    "    \n",
    "    return page_image_dict\n",
    "\n",
    "\n",
    "def extract_text_tables_images_per_page(doc,doc_name,doc_img,index,download):\n",
    "    print(\"IN extract_text_tables_images_per_page\")\n",
    "    page_dict={}\n",
    "    page_image_dict={}\n",
    "    tab_df_lst=[]\n",
    "    page = doc[index]\n",
    "    tabs = page.find_tables()  # detect the tables\n",
    "    \n",
    "    ##Extract Images From Pages############\n",
    "    \n",
    "    page_image_dict=extract_images_per_page(doc_img,doc_name,index,download)\n",
    "    \n",
    "    print(\"page_image_dict\")\n",
    "    print(page_image_dict)\n",
    "    \n",
    "    \n",
    "    page_dict['page']=page_image_dict['page']\n",
    "    #page_dict['img_lst']=page_image_dict['img_lst']\n",
    "\n",
    "    page_dict['img_cnt']=page_image_dict['img_cnt']\n",
    "    \n",
    "    if page_dict['img_cnt']==0:\n",
    "        page_dict['img_flag']=0\n",
    "    else:\n",
    "        page_dict['img_flag']=1\n",
    "    \n",
    "    page_dict['img_npy_lst']=page_image_dict['img_npy_lst']\n",
    "    \n",
    "    #######################################\n",
    "    \n",
    "    ############################Extract Text#######################################################\n",
    "    #Extract Text From each page\n",
    "    text = page.get_text()\n",
    "    page_dict['text']=text\n",
    "    \n",
    "    print(text)\n",
    "    ###############################################################################################\n",
    "    \n",
    "    #for i,tab in enumerate(tabs):  # iterate over all tables\n",
    "    #    for cell in tab.header.cells:\n",
    "    #       page.draw_rect(cell,color=fitz.pdfcolor[\"red\"],width=0.3)\n",
    "    #    page.draw_rect(tab.bbox,color=fitz.pdfcolor[\"green\"])\n",
    "    #    print(f\"Table {i} column names: {tab.header.names}, external: {tab.header.external}\")\n",
    "    \n",
    "    #show_image(page, f\"Table & Header BBoxes\")\n",
    "   \n",
    "    # choose the second table for conversion to a DataFrame\n",
    "    #tab = tabs[0]\n",
    "    #print(tabs)\n",
    "    \n",
    "    if tabs.tables == []:\n",
    "        page_dict['tables_flag']=0\n",
    "    else:\n",
    "        for tab in tabs:\n",
    "            df=pd.DataFrame()\n",
    "            df = tab.to_pandas()\n",
    "            tab_df_lst.append(df)\n",
    "        page_dict['tables_flag']=1\n",
    "    \n",
    "    page_dict['tables']=tab_df_lst\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(tab_df_lst)\n",
    "    #df = tab.to_pandas()\n",
    "    # show the DataFrame\n",
    "    return page_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e215785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpyencoder import NumpyEncoder\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "def parse_pdf(doc_path,download=False):\n",
    "    \n",
    "    doc_per_page_tabs_lst=[]\n",
    "    doc = fitz.open(doc_path)\n",
    "    \n",
    "    num_pages=len(doc)\n",
    "    \n",
    "    doc_img = pymupdf.open(doc_path)\n",
    "    \n",
    "    doc_name=url.split('/')[-1]\n",
    "    \n",
    "    doc_type=url.split('.')[-1]\n",
    "    \n",
    "    doc_name_wo_type=url.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    print(doc_name_wo_type)\n",
    "    \n",
    "    isExist = os.path.exists('./parsed_pdf_output/'+doc_name_wo_type)\n",
    "    \n",
    "    if isExist:\n",
    "        shutil.rmtree('./parsed_pdf_output/'+doc_name_wo_type)\n",
    "        \n",
    "    os.mkdir('./parsed_pdf_output/'+doc_name_wo_type)\n",
    "    \n",
    "    for i in range(1,num_pages):\n",
    "        #page_image_dict={}\n",
    "        \n",
    "        os.mkdir('./parsed_pdf_output/'+doc_name_wo_type+'/page_'+str(i+1))\n",
    "        \n",
    "        tab_df_lst=extract_text_tables_images_per_page(doc,doc_name_wo_type,doc_img,i,download)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(tab_df_lst) == 0:\n",
    "            print(\"Do Nothing Here\")\n",
    "        else: \n",
    "            doc_per_page_tabs_lst.append(tab_df_lst)\n",
    "        \n",
    "    \n",
    "    \n",
    "    document_dictionary={\"name\":doc_name,\"type\":doc_type, \"data\": doc_per_page_tabs_lst}\n",
    "\n",
    "    if download:\n",
    "        #Save the List of MetaData to pickle in disk.\n",
    "        with open(\"./parsed_pdf_output/\"+doc_name_wo_type+'/'+doc_name+'.pkl', 'wb') as f:\n",
    "            pickle.dump(document_dictionary, f)\n",
    "    \n",
    "    return doc_per_page_tabs_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbdda1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29ae6d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "no such file: './PDF_SOURCE/Kubernetes_in_Action.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32243/2530166404.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./PDF_SOURCE/Kubernetes_in_Action.pdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Extraction if Document Name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoc_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdocument_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_32243/2341935660.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(doc_path, download)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdoc_per_page_tabs_lst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnum_pages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge-pypy3/envs/search_agent_poc/lib/python3.10/site-packages/pymupdf/__init__.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, filename, stream, filetype, rect, width, height, fontsize)\u001b[0m\n\u001b[1;32m   2850\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count_pdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2852\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_count_fz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2854\u001b[0;31m             \u001b[0mJM_mupdf_show_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJM_mupdf_show_errors_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: no such file: './PDF_SOURCE/Kubernetes_in_Action.pdf'"
     ]
    }
   ],
   "source": [
    "#################################Executing The Function################################################\n",
    "#This url Variable is the input to the program\n",
    "url=\"./pdf_source/Kubernetes_in_Action.pdf\"\n",
    "#Extraction if Document Name\n",
    "doc_name=url.split('/')[-1]\n",
    "\n",
    "document_dict=parse_pdf(url,download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97c1d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_len=len(document_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67fb7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDFs That faced Error\n",
    "#url='./PDF_FOLDER/Narasimha_Karumanchi_DS_Algo.pdf' -- error\n",
    "#url=\"./PDF_FOLDER/Kubernetes_in_Action.pdf\"\n",
    "#url=\"./PDF_FOLDER/2022.acl-long.62.pdf\"\n",
    "#This url Variable is the input to the program\n",
    "url=\"./pdf_source/Kubernetes_in_Action.pdf\"\n",
    "#Extraction if Document Name\n",
    "doc_name=url.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461c7e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kubernetes_in_Action.pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f83a7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import json_encoder as json_enc\n",
    "def serialize_to_json(lst_dict):\n",
    "    # convert into json\n",
    "    json_serialized_output = json_enc(lst_dict)\n",
    "    return json_serialized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d648d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Required Libraries Used for Graph Visualization##################################\n",
    "from pyvis.network import Network\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8ece127",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################Initializing the Graph Network##############################\n",
    "G = nx.DiGraph()\n",
    "##########Adding the root Node.Root Node is te Name of the PDF#########################################\n",
    "G.add_node(1, label=doc_name , title=doc_name , color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f3e8288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 3,\n",
       " 'img_cnt': 0,\n",
       " 'img_flag': 0,\n",
       " 'img_npy_lst': [],\n",
       " 'text': 'Kubernetes in Action\\n \\nwww.allitebooks.com\\n',\n",
       " 'tables_flag': 0,\n",
       " 'tables': []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae170c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_with_no_tables=[]\n",
    "pages_with_no_images=[]\n",
    "\n",
    "############Using for loop for each page the operations will go on till the final page############################\n",
    "for i in range(2,doc_len):\n",
    "    \n",
    "    #Adding the Page Number Nodes and connecting then to the root Node that is the document_name name node\n",
    "    #Form the page number from the dictionary metadata 'page'\n",
    "    page_idx=document_dict[i]['page']\n",
    "    page_num=\"Page_\"+ str(document_dict[i]['page'])\n",
    "    G.add_node(page_idx, label=page_num , title=page_num,color=\"blue\")\n",
    "    G.add_edge(1,page_idx)\n",
    "    \n",
    "    ##Under each Page we will add the different types of extracted entities like tables,text,images\n",
    "    #We will Create and add the text node and attach it with the page_num node.\n",
    "    text_idx='text_'+str(i)\n",
    "    G.add_node(text_idx, label=document_dict[i]['text'] , title=document_dict[i]['text'],color=\"violet\")\n",
    "    G.add_edge(page_idx,text_idx)\n",
    "    \n",
    "    #We will Create and add the table_flag node which will indicate if a page has tables\n",
    "    #If a Page has Tables it will be labelled as 1 else as 0.This ca be used a fileter to make search faster \n",
    "    #Through PDf.Hence this metadata is added. \n",
    "    table_flag_idx='table_flag'+str(i)\n",
    "    G.add_node(table_flag_idx, label= document_dict[i]['tables_flag'] , title=str(document_dict[i]['tables_flag']),color=\"green\")\n",
    "    G.add_edge(page_idx,table_flag_idx)\n",
    "    \n",
    "    ##We will extract the list of table for each page having the table.\n",
    "    ##After that for each element of the list of tables we will create a node.\n",
    "    ###The tables will be connceted to the tables flag.\n",
    "    \n",
    "    ###Commenting the section as visualization in pyvis needs more research\n",
    "    #if document_dict[i]['tables_flag']==0:\n",
    "    #    pages_with_no_tables.append(page_idx)\n",
    "    #else:\n",
    "    #    table_flag='table_flag'+str(i)\n",
    "    #    \n",
    "        ###Serialize DataFrame Object to json before we can visualize on pyviz###### \n",
    "    #    serilized_json=serialize_to_json(document_dict[i]['tables'])\n",
    "        \n",
    "       \n",
    "        \n",
    "    #  G.add_node(table_flag, label= document_dict[i]['tables'] , title=str(document_dict[i]['tables']),color=\"green\")\n",
    "    #   G.add_edge(table_flag_idx,table_flag)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5308c20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_dict[45]['tables']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bf429a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: When  cdn_resources is 'local' jupyter notebook has issues displaying graphics on chrome/safari. Use cdn_resources='in_line' or cdn_resources='remote' if you have issues viewing graphics in a notebook.\n",
      "nx1.html\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"2000px\"\n",
       "            height=\"800px\"\n",
       "            src=\"nx1.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7d1d65d53ac0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nt = Network('800px', '2000px',notebook=True)\n",
    "# populates the nodes and edges data structures\n",
    "nt.from_nx(G)\n",
    "nt.toggle_physics(True)\n",
    "#nt.show_buttons(filter_=['physics'])\n",
    "nt.show('nx1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a96fff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############Pickle the list of dictionaries ############\n",
    "import pickle\n",
    "\n",
    "# Store data (serialize in a pickle)\n",
    "with open('pdf_content_dict_stage1.pickle', 'wb') as handle:\n",
    "    pickle.dump(document_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615b67ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search_agent_poc",
   "language": "python",
   "name": "search_agent_poc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
