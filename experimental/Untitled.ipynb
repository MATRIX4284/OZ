{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc4f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "#rag_test_input_path='/home/matrix4284/MY_GEN_AI_PROJECTS/RAG/GraphRAG/graphrag-local-ollama/ragtest/input/'+file_name\n",
    "import os\n",
    "# importing shutil module\n",
    "import shutil\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#embeddings = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import XMLOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2040f4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m     justification: \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m     10\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOllama(base_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://192.168.50.100:11434\u001b[39m\u001b[38;5;124m\"\u001b[39m,model\u001b[38;5;241m=\u001b[39mmodel_name,temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m structured_llm \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAnswerWithJustification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m structured_llm\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat weighs more a pound of bricks or a pound of feathers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/search_agent_poc/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1222\u001b[0m, in \u001b[0;36mBaseChatModel.with_structured_output\u001b[0;34m(self, schema, include_raw, **kwargs)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_tools \u001b[38;5;129;01mis\u001b[39;00m BaseChatModel\u001b[38;5;241m.\u001b[39mbind_tools:\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_structured_output is not implemented for this model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1221\u001b[0m     )\n\u001b[0;32m-> 1222\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43many\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m is_basemodel_subclass(schema):\n\u001b[1;32m   1224\u001b[0m     output_parser: OutputParserLike \u001b[38;5;241m=\u001b[39m PydanticToolsParser(\n\u001b[1;32m   1225\u001b[0m         tools\u001b[38;5;241m=\u001b[39m[cast(TypeBaseModel, schema)], first_tool_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m     )\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/search_agent_poc/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:1099\u001b[0m, in \u001b[0;36mBaseChatModel.bind_tools\u001b[0;34m(self, tools, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_tools\u001b[39m(\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1096\u001b[0m     tools: Sequence[Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Type, Callable, BaseTool]],\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1098\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Runnable[LanguageModelInput, BaseMessage]:\n\u001b[0;32m-> 1099\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "model_name=\"llama3.1\"\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user question along with justification for the answer.'''\n",
    "    answer: str\n",
    "    justification: str\n",
    "\n",
    "llm = ChatOllama(base_url=\"http://192.168.50.100:11434\",model=model_name,temperature=0.2)\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification, include_raw=True)\n",
    "\n",
    "structured_llm.invoke(\"What weighs more a pound of bricks or a pound of feathers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8796ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\",model_kwargs = model_kwargs)\n",
    "\n",
    "##Define Vectorstore\n",
    "vectorstore = Chroma(embedding_function=embeddings, persist_directory=\"./chroma_kubernetes_in_action\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search_agent_poc",
   "language": "python",
   "name": "search_agent_poc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
