{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Python venv: search_agent_poc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4375a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This module will take the serialized dictionary got out of PDF Parsing ann try to extract\n",
    "##Semantic Knowldge like: \n",
    "## 1.Identifying top highlights from each page text\n",
    "## 2.Convert these highlights pertaining to each page to a json object.\n",
    "## 3.Store these structered list of json that list of highlights per page into the main pdf dictionary\n",
    "\n",
    "#Reasons for highlight extraction:\n",
    "####This helps in adding semantic information from the page text and bring them our as highlights####  \n",
    "####This helps in separating diffrent semantic information from th text chunked where the information present###\n",
    "####In the embedding is ofeten an averaged out information and functions like cosine similarity is ###\n",
    "####calculated to identify the main chunks some chunks became top candidates or the closest candidates of###\n",
    "####Similarity functions.\n",
    "\n",
    "##Usecase 1\n",
    "#Due to the aveeaging effect in chunks even if a chunks has only 70 percent information###\n",
    "####related to the question it is selected as a whole to answer the Question, in case the\n",
    "#chunks has context information than 70 percent which resullts in hallucination###\n",
    "####as it also tries to use other 30 percent unrelated information in some way to generate.#######\n",
    "\n",
    "#Usecase 2:\n",
    "####There can be scenario where there are 10 chunks out which 6 chunks contains 3 percent context-related\n",
    "####information and rest 4 chunks contain 10,5,5,5 percent each.So now if the max chunks for the data rag\n",
    "#### is set to 4 then the 4 chunks with 10,5,5,4 will be selected which is too less in delivering the answer \n",
    "#### and owing to the less information and chunked RAG only 25 percent informtaion will be used to make\n",
    "##the answer.\n",
    "\n",
    "\n",
    "####In this method the page is first strcutured as triplet then as highlights so that the granularity of\n",
    "####the contextual information is made much finer than a bink chunk owing to which the during QA or summary\n",
    "####Every individual entity and relation information of the triplet is taken into account which acts as a\n",
    "####fine-grained,more to the point ,very much suitable to the context and less unrelated information due to th removal of\n",
    "####chunk based information which is a averaged information#####\n",
    "####This helps in separating diffrent semantic information from th text chunked where the information present###\n",
    "####In the embedding is ofeten an averaged out information and functions like cosine similarity is ###\n",
    "####calculated to identify the main chunks some chunks became top candidates or the closest candidates of###\n",
    "####Similarity functions.Due to the averaging effect in chunks even if a chunks has only 50 percent information###\n",
    "####related to the question it is selected as a whole to answer the Question which resullts in hallucination###\n",
    "####as it also tries to use other 50 percent unrelated information in some way.#######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15191ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "#rag_test_input_path='/home/matrix4284/MY_GEN_AI_PROJECTS/RAG/GraphRAG/graphrag-local-ollama/ragtest/input/'+file_name\n",
    "import os\n",
    "# importing shutil module\n",
    "import shutil\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#embeddings = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import XMLOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01aaca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"llama3.1\"\n",
    "book_text=''\n",
    "page_text=''\n",
    "file_name='Kubernetes_in_action_text_only'\n",
    "extension='.txt'\n",
    "start_page_idx=433\n",
    "end_page_index=479\n",
    "#full_filename=file_name+'_'+str(page_idx)+extension\n",
    "#full_filename\n",
    "pdf_enrichment_output_dir='./pdf_enriched_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbcded8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matrix4284/mambaforge-pypy3/envs/search_agent_poc/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/matrix4284/mambaforge-pypy3/envs/search_agent_poc/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 0.4. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "#LLM Model for Prompt Tuning\n",
    "llm = ChatOllama(base_url=\"http://192.168.50.100:11434\",model=model_name,temperature=0.15)\n",
    "\n",
    "#embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\",model_kwargs = model_kwargs)\n",
    "\n",
    "##Define Vectorstore\n",
    "vectorstore = Chroma(embedding_function=embeddings, persist_directory=\"./chroma_kubernetes_in_action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a648bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (deserialized data)\n",
    "with open(pdf_enrichment_output_dir+'pdf_enriched_content_dict_stage2_phase2_433.pickle', 'rb') as handle:\n",
    "    document_dict_deserialized = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44433479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_dict_deserialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4eb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_dict_deserialized_stage2=document_dict_deserialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20db8986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_dict_deserialized_stage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2f9e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Definitions of Individual Enrichment Modules######\n",
    "\n",
    "def extract_summary_per_page(page_text):\n",
    "    \n",
    "    \n",
    "    parser = XMLOutputParser()\n",
    "\n",
    "# Prompt\n",
    "    prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a computer technology expert who has mastery in Kubernetes,Docker \\n\n",
    "            Machine Larning,Generative AI,Natural Language Understanding and Computer Vision.\\n\n",
    "            You have to deeply study a document page and extract a small summary within 150 words that will\\n\n",
    "            be enough to represent all information for that page.\n",
    "            There is no need to mention any header statement before the summary.\n",
    "            Wrap the summary in a json with key named summary.\n",
    "            Output the json and nothing else no headers no footers.\n",
    "            Here is the document page: \\n\\n {context} \\n\\n\"\"\",\n",
    "            input_variables=[\"context\"],\n",
    "            ###Introduced by Kaustav while experimenting with XMLParsers\n",
    "            #partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    #Commented out By Kaustav 20/08/2024 as str output parser is giving some unwanted text #####\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Trying out XML Output parser by Kautsva added 20/08/2024####\n",
    "    #chain = prompt | llm | parser\n",
    "    \n",
    "    \n",
    "\n",
    "    # Score\n",
    "    #filtered_docs = []\n",
    "\n",
    "    output = chain.invoke(\n",
    "        {\n",
    "                \"context\": page_text,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    json_output = output\n",
    "    json_output=json_output.split('{')[1]\n",
    "    #page_output_json=json.loads(output)\n",
    "    \n",
    "    \n",
    "    #print('JSON OUTPUT:')\n",
    "    #print(json_output)\n",
    "    \n",
    "    json_output='{'+json_output\n",
    "    \n",
    "    json_output=json_output.split('}')[0]\n",
    "    \n",
    "    json_output=json_output+'}'\n",
    "    #page_output_json=json.loads(output)\n",
    "    #return page_output_json\n",
    "    return json_output\n",
    "    \n",
    "    #return page_output_json\n",
    "    #return output\n",
    "\n",
    "    \n",
    "# Function to reverse a string\n",
    "def reverse(string):\n",
    "    string = string[::-1]\n",
    "    return string\n",
    "    \n",
    "##Definitions of Individual Enrichment Modules######\n",
    "\n",
    "def extract_highlights_per_page(page_text):\n",
    "    \n",
    "    \n",
    "    parser = XMLOutputParser()\n",
    "\n",
    "# Prompt\n",
    "    prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a computer technology expert who has mastery in Kubernetes,Docker,\\n\n",
    "            Machine Learning,Generative AI,Natural Language Understanding and Computer Vision.\\n\n",
    "            You have to deeply study a document page and extract upto maximum of 5 most important and most \\n\n",
    "            informative highlights from the page content. \\n\n",
    "            content.Every highlight extracted but have some concrete information and all highlights together \\n\n",
    "            for the same page should make sense.\\n\n",
    "            Extract the highlights following the mentioned rules below:\\n\n",
    "            1.For each highlight wrap it up in json with the key named highlight.\\n\n",
    "            2.After all the highlights have been extracted collate them into a list of json.\\n\n",
    "            Output should only contain the list of json and no other words or character or sentences.\\n\n",
    "            Here is the document page: \\n\\n {context} \\n\\n\"\"\",\n",
    "            input_variables=[\"context\"],\n",
    "            ###Introduced by Kaustav while experimenting with XMLParsers\n",
    "            #partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    #Commented out By Kaustav 20/08/2024 as str output parser is giving some unwanted text #####\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "   \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Trying out XML Output parser by Kautsva added 20/08/2024####\n",
    "    #chain = prompt | llm | parser\n",
    "    \n",
    "    \n",
    "\n",
    "    # Score\n",
    "    #filtered_docs = []\n",
    "\n",
    "    output = chain.invoke(\n",
    "        {\n",
    "                \"context\": page_text,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(\"Raw Output\")\n",
    "    print(output)\n",
    "    \n",
    "    json_output=output.split('[')[1]\n",
    "    #page_output_json=json.loads(output)\n",
    "    \n",
    "    \n",
    "    #print('JSON OUTPUT:')\n",
    "    #print(json_output)\n",
    "    \n",
    "    json_output='['+json_output\n",
    "    \n",
    "    \n",
    "    \n",
    "    json_output=reverse(json_output)\n",
    "    \n",
    "    print('Reversed JSON OUTPUT:')\n",
    "    print(json_output)\n",
    "    \n",
    "    json_output=json_output.split(']')[1]\n",
    "    \n",
    "    json_output=reverse(json_output)\n",
    "    #json_output=json_output.rsplit(']')[-1]\n",
    "    #page_output_json=json.loads(output)\n",
    "    \n",
    "    \n",
    "    #print('JSON OUTPUT:')\n",
    "    #print(json_output)\n",
    "    \n",
    "    json_output= json_output + ']'\n",
    "    \n",
    "    print('JSON OUTPUT:')\n",
    "    print(json_output)\n",
    "    \n",
    "    #page_output_json=json.loads(output)\n",
    "    #return page_output_json\n",
    "    return json_output\n",
    "    \n",
    "    #return page_output_json\n",
    "    #return output\n",
    "\n",
    "def entity_collector_per_page(entity_lst):\n",
    "\n",
    "    entities=[]\n",
    "    \n",
    "    for entity in entity_lst:\n",
    "        print(\"Entity:\")\n",
    "        print(entity)\n",
    "        entity_name=entity['entity']\n",
    "        entities.append(entity_name)\n",
    "    return list(set(entities))\n",
    "\n",
    "\n",
    "def enrich_page(page_idx):\n",
    "    \n",
    "    #print(\"Page Number\")\n",
    "    #print(page_idx)\n",
    "    \n",
    "    page_text=document_dict_deserialized_stage2[page_idx]['text']\n",
    "    \n",
    "    \n",
    "    ########################################Summary Extraction Enrichment###########################################\n",
    "    \n",
    "    ##Summary Extraction Enrichment\n",
    "    #page_summary_txt=extract_summary_per_page(page_text)\n",
    "    \n",
    "    #print(\"Page Summary Text\")\n",
    "    #print(page_summary_txt)\n",
    "    \n",
    "    ######Add Summary as a part of pdf structured dictionary list in order summarization enrichment to data######### \n",
    "    #document_dict_deserialized_stage2[page_idx]['summary']=json.loads(page_summary_txt.strip())[\"summary\"]\n",
    "    \n",
    "    ################################################################################################################\n",
    "    \n",
    "    ######################################Highlight Extraction######################################################\n",
    "    \n",
    "    ##Summary Extraction Enrichment\n",
    "    page_highlights_json_lst=extract_highlights_per_page('\"\"'+page_text+'\"\"')\n",
    "    \n",
    "    #print(\"Page Highlights\")\n",
    "    #print(page_highlights_json_lst)\n",
    "    \n",
    "    page_highlights_json_lst=json.loads(page_highlights_json_lst)\n",
    "    \n",
    "    ######Add Summary as a part of pdf structured dictionary list in order summarization enrichment to data######### \n",
    "    document_dict_deserialized_stage2[page_idx]['highlights']=page_highlights_json_lst\n",
    "    \n",
    "    ################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5465a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "Here are the 5 most important highlights extracted from the document page in JSON format:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"The termination grace period can be configured in the pod spec by setting the spec.terminationGracePeriodSeconds field.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You should set the grace period to long enough so your process can finish cleaning up in that time.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When deleting a pod, you can override the specified grace period using the --grace-period option with kubectl delete command.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Applications should react to a SIGTERM signal by starting their shut-down procedure and terminating when it finishes.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Forcing the deletion of a pod without waiting for its containers to shut down can cause issues in stateful clusters, so use with caution.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".noituac htiw esu os ,sretsulc lufetats ni seussi esuac nac nwod tuhs ot sreniatnoc sti rof gnitiaw tuohtiw dop a fo noiteled eht gnicroF\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".sehsinif ti nehw gnitanimret dna erudecorp nwod-tuhs rieht gnitrats yb langis MRETGIS a ot tcaer dluohs snoitacilppA\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".dnammoc eteled ltcebuk htiw noitpo doirep-ecarg-- eht gnisu doirep ecarg deificeps eht edirrevo nac uoy ,dop a gniteled nehW\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".emit taht ni pu gninaelc hsinif nac ssecorp ruoy os hguone gnol ot doirep ecarg eht tes dluohs uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".dleif sdnoceSdoirePecarGnoitanimret.ceps eht gnittes yb ceps dop eht ni derugifnoc eb nac doirep ecarg noitanimret ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"The termination grace period can be configured in the pod spec by setting the spec.terminationGracePeriodSeconds field.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You should set the grace period to long enough so your process can finish cleaning up in that time.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When deleting a pod, you can override the specified grace period using the --grace-period option with kubectl delete command.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Applications should react to a SIGTERM signal by starting their shut-down procedure and terminating when it finishes.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Forcing the deletion of a pod without waiting for its containers to shut down can cause issues in stateful clusters, so use with caution.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:433\n",
      "Raw Output\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"A pod should not start migrating its data upon receiving a termination signal because it's not guaranteed that the shut-down procedure will finish before the process is killed.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Creating a new Job resource to run a dedicated pod for data migration is one solution, but there's no guarantee the app will manage to create the Job object every single time.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A dedicated, constantly running pod or a CronJob resource can be used to periodically check for orphaned data and migrate it to remaining pods.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"StatefulSets don't help with this problem because scaling down leaves PersistentVolumeClaims orphaned, leaving the data stored on the PersistentVolume stranded.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A data-migrating pod should be run when using StatefulSets to prevent data loss in case of a scale-up failure or long delay.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".yaled gnol ro eruliaf pu-elacs a fo esac ni ssol atad tneverp ot steSlufetatS gnisu nehw nur eb dluohs dop gnitargim-atad A\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".dednarts emuloVtnetsisreP eht no derots atad eht gnivael ,denahpro smialCemuloVtnetsisreP sevael nwod gnilacs esuaceb melborp siht htiw pleh t'nod steSlufetatS\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".sdop gniniamer ot ti etargim dna atad denahpro rof kcehc yllacidoirep ot desu eb nac ecruoser boJnorC a ro dop gninnur yltnatsnoc ,detacided A\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".emit elgnis yreve tcejbo boJ eht etaerc ot eganam lliw ppa eht eetnaraug on s'ereht tub ,noitulos eno si noitargim atad rof dop detacided a nur ot ecruoser boJ wen a gnitaerC\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".dellik si ssecorp eht erofeb hsinif lliw erudecorp nwod-tuhs eht taht deetnaraug ton s'ti esuaceb langis noitanimret a gniviecer nopu atad sti gnitargim trats ton dluohs dop A\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"A pod should not start migrating its data upon receiving a termination signal because it's not guaranteed that the shut-down procedure will finish before the process is killed.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Creating a new Job resource to run a dedicated pod for data migration is one solution, but there's no guarantee the app will manage to create the Job object every single time.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A dedicated, constantly running pod or a CronJob resource can be used to periodically check for orphaned data and migrate it to remaining pods.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"StatefulSets don't help with this problem because scaling down leaves PersistentVolumeClaims orphaned, leaving the data stored on the PersistentVolume stranded.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A data-migrating pod should be run when using StatefulSets to prevent data loss in case of a scale-up failure or long delay.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:434\n",
      "Raw Output\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To prevent broken client connections when a pod is starting up, ensure each connection is handled properly by adding an HTTP GET readiness probe and pointing it to the base URL of your app.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"If you don't specify a readiness probe in your pod spec, the pod is always considered ready and will start receiving requests almost immediately, which can lead to 'connection refused' types of errors if your app isn't ready to accept connections by then.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Kubernetes doesn't prevent broken client connections when pods are starting up or shutting down, so it's essential for your app to follow a few rules to prevent this from happening.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A dedicated pod can be used to migrate data between StatefulSets, as shown in Figure 17.6, which involves transferring data to remaining pod(s) and connecting to orphaned PVCs.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"To ensure all client requests are handled properly, your app needs to follow a few rules, including making sure connections are handled properly when the pod starts up and shutting down cleanly.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".ylnaelc nwod gnittuhs dna pu strats dop eht nehw ylreporp deldnah era snoitcennoc erus gnikam gnidulcni ,selur wef a wollof ot sdeen ppa ruoy ,ylreporp deldnah era stseuqer tneilc lla erusne oT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".sCVP denahpro ot gnitcennoc dna )s(dop gniniamer ot atad gnirrefsnart sevlovni hcihw ,6.71 erugiF ni nwohs sa ,steSlufetatS neewteb atad etargim ot desu eb nac dop detacided A\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".gnineppah morf siht tneverp ot selur wef a wollof ot ppa ruoy rof laitnesse s'ti os ,nwod gnittuhs ro pu gnitrats era sdop nehw snoitcennoc tneilc nekorb tneverp t'nseod setenrebuK\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".neht yb snoitcennoc tpecca ot ydaer t'nsi ppa ruoy fi srorre fo sepyt 'desufer noitcennoc' ot dael nac hcihw ,yletaidemmi tsomla stseuqer gniviecer trats lliw dna ydaer deredisnoc syawla si dop eht ,ceps dop ruoy ni eborp ssenidaer a yficeps t'nod uoy fI\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ppa ruoy fo LRU esab eht ot ti gnitniop dna eborp ssenidaer TEG PTTH na gnidda yb ylreporp deldnah si noitcennoc hcae erusne ,pu gnitrats si dop a nehw snoitcennoc tneilc nekorb tneverp oT\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To prevent broken client connections when a pod is starting up, ensure each connection is handled properly by adding an HTTP GET readiness probe and pointing it to the base URL of your app.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"If you don't specify a readiness probe in your pod spec, the pod is always considered ready and will start receiving requests almost immediately, which can lead to 'connection refused' types of errors if your app isn't ready to accept connections by then.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Kubernetes doesn't prevent broken client connections when pods are starting up or shutting down, so it's essential for your app to follow a few rules to prevent this from happening.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A dedicated pod can be used to migrate data between StatefulSets, as shown in Figure 17.6, which involves transferring data to remaining pod(s) and connecting to orphaned PVCs.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"To ensure all client requests are handled properly, your app needs to follow a few rules, including making sure connections are handled properly when the pod starts up and shutting down cleanly.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"Preventing broken connections during pod shut-down involves handling client requests properly, which includes continuing to accept requests, completing pending requests, and closing persistent HTTP connections.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When a request for a pod deletion is received by the API server, it modifies the state in etcd and notifies its watchers, including the Kubelet and Endpoints controller, of the deletion.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The sequence of events that occurs when a Pod is deleted involves parallel sequences A and B, which include stopping containers, notifying the Kubelet and Endpoints controller, modifying endpoints, removing the pod from iptables, and removing the pod as an endpoint.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The API server modifies the state in etcd and notifies its watchers of the deletion, while the Kubelet and Endpoints controller receive notifications and take actions to remove the pod from the cluster.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Understanding the sequence of events that occurs when a Pod is deleted is crucial for ensuring all client requests are handled properly during pod shut-down.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".nwod-tuhs dop gnirud ylreporp deldnah era stseuqer tneilc lla gnirusne rof laicurc si deteled si doP a nehw srucco taht stneve fo ecneuqes eht gnidnatsrednU\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".retsulc eht morf dop eht evomer ot snoitca ekat dna snoitacifiton eviecer rellortnoc stniopdnE dna telebuK eht elihw ,noiteled eht fo srehctaw sti seifiton dna dcte ni etats eht seifidom revres IPA ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".tniopdne na sa dop eht gnivomer dna ,selbatpi morf dop eht gnivomer ,stniopdne gniyfidom ,rellortnoc stniopdnE dna telebuK eht gniyfiton ,sreniatnoc gnippots edulcni hcihw ,B dna A secneuqes lellarap sevlovni deteled si doP a nehw srucco taht stneve fo ecneuqes ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".noiteled eht fo ,rellortnoc stniopdnE dna telebuK eht gnidulcni ,srehctaw sti seifiton dna dcte ni etats eht seifidom ti ,revres IPA eht yb deviecer si noiteled dop a rof tseuqer a nehW\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".snoitcennoc PTTH tnetsisrep gnisolc dna ,stseuqer gnidnep gnitelpmoc ,stseuqer tpecca ot gniunitnoc sedulcni hcihw ,ylreporp stseuqer tneilc gnildnah sevlovni nwod-tuhs dop gnirud snoitcennoc nekorb gnitneverP\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"Preventing broken connections during pod shut-down involves handling client requests properly, which includes continuing to accept requests, completing pending requests, and closing persistent HTTP connections.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When a request for a pod deletion is received by the API server, it modifies the state in etcd and notifies its watchers, including the Kubelet and Endpoints controller, of the deletion.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The sequence of events that occurs when a Pod is deleted involves parallel sequences A and B, which include stopping containers, notifying the Kubelet and Endpoints controller, modifying endpoints, removing the pod from iptables, and removing the pod as an endpoint.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The API server modifies the state in etcd and notifies its watchers of the deletion, while the Kubelet and Endpoints controller receive notifications and take actions to remove the pod from the cluster.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Understanding the sequence of events that occurs when a Pod is deleted is crucial for ensuring all client requests are handled properly during pod shut-down.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:436\n",
      "Raw Output\n",
      "Here are the 5 most important and informative highlights extracted from the document page:\n",
      "\n",
      "```\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"When a pod is deleted, the Kubelet initiates a shutdown sequence that includes running the pre-stop hook, sending SIGTERM, waiting for a period of time, and then forcibly killing the container if it hasn't yet terminated on its own.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Endpoints controller removes the pod as an endpoint in all services that the pod is a part of by modifying the Endpoints API object and notifying all clients watching the Endpoints object.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Removing iptables rules has no effect on existing connections - clients who are already connected to the pod will still send additional requests to the pod through those existing connections.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The time it takes for a pod to be shut down is slightly shorter than the time required for iptables rules to be updated, and the chain of events leading to iptables rule updates is considerably longer.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Both sequences of events (shutting down the app's process and updating iptables rules) happen in parallel, with the shutdown sequence initiated by the Kubelet and the iptables rule update sequence initiated by the Endpoints controller.\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Reversed JSON OUTPUT:\n",
      "```\n",
      "]\n",
      "}    \n",
      "\".rellortnoc stniopdnE eht yb detaitini ecneuqes etadpu elur selbatpi eht dna telebuK eht yb detaitini ecneuqes nwodtuhs eht htiw ,lellarap ni neppah )selur selbatpi gnitadpu dna ssecorp s'ppa eht nwod gnittuhs( stneve fo secneuqes htoB\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".regnol ylbaredisnoc si setadpu elur selbatpi ot gnidael stneve fo niahc eht dna ,detadpu eb ot selur selbatpi rof deriuqer emit eht naht retrohs ylthgils si nwod tuhs eb ot dop a rof sekat ti emit ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".snoitcennoc gnitsixe esoht hguorht dop eht ot stseuqer lanoitidda dnes llits lliw dop eht ot detcennoc ydaerla era ohw stneilc - snoitcennoc gnitsixe no tceffe on sah selur selbatpi gnivomeR\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".tcejbo stniopdnE eht gnihctaw stneilc lla gniyfiton dna tcejbo IPA stniopdnE eht gniyfidom yb fo trap a si dop eht taht secivres lla ni tniopdne na sa dop eht sevomer rellortnoc stniopdnE ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".nwo sti no detanimret tey t'nsah ti fi reniatnoc eht gnillik ylbicrof neht dna ,emit fo doirep a rof gnitiaw ,MRETGIS gnidnes ,kooh pots-erp eht gninnur sedulcni taht ecneuqes nwodtuhs a setaitini telebuK eht ,deteled si dop a nehW\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"When a pod is deleted, the Kubelet initiates a shutdown sequence that includes running the pre-stop hook, sending SIGTERM, waiting for a period of time, and then forcibly killing the container if it hasn't yet terminated on its own.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Endpoints controller removes the pod as an endpoint in all services that the pod is a part of by modifying the Endpoints API object and notifying all clients watching the Endpoints object.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Removing iptables rules has no effect on existing connections - clients who are already connected to the pod will still send additional requests to the pod through those existing connections.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The time it takes for a pod to be shut down is slightly shorter than the time required for iptables rules to be updated, and the chain of events leading to iptables rule updates is considerably longer.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Both sequences of events (shutting down the app's process and updating iptables rules) happen in parallel, with the shutdown sequence initiated by the Kubelet and the iptables rule update sequence initiated by the Endpoints controller.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:437\n",
      "Raw Output\n",
      "[{\"highlight\": \"The pod may still receive client requests after it was sent the termination signal.\"}, {\"highlight\": \"Adding a readiness probe to your pod will not solve the problem of handling client requests properly.\"}, {\"highlight\": \"The Endpoints controller removes the pod from the service Endpoints as soon as it receives notice of the pod being deleted.\"}, {\"highlight\": \"You can improve the user experience by adding a 5- or 10-second delay before shutting down the pod.\"}, {\"highlight\": \"There is no perfect solution to ensure all requests are handled fully, but a longer delay may still improve the user experience.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".ecneirepxe resu eht evorpmi llits yam yaled regnol a tub ,ylluf deldnah era stseuqer lla erusne ot noitulos tcefrep on si erehT\" :\"thgilhgih\"{ ,}\".dop eht nwod gnittuhs erofeb yaled dnoces-01 ro -5 a gnidda yb ecneirepxe resu eht evorpmi nac uoY\" :\"thgilhgih\"{ ,}\".deteled gnieb dop eht fo eciton seviecer ti sa noos sa stniopdnE ecivres eht morf dop eht sevomer rellortnoc stniopdnE ehT\" :\"thgilhgih\"{ ,}\".ylreporp stseuqer tneilc gnildnah fo melborp eht evlos ton lliw dop ruoy ot eborp ssenidaer a gniddA\" :\"thgilhgih\"{ ,}\".langis noitanimret eht tnes saw ti retfa stseuqer tneilc eviecer llits yam dop ehT\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"The pod may still receive client requests after it was sent the termination signal.\"}, {\"highlight\": \"Adding a readiness probe to your pod will not solve the problem of handling client requests properly.\"}, {\"highlight\": \"The Endpoints controller removes the pod from the service Endpoints as soon as it receives notice of the pod being deleted.\"}, {\"highlight\": \"You can improve the user experience by adding a 5- or 10-second delay before shutting down the pod.\"}, {\"highlight\": \"There is no perfect solution to ensure all requests are handled fully, but a longer delay may still improve the user experience.\"}]\n",
      "Done for page number:438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[{\"highlight\": \"To properly shut down an application, wait for a few seconds, then stop accepting new connections, close all keep-alive connections not in the middle of a request, wait for all active requests to finish, and then shut down completely.\"}, {\"highlight\": \"A pre-stop hook can be added to wait a few seconds before shutting down, preventing broken connections and allowing active requests to complete.\"}, {\"highlight\": \"The process of shutting down an application is not as simple as exiting the process immediately upon receiving the termination signal.\"}, {\"highlight\": \"Properly handling existing and new connections after receiving a termination signal involves stopping accepting new connections, closing inactive keep-alive connections, and waiting for active requests to finish before shutting down completely.\"}, {\"highlight\": \"A delay of a few seconds can be added using a pre-stop hook to prevent the container from shutting down promptly and causing the pod to be shown in lists long after it has been deleted.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".deteled neeb sah ti retfa gnol stsil ni nwohs eb ot dop eht gnisuac dna yltpmorp nwod gnittuhs morf reniatnoc eht tneverp ot kooh pots-erp a gnisu dedda eb nac sdnoces wef a fo yaled A\" :\"thgilhgih\"{ ,}\".yletelpmoc nwod gnittuhs erofeb hsinif ot stseuqer evitca rof gnitiaw dna ,snoitcennoc evila-peek evitcani gnisolc ,snoitcennoc wen gnitpecca gnippots sevlovni langis noitanimret a gniviecer retfa snoitcennoc wen dna gnitsixe gnildnah ylreporP\" :\"thgilhgih\"{ ,}\".langis noitanimret eht gniviecer nopu yletaidemmi ssecorp eht gnitixe sa elpmis sa ton si noitacilppa na nwod gnittuhs fo ssecorp ehT\" :\"thgilhgih\"{ ,}\".etelpmoc ot stseuqer evitca gniwolla dna snoitcennoc nekorb gnitneverp ,nwod gnittuhs erofeb sdnoces wef a tiaw ot dedda eb nac kooh pots-erp A\" :\"thgilhgih\"{ ,}\".yletelpmoc nwod tuhs neht dna ,hsinif ot stseuqer evitca lla rof tiaw ,tseuqer a fo elddim eht ni ton snoitcennoc evila-peek lla esolc ,snoitcennoc wen gnitpecca pots neht ,sdnoces wef a rof tiaw ,noitacilppa na nwod tuhs ylreporp oT\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"To properly shut down an application, wait for a few seconds, then stop accepting new connections, close all keep-alive connections not in the middle of a request, wait for all active requests to finish, and then shut down completely.\"}, {\"highlight\": \"A pre-stop hook can be added to wait a few seconds before shutting down, preventing broken connections and allowing active requests to complete.\"}, {\"highlight\": \"The process of shutting down an application is not as simple as exiting the process immediately upon receiving the termination signal.\"}, {\"highlight\": \"Properly handling existing and new connections after receiving a termination signal involves stopping accepting new connections, closing inactive keep-alive connections, and waiting for active requests to finish before shutting down completely.\"}, {\"highlight\": \"A delay of a few seconds can be added using a pre-stop hook to prevent the container from shutting down promptly and causing the pod to be shown in lists long after it has been deleted.\"}]\n",
      "Done for page number:439\n",
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"You don't need to modify the code of your app at all to make it easy to run and manage in Kubernetes.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Including unnecessary files in container images can make them larger than necessary, which can slow down deploying new pods and scaling them.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Using minimal Docker images without unnecessary cruft is recommended for Kubernetes, but they can be difficult to debug.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Properly tagging your images with specific versions instead of using the latest tag is wise, as it allows you to roll back to a previous version if needed.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Using the FROM scratch directive in the Dockerfile can create extremely small and perfect container images for Kubernetes, especially for Go-based apps.\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\".sppa desab-oG rof yllaicepse ,setenrebuK rof segami reniatnoc tcefrep dna llams ylemertxe etaerc nac elifrekcoD eht ni evitcerid hctarcs MORF eht gnisU\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".dedeen fi noisrev suoiverp a ot kcab llor ot uoy swolla ti sa ,esiw si gat tsetal eht gnisu fo daetsni snoisrev cificeps htiw segami ruoy gniggat ylreporP\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".gubed ot tluciffid eb nac yeht tub ,setenrebuK rof dednemmocer si tfurc yrassecennu tuohtiw segami rekcoD laminim gnisU\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".meht gnilacs dna sdop wen gniyolped nwod wols nac hcihw ,yrassecen naht regral meht ekam nac segami reniatnoc ni selif yrassecennu gnidulcnI\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".setenrebuK ni eganam dna nur ot ysae ti ekam ot lla ta ppa ruoy fo edoc eht yfidom ot deen t'nod uoY\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"You don't need to modify the code of your app at all to make it easy to run and manage in Kubernetes.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Including unnecessary files in container images can make them larger than necessary, which can slow down deploying new pods and scaling them.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Using minimal Docker images without unnecessary cruft is recommended for Kubernetes, but they can be difficult to debug.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Properly tagging your images with specific versions instead of using the latest tag is wise, as it allows you to roll back to a previous version if needed.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Using the FROM scratch directive in the Dockerfile can create extremely small and perfect container images for Kubernetes, especially for Go-based apps.\"\n",
      "  }\n",
      "]\n",
      "Done for page number:440\n",
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"Use tags containing a proper version designator instead of latest, except in development. Set imagePullPolicy field to Always for mutable tags.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Label all resources with multiple labels across each individual dimension, including application name, tier, environment, version, release type, tenant, and shard.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Use annotations to add additional information to resources, such as contact information, dependencies between pods, build and version info, and metadata for tooling or GUIs.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Set imagePullPolicy field to Always can slow down pod startup and prevent pod from starting up when registry cannot be contacted.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Providing information on why a container terminated is crucial, especially in microservices architecture, to troubleshoot and resolve issues efficiently.\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\".yltneiciffe seussi evloser dna toohselbuort ot ,erutcetihcra secivresorcim ni yllaicepse ,laicurc si detanimret reniatnoc a yhw no noitamrofni gnidivorP\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".detcatnoc eb tonnac yrtsiger nehw pu gnitrats morf dop tneverp dna putrats dop nwod wols nac syawlA ot dleif yciloPlluPegami teS\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".sIUG ro gniloot rof atadatem dna ,ofni noisrev dna dliub ,sdop neewteb seicnedneped ,noitamrofni tcatnoc sa hcus ,secruoser ot noitamrofni lanoitidda dda ot snoitatonna esU\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".drahs dna ,tnanet ,epyt esaeler ,noisrev ,tnemnorivne ,reit ,eman noitacilppa gnidulcni ,noisnemid laudividni hcae ssorca slebal elpitlum htiw secruoser lla lebaL\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".sgat elbatum rof syawlA ot dleif yciloPlluPegami teS .tnempoleved ni tpecxe ,tsetal fo daetsni rotangised noisrev reporp a gniniatnoc sgat esU\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"Use tags containing a proper version designator instead of latest, except in development. Set imagePullPolicy field to Always for mutable tags.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Label all resources with multiple labels across each individual dimension, including application name, tier, environment, version, release type, tenant, and shard.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Use annotations to add additional information to resources, such as contact information, dependencies between pods, build and version info, and metadata for tooling or GUIs.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Set imagePullPolicy field to Always can slow down pod startup and prevent pod from starting up when registry cannot be contacted.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Providing information on why a container terminated is crucial, especially in microservices architecture, to troubleshoot and resolve issues efficiently.\"\n",
      "  }\n",
      "]\n",
      "Done for page number:441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"To make triage even easier, you can use one other Kubernetes feature that makes it possible to show the reason why a container terminated in the pods status.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"The default file the process needs to write the message to is /dev/termination-log, but it can be changed by setting the terminationMessagePath field in the container definition in the pod spec.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"When running this pod, youll soon see the pods status shown as CrashLoopBackOff. If you then use kubectl describe, you can see why the container died, without having to dig down into its logs,\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"The container will write the message to the file just before exiting.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Youre overriding the default path of the termination message file.\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\".elif egassem noitanimret eht fo htap tluafed eht gnidirrevo eruoY\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".gnitixe erofeb tsuj elif eht ot egassem eht etirw lliw reniatnoc ehT\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\",sgol sti otni nwod gid ot gnivah tuohtiw ,deid reniatnoc eht yhw ees nac uoy ,ebircsed ltcebuk esu neht uoy fI .ffOkcaBpooLhsarC sa nwohs sutats sdop eht ees noos lluoy ,dop siht gninnur nehW\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".ceps dop eht ni noitinifed reniatnoc eht ni dleif htaPegasseMnoitanimret eht gnittes yb degnahc eb nac ti tub ,gol-noitanimret/ved/ si ot egassem eht etirw ot sdeen ssecorp eht elif tluafed ehT\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".sutats sdop eht ni detanimret reniatnoc a yhw nosaer eht wohs ot elbissop ti sekam taht erutaef setenrebuK rehto eno esu nac uoy ,reisae neve egairt ekam oT\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"To make triage even easier, you can use one other Kubernetes feature that makes it possible to show the reason why a container terminated in the pods status.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"The default file the process needs to write the message to is /dev/termination-log, but it can be changed by setting the terminationMessagePath field in the container definition in the pod spec.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"When running this pod, youll soon see the pods status shown as CrashLoopBackOff. If you then use kubectl describe, you can see why the container died, without having to dig down into its logs,\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"The container will write the message to the file just before exiting.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Youre overriding the default path of the termination message file.\"\n",
      "  }\n",
      "]\n",
      "Done for page number:442\n",
      "Raw Output\n",
      "[{\"highlight\": \"Kubernetes doesn't provide functionality to show app-specific status messages of running containers.\"}, \n",
      " {\"highlight\": \"Apps should write to standard output instead of files for easy log viewing with kubectl logs command.\"}, \n",
      " {\"highlight\": \"Use --previous option with kubectl logs to see previous container's logs after a crash and replacement.\"}, \n",
      " {\"highlight\": \"Copy log file from container using kubectl exec <pod> cat <logfile> or kubectl cp command.\"}, \n",
      " {\"highlight\": \"Transfer files between local machine and pod using kubectl cp command, e.g., $ kubectl cp foo-pod:/var/log/foo.log foo.log\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\"gol.oof gol.oof/gol/rav/:dop-oof pc ltcebuk $ ,.g.e ,dnammoc pc ltcebuk gnisu dop dna enihcam lacol neewteb selif refsnarT\" :\"thgilhgih\"{ \n",
      " ,}\".dnammoc pc ltcebuk ro >elifgol< tac >dop< cexe ltcebuk gnisu reniatnoc morf elif gol ypoC\" :\"thgilhgih\"{ \n",
      " ,}\".tnemecalper dna hsarc a retfa sgol s'reniatnoc suoiverp ees ot sgol ltcebuk htiw noitpo suoiverp-- esU\" :\"thgilhgih\"{ \n",
      " ,}\".dnammoc sgol ltcebuk htiw gniweiv gol ysae rof selif fo daetsni tuptuo dradnats ot etirw dluohs sppA\" :\"thgilhgih\"{ \n",
      " ,}\".sreniatnoc gninnur fo segassem sutats cificeps-ppa wohs ot ytilanoitcnuf edivorp t'nseod setenrebuK\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"Kubernetes doesn't provide functionality to show app-specific status messages of running containers.\"}, \n",
      " {\"highlight\": \"Apps should write to standard output instead of files for easy log viewing with kubectl logs command.\"}, \n",
      " {\"highlight\": \"Use --previous option with kubectl logs to see previous container's logs after a crash and replacement.\"}, \n",
      " {\"highlight\": \"Copy log file from container using kubectl exec <pod> cat <logfile> or kubectl cp command.\"}, \n",
      " {\"highlight\": \"Transfer files between local machine and pod using kubectl cp command, e.g., $ kubectl cp foo-pod:/var/log/foo.log foo.log\"}]\n",
      "Done for page number:443\n",
      "Raw Output\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"In a production system, youll want to use a centralized, cluster-wide logging solution, so all your logs are collected and (permanently) stored in a central location.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Kubernetes by itself doesnt provide any kind of centralized logging. The components necessary for providing a centralized storage and analysis of all the container logs must be provided by additional components,\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When using the EFK stack for centralized logging, each Kubernetes cluster node runs a FluentD agent (usually as a pod deployed through a DaemonSet), which is responsible for gathering the logs from the containers,\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"ElasticSearch is also deployed as a pod somewhere in the cluster. The logs can then be viewed and analyzed in a web browser through Kibana, which is a web tool for visualizing ElasticSearch data.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You may have already heard of the ELK stack composed of ElasticSearch, Logstash, and Kibana. A slightly modified variation is the EFK stack, where Logstash is replaced with FluentD.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".DtneulF htiw decalper si hsatsgoL erehw ,kcats KFE eht si noitairav deifidom ylthgils A .anabiK dna ,hsatsgoL ,hcraeScitsalE fo desopmoc kcats KLE eht fo draeh ydaerla evah yam uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".atad hcraeScitsalE gnizilausiv rof loot bew a si hcihw ,anabiK hguorht resworb bew a ni dezylana dna deweiv eb neht nac sgol ehT .retsulc eht ni erehwemos dop a sa deyolped osla si hcraeScitsalE\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\",sreniatnoc eht morf sgol eht gnirehtag rof elbisnopser si hcihw ,)teSnomeaD a hguorht deyolped dop a sa yllausu( tnega DtneulF a snur edon retsulc setenrebuK hcae ,gniggol dezilartnec rof kcats KFE eht gnisu nehW\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\",stnenopmoc lanoitidda yb dedivorp eb tsum sgol reniatnoc eht lla fo sisylana dna egarots dezilartnec a gnidivorp rof yrassecen stnenopmoc ehT .gniggol dezilartnec fo dnik yna edivorp tnseod flesti yb setenrebuK\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".noitacol lartnec a ni derots )yltnenamrep( dna detcelloc era sgol ruoy lla os ,noitulos gniggol ediw-retsulc ,dezilartnec a esu ot tnaw lluoy ,metsys noitcudorp a nI\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"In a production system, youll want to use a centralized, cluster-wide logging solution, so all your logs are collected and (permanently) stored in a central location.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Kubernetes by itself doesnt provide any kind of centralized logging. The components necessary for providing a centralized storage and analysis of all the container logs must be provided by additional components,\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When using the EFK stack for centralized logging, each Kubernetes cluster node runs a FluentD agent (usually as a pod deployed through a DaemonSet), which is responsible for gathering the logs from the containers,\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"ElasticSearch is also deployed as a pod somewhere in the cluster. The logs can then be viewed and analyzed in a web browser through Kibana, which is a web tool for visualizing ElasticSearch data.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You may have already heard of the ELK stack composed of ElasticSearch, Logstash, and Kibana. A slightly modified variation is the EFK stack, where Logstash is replaced with FluentD.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:444\n",
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"The FluentD agent stores each line of the log file as an entry in the ElasticSearch data store, but this can cause issues with multiline log statements.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Outputting JSON logs instead of plain text can help solve the problem of multiline log statements being stored and shown as separate entries in the centralized logging system.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"It's not necessary to run apps in Kubernetes during development, and you can develop and run them on your local machine or IDE without needing a container.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"You can set environment variables on your local machine to connect to backend services, regardless of whether they're running inside or outside a Kubernetes cluster.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Configuring the node-level FluentD agent or adding a logging sidecar container to every pod is required to process JSON logs and keep outputting human-readable logs to standard output.\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\".tuptuo dradnats ot sgol elbadaer-namuh gnittuptuo peek dna sgol NOSJ ssecorp ot deriuqer si dop yreve ot reniatnoc racedis gniggol a gnidda ro tnega DtneulF level-edon eht gnirugifnoC\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".retsulc setenrebuK a edistuo ro edisni gninnur er'yeht rehtehw fo sseldrager ,secivres dnekcab ot tcennoc ot enihcam lacol ruoy no selbairav tnemnorivne tes nac uoY\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".reniatnoc a gnideen tuohtiw EDI ro enihcam lacol ruoy no meht nur dna poleved nac uoy dna ,tnempoleved gnirud setenrebuK ni sppa nur ot yrassecen ton s'tI\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".metsys gniggol dezilartnec eht ni seirtne etarapes sa nwohs dna derots gnieb stnemetats gol enilitlum fo melborp eht evlos pleh nac txet nialp fo daetsni sgol NOSJ gnittuptuO\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".stnemetats gol enilitlum htiw seussi esuac nac siht tub ,erots atad hcraeScitsalE eht ni yrtne na sa elif gol eht fo enil hcae serots tnega DtneulF ehT\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"The FluentD agent stores each line of the log file as an entry in the ElasticSearch data store, but this can cause issues with multiline log statements.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Outputting JSON logs instead of plain text can help solve the problem of multiline log statements being stored and shown as separate entries in the centralized logging system.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"It's not necessary to run apps in Kubernetes during development, and you can develop and run them on your local machine or IDE without needing a container.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"You can set environment variables on your local machine to connect to backend services, regardless of whether they're running inside or outside a Kubernetes cluster.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Configuring the node-level FluentD agent or adding a logging sidecar container to every pod is required to process JSON logs and keep outputting human-readable logs to standard output.\"\n",
      "  }\n",
      "]\n",
      "Done for page number:445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "Here are the 5 most important highlights extracted from the document page:\n",
      "\n",
      "```\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"You can easily talk to the Kubernetes API server from outside the cluster during development using the ServiceAccount's token or an ambassador container.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When developing with Minikube, you can mount your local filesystem into the Minikube VM and then into your containers through a hostPath volume.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can use the Docker daemon inside the Minikube VM to build your container image after every change instead of building it locally.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Running your app in a container during development doesn't require rebuilding the image every time, you can mount your local filesystem into the container through Docker volumes.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Minikube is a valuable method for trying out your app in Kubernetes and developing resource manifests without requiring a proper multi-node cluster.\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Reversed JSON OUTPUT:\n",
      "```\n",
      "]\n",
      "}    \n",
      "\".retsulc edon-itlum reporp a gniriuqer tuohtiw stsefinam ecruoser gnipoleved dna setenrebuK ni ppa ruoy tuo gniyrt rof dohtem elbaulav a si ebukiniM\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".semulov rekcoD hguorht reniatnoc eht otni metsyselif lacol ruoy tnuom nac uoy ,emit yreve egami eht gnidliuber eriuqer t'nseod tnempoleved gnirud reniatnoc a ni ppa ruoy gninnuR\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".yllacol ti gnidliub fo daetsni egnahc yreve retfa egami reniatnoc ruoy dliub ot MV ebukiniM eht edisni nomead rekcoD eht esu nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".emulov htaPtsoh a hguorht sreniatnoc ruoy otni neht dna MV ebukiniM eht otni metsyselif lacol ruoy tnuom nac uoy ,ebukiniM htiw gnipoleved nehW\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".reniatnoc rodassabma na ro nekot s'tnuoccAecivreS eht gnisu tnempoleved gnirud retsulc eht edistuo morf revres IPA setenrebuK eht ot klat ylisae nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"You can easily talk to the Kubernetes API server from outside the cluster during development using the ServiceAccount's token or an ambassador container.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When developing with Minikube, you can mount your local filesystem into the Minikube VM and then into your containers through a hostPath volume.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can use the Docker daemon inside the Minikube VM to build your container image after every change instead of building it locally.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Running your app in a container during development doesn't require rebuilding the image every time, you can mount your local filesystem into the container through Docker volumes.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Minikube is a valuable method for trying out your app in Kubernetes and developing resource manifests without requiring a proper multi-node cluster.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:446\n",
      "Raw Output\n",
      "Here are the 5 most important and informative highlights extracted from the document page:\n",
      "\n",
      "```\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To use Minikube's Docker daemon, set the DOCKER_HOST environment variable by running eval $(minikube docker-env) on your local machine.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can build images locally and copy them over to the Minikube VM using the command $ docker save <image> | (eval $(minikube docker-env) && docker load).\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When combining Minikube with a proper Kubernetes cluster, you can develop apps in your local Minikube cluster and have them talk to workloads deployed in a remote multi-node cluster.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Kubernetes uses a declarative model, where you tell the system your desired state and it takes necessary actions to reconcile the cluster state with the desired state.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can store resource manifests in a Version Control System, enabling code reviews, audit trails, and rolling back changes as needed, and apply changes using kubectl apply command after each commit.\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Reversed JSON OUTPUT:\n",
      "```\n",
      "]\n",
      "}    \n",
      "\".timmoc hcae retfa dnammoc ylppa ltcebuk gnisu segnahc ylppa dna ,dedeen sa segnahc kcab gnillor dna ,sliart tidua ,sweiver edoc gnilbane ,metsyS lortnoC noisreV a ni stsefinam ecruoser erots nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".etats derised eht htiw etats retsulc eht elicnocer ot snoitca yrassecen sekat ti dna etats derised ruoy metsys eht llet uoy erehw ,ledom evitaralced a sesu setenrebuK\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".retsulc edon-itlum etomer a ni deyolped sdaolkrow ot klat meht evah dna retsulc ebukiniM lacol ruoy ni sppa poleved nac uoy ,retsulc setenrebuK reporp a htiw ebukiniM gninibmoc nehW\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".)daol rekcod && )vne-rekcod ebukinim($ lave( | >egami< evas rekcod $ dnammoc eht gnisu MV ebukiniM eht ot revo meht ypoc dna yllacol segami dliub nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".enihcam lacol ruoy no )vne-rekcod ebukinim($ lave gninnur yb elbairav tnemnorivne TSOH_REKCOD eht tes ,nomead rekcoD s'ebukiniM esu oT\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To use Minikube's Docker daemon, set the DOCKER_HOST environment variable by running eval $(minikube docker-env) on your local machine.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can build images locally and copy them over to the Minikube VM using the command $ docker save <image> | (eval $(minikube docker-env) && docker load).\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When combining Minikube with a proper Kubernetes cluster, you can develop apps in your local Minikube cluster and have them talk to workloads deployed in a remote multi-node cluster.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Kubernetes uses a declarative model, where you tell the system your desired state and it takes necessary actions to reconcile the cluster state with the desired state.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can store resource manifests in a Version Control System, enabling code reviews, audit trails, and rolling back changes as needed, and apply changes using kubectl apply command after each commit.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:447\n",
      "Raw Output\n",
      "Here are the 5 most important and informative highlights extracted from the document page, wrapped in JSON with the key \"highlight\":\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"You can manage your running apps simply by committing changes to the VCS without having to manually talk to the Kubernetes API server.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Ksonnet is a library built on top of Jsonnet that allows you to define parameterized JSON fragments, giving you much less code to write when building Kubernetes resource manifests.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can use multiple branches to deploy the manifests to a development, QA, staging, and production cluster (or in different namespaces in the same cluster).\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Ksonnet defines fragments you'd find in Kubernetes resource manifests, allowing you to quickly build a complete Kubernetes resource JSON manifest with much less code.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The kubia.ksonnet file is converted to a full JSON Deployment manifest when you run the command $ jsonnet kubia.ksonnet\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\"tennosk.aibuk tennosj $ dnammoc eht nur uoy nehw tsefinam tnemyolpeD NOSJ lluf a ot detrevnoc si elif tennosk.aibuk ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".edoc ssel hcum htiw tsefinam NOSJ ecruoser setenrebuK etelpmoc a dliub ylkciuq ot uoy gniwolla ,stsefinam ecruoser setenrebuK ni dnif d'uoy stnemgarf senifed tennosK\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".)retsulc emas eht ni secapseman tnereffid ni ro( retsulc noitcudorp dna ,gnigats ,AQ ,tnempoleved a ot stsefinam eht yolped ot sehcnarb elpitlum esu nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".stsefinam ecruoser setenrebuK gnidliub nehw etirw ot edoc ssel hcum uoy gnivig ,stnemgarf NOSJ deziretemarap enifed ot uoy swolla taht tennosJ fo pot no tliub yrarbil a si tennosK\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".revres IPA setenrebuK eht ot klat yllaunam ot gnivah tuohtiw SCV eht ot segnahc gnittimmoc yb ylpmis sppa gninnur ruoy eganam nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"You can manage your running apps simply by committing changes to the VCS without having to manually talk to the Kubernetes API server.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Ksonnet is a library built on top of Jsonnet that allows you to define parameterized JSON fragments, giving you much less code to write when building Kubernetes resource manifests.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can use multiple branches to deploy the manifests to a development, QA, staging, and production cluster (or in different namespaces in the same cluster).\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Ksonnet defines fragments you'd find in Kubernetes resource manifests, allowing you to quickly build a complete Kubernetes resource JSON manifest with much less code.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The kubia.ksonnet file is converted to a full JSON Deployment manifest when you run the command $ jsonnet kubia.ksonnet\"\n",
      "    }\n",
      "]\n",
      "Done for page number:448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"The power of Ksonnet and Jsonnet becomes apparent when you can define your own higher-level fragments and make all your manifests consistent and duplication-free.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Employing Continuous Integration and Continuous Delivery (CI/CD) is essential for building application binaries, container images, and resource manifests and then deploying them in one or more Kubernetes clusters.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"The Fabric8 project (http://fabric8.io) is an integrated development platform for Kubernetes that includes Jenkins and various other tools to deliver a full CI/CD pipeline for DevOps-style development, deployment, and management of microservices on Kubernetes.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Init containers can be used to initialize a pod or delay the start of the pod's main containers until a precondition is met.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Container lifecycle hooks can be used to make your apps shut down properly without breaking client connections, and understanding their consequences is essential for Kubernetes development.\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\".tnempoleved setenrebuK rof laitnesse si secneuqesnoc rieht gnidnatsrednu dna ,snoitcennoc tneilc gnikaerb tuohtiw ylreporp nwod tuhs sppa ruoy ekam ot desu eb nac skooh elcycefil reniatnoC\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".tem si noitidnocerp a litnu sreniatnoc niam s'dop eht fo trats eht yaled ro dop a ezilaitini ot desu eb nac sreniatnoc tinI\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".setenrebuK no secivresorcim fo tnemeganam dna ,tnemyolped ,tnempoleved elyts-spOveD rof enilepip DC/IC lluf a reviled ot sloot rehto suoirav dna snikneJ sedulcni taht setenrebuK rof mroftalp tnempoleved detargetni na si )oi.8cirbaf//:ptth( tcejorp 8cirbaF ehT\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".sretsulc setenrebuK erom ro eno ni meht gniyolped neht dna stsefinam ecruoser dna ,segami reniatnoc ,seiranib noitacilppa gnidliub rof laitnesse si )DC/IC( yrevileD suounitnoC dna noitargetnI suounitnoC gniyolpmE\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".eerf-noitacilpud dna tnetsisnoc stsefinam ruoy lla ekam dna stnemgarf level-rehgih nwo ruoy enifed nac uoy nehw tnerappa semoceb tennosJ dna tennosK fo rewop ehT\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"The power of Ksonnet and Jsonnet becomes apparent when you can define your own higher-level fragments and make all your manifests consistent and duplication-free.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Employing Continuous Integration and Continuous Delivery (CI/CD) is essential for building application binaries, container images, and resource manifests and then deploying them in one or more Kubernetes clusters.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"The Fabric8 project (http://fabric8.io) is an integrated development platform for Kubernetes that includes Jenkins and various other tools to deliver a full CI/CD pipeline for DevOps-style development, deployment, and management of microservices on Kubernetes.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Init containers can be used to initialize a pod or delay the start of the pod's main containers until a precondition is met.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Container lifecycle hooks can be used to make your apps shut down properly without breaking client connections, and understanding their consequences is essential for Kubernetes development.\"\n",
      "  }\n",
      "]\n",
      "Done for page number:449\n",
      "Raw Output\n",
      "Here are the 5 most important highlights extracted from the document page in JSON format:\n",
      "\n",
      "[{\"highlight\": \"Keeping image sizes small can make apps easier to manage.\"}, {\"highlight\": \"Adding annotations and multi-dimensional labels to resources is essential for app management.\"}, {\"highlight\": \"Developing Kubernetes apps locally or in Minikube before deployment is crucial.\"}, {\"highlight\": \"Extending Kubernetes with custom API objects and controllers is possible.\"}, {\"highlight\": \"Creating Platform-as-a-Service solutions on top of Kubernetes is achievable.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".elbaveihca si setenrebuK fo pot no snoitulos ecivreS-a-sa-mroftalP gnitaerC\" :\"thgilhgih\"{ ,}\".elbissop si srellortnoc dna stcejbo IPA motsuc htiw setenrebuK gnidnetxE\" :\"thgilhgih\"{ ,}\".laicurc si tnemyolped erofeb ebukiniM ni ro yllacol sppa setenrebuK gnipoleveD\" :\"thgilhgih\"{ ,}\".tnemeganam ppa rof laitnesse si secruoser ot slebal lanoisnemid-itlum dna snoitatonna gniddA\" :\"thgilhgih\"{ ,}\".eganam ot reisae sppa ekam nac llams sezis egami gnipeeK\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"Keeping image sizes small can make apps easier to manage.\"}, {\"highlight\": \"Adding annotations and multi-dimensional labels to resources is essential for app management.\"}, {\"highlight\": \"Developing Kubernetes apps locally or in Minikube before deployment is crucial.\"}, {\"highlight\": \"Extending Kubernetes with custom API objects and controllers is possible.\"}, {\"highlight\": \"Creating Platform-as-a-Service solutions on top of Kubernetes is achievable.\"}]\n",
      "Done for page number:450\n",
      "Raw Output\n",
      "Here are the 5 most important highlights extracted from the document page:\n",
      "\n",
      "[{\"highlight\": \"Defining custom API objects is covered in this chapter, including adding custom objects to Kubernetes, creating a controller for the custom object, and adding custom API servers.\"}]\n",
      "\n",
      "[{\"highlight\": \"Kubernetes users mostly use only generic API objects provided by Kubernetes, despite them representing low-level concepts.\"}]\n",
      "\n",
      "[{\"highlight\": \"The Service Catalog feature of Kubernetes enables self-provisioning of services with a catalog-based approach.\"}]\n",
      "\n",
      "[{\"highlight\": \"Red Hat's OpenShift Container Platform and Deis Workflow are examples of Platform-as-a-Service solutions built on top of Kubernetes.\"}]\n",
      "\n",
      "[{\"highlight\": \"Helm is another example of a tool that has been used to extend Kubernetes and build PaaS solutions, along with Red Hat's OpenShift Container Platform and Deis Workflow.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "\n",
      "\n",
      "]}\".srevres IPA motsuc gnidda dna ,tcejbo motsuc eht rof rellortnoc a gnitaerc ,setenrebuK ot stcejbo motsuc gnidda gnidulcni ,retpahc siht ni derevoc si stcejbo IPA motsuc gninifeD\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"Defining custom API objects is covered in this chapter, including adding custom objects to Kubernetes, creating a controller for the custom object, and adding custom API servers.\"}]\n",
      "Done for page number:451\n",
      "Raw Output\n",
      "[{\"highlight\": \"Custom API objects will be high-level objects that represent whole applications or software services.\"}, \n",
      " {\"highlight\": \"A custom controller will observe those high-level objects and create low-level objects based on them.\"}, \n",
      " {\"highlight\": \"To define a new resource type, all you need to do is post a CustomResourceDefinition object (CRD) to the Kubernetes API server.\"}, \n",
      " {\"highlight\": \"Each CRD will usually also have an associated controller, which does something tangible happen in the cluster.\"}, \n",
      " {\"highlight\": \"Users can create objects of the new type by posting JSON or YAML manifests to the API server.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".revres IPA eht ot stsefinam LMAY ro NOSJ gnitsop yb epyt wen eht fo stcejbo etaerc nac sresU\" :\"thgilhgih\"{ \n",
      " ,}\".retsulc eht ni neppah elbignat gnihtemos seod hcihw ,rellortnoc detaicossa na evah osla yllausu lliw DRC hcaE\" :\"thgilhgih\"{ \n",
      " ,}\".revres IPA setenrebuK eht ot )DRC( tcejbo noitinifeDecruoseRmotsuC a tsop si od ot deen uoy lla ,epyt ecruoser wen a enifed oT\" :\"thgilhgih\"{ \n",
      " ,}\".meht no desab stcejbo level-wol etaerc dna stcejbo level-hgih esoht evresbo lliw rellortnoc motsuc A\" :\"thgilhgih\"{ \n",
      " ,}\".secivres erawtfos ro snoitacilppa elohw tneserper taht stcejbo level-hgih eb lliw stcejbo IPA motsuC\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"Custom API objects will be high-level objects that represent whole applications or software services.\"}, \n",
      " {\"highlight\": \"A custom controller will observe those high-level objects and create low-level objects based on them.\"}, \n",
      " {\"highlight\": \"To define a new resource type, all you need to do is post a CustomResourceDefinition object (CRD) to the Kubernetes API server.\"}, \n",
      " {\"highlight\": \"Each CRD will usually also have an associated controller, which does something tangible happen in the cluster.\"}, \n",
      " {\"highlight\": \"Users can create objects of the new type by posting JSON or YAML manifests to the API server.\"}]\n",
      "Done for page number:452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"To make Kubernetes accept your custom Website resource instances, you need to post the CustomResourceDefinition shown in the following listing to the API server.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"A custom object kind The name of the website (used for naming the resulting Service and Pod) The Git repository holding the websites files\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"CustomResourceDefinitions belong to this API group and version. The full name of your custom object You want Website resources to be namespaced.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Each Website object should result in the creation of a Service and an HTTP server Pod.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"If you try posting this resource to Kubernetes, youll receive an error because Kubernetes doesnt know what a Website object is yet:\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\":tey si tcejbo etisbeW a tahw wonk tnseod setenrebuK esuaceb rorre na eviecer lluoy ,setenrebuK ot ecruoser siht gnitsop yrt uoy fI\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".doP revres PTTH na dna ecivreS a fo noitaerc eht ni tluser dluohs tcejbo etisbeW hcaE\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".decapseman eb ot secruoser etisbeW tnaw uoY tcejbo motsuc ruoy fo eman lluf ehT .noisrev dna puorg IPA siht ot gnoleb snoitinifeDecruoseRmotsuC\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\"selif setisbew eht gnidloh yrotisoper tiG ehT )doP dna ecivreS gnitluser eht gniman rof desu( etisbew eht fo eman ehT dnik tcejbo motsuc A\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".revres IPA eht ot gnitsil gniwollof eht ni nwohs noitinifeDecruoseRmotsuC eht tsop ot deen uoy ,secnatsni ecruoser etisbeW motsuc ruoy tpecca setenrebuK ekam oT\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"To make Kubernetes accept your custom Website resource instances, you need to post the CustomResourceDefinition shown in the following listing to the API server.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"A custom object kind The name of the website (used for naming the resulting Service and Pod) The Git repository holding the websites files\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"CustomResourceDefinitions belong to this API group and version. The full name of your custom object You want Website resources to be namespaced.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Each Website object should result in the creation of a Service and an HTTP server Pod.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"If you try posting this resource to Kubernetes, youll receive an error because Kubernetes doesnt know what a Website object is yet:\"\n",
      "  }\n",
      "]\n",
      "Done for page number:453\n",
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"To create a custom API object, you must define its group, version, and names in the CustomResourceDefinition (CRD).\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"The CRD's long name is used to prevent name clashes, but you can use the shorter 'kind' property when creating instances of the custom resource.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"When creating an instance of a custom resource, you must set the 'apiVersion' property to the API group and version number defined in the CRD.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"You can create a custom Website resource by defining its API group, version, and names in the CustomResourceDefinition (CRD).\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"To create an instance of a custom Website resource, you must specify its 'kind' as 'Website' and set the 'apiVersion' to the API group and version number defined in the CRD.\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\".DRC eht ni denifed rebmun noisrev dna puorg IPA eht ot 'noisreVipa' eht tes dna 'etisbeW' sa 'dnik' sti yficeps tsum uoy ,ecruoser etisbeW motsuc a fo ecnatsni na etaerc oT\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".)DRC( noitinifeDecruoseRmotsuC eht ni seman dna ,noisrev ,puorg IPA sti gninifed yb ecruoser etisbeW motsuc a etaerc nac uoY\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".DRC eht ni denifed rebmun noisrev dna puorg IPA eht ot ytreporp 'noisreVipa' eht tes tsum uoy ,ecruoser motsuc a fo ecnatsni na gnitaerc nehW\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".ecruoser motsuc eht fo secnatsni gnitaerc nehw ytreporp 'dnik' retrohs eht esu nac uoy tub ,sehsalc eman tneverp ot desu si eman gnol s'DRC ehT\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".)DRC( noitinifeDecruoseRmotsuC eht ni seman dna ,noisrev ,puorg sti enifed tsum uoy ,tcejbo IPA motsuc a etaerc oT\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"To create a custom API object, you must define its group, version, and names in the CustomResourceDefinition (CRD).\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"The CRD's long name is used to prevent name clashes, but you can use the shorter 'kind' property when creating instances of the custom resource.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"When creating an instance of a custom resource, you must set the 'apiVersion' property to the API group and version number defined in the CRD.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"You can create a custom Website resource by defining its API group, version, and names in the CustomResourceDefinition (CRD).\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"To create an instance of a custom Website resource, you must specify its 'kind' as 'Website' and set the 'apiVersion' to the API group and version number defined in the CRD.\"\n",
      "  }\n",
      "]\n",
      "Done for page number:454\n",
      "Raw Output\n",
      "[{\"highlight\": \"You can list all websites in your cluster using kubectl get websites command.\"}, {\"highlight\": \"The custom object includes additional metadata fields initialized by Kubernetes, such as creationTimestamp and resourceVersion.\"}, {\"highlight\": \"You can delete an instance of a custom object using kubectl delete website <name> command.\"}, {\"highlight\": \"Deleting a custom object instance does not affect the CustomResourceDefinition (CRD) itself.\"}, {\"highlight\": \"Custom objects do not have any functionality yet, and you need to create a controller to make them do something.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".gnihtemos od meht ekam ot rellortnoc a etaerc ot deen uoy dna ,tey ytilanoitcnuf yna evah ton od stcejbo motsuC\" :\"thgilhgih\"{ ,}\".flesti )DRC( noitinifeDecruoseRmotsuC eht tceffa ton seod ecnatsni tcejbo motsuc a gniteleD\" :\"thgilhgih\"{ ,}\".dnammoc >eman< etisbew eteled ltcebuk gnisu tcejbo motsuc a fo ecnatsni na eteled nac uoY\" :\"thgilhgih\"{ ,}\".noisreVecruoser dna pmatsemiTnoitaerc sa hcus ,setenrebuK yb dezilaitini sdleif atadatem lanoitidda sedulcni tcejbo motsuc ehT\" :\"thgilhgih\"{ ,}\".dnammoc setisbew teg ltcebuk gnisu retsulc ruoy ni setisbew lla tsil nac uoY\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"You can list all websites in your cluster using kubectl get websites command.\"}, {\"highlight\": \"The custom object includes additional metadata fields initialized by Kubernetes, such as creationTimestamp and resourceVersion.\"}, {\"highlight\": \"You can delete an instance of a custom object using kubectl delete website <name> command.\"}, {\"highlight\": \"Deleting a custom object instance does not affect the CustomResourceDefinition (CRD) itself.\"}, {\"highlight\": \"Custom objects do not have any functionality yet, and you need to create a controller to make them do something.\"}]\n",
      "Done for page number:455\n",
      "Raw Output\n",
      "Here are the extracted highlights in JSON format, collated into a list:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"Custom API objects can be used to store data instead of using a more generic mechanism such as a ConfigMap.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The existence of a Website object can result in the spinning up of a web server serving the contents of the Git repository referenced in the object.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A custom controller, called a Website controller, is needed to automate the creation of a Service and a web server Pod for each Website object.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The controller creates a Deployment resource instead of an unmanaged Pod directly to ensure the Pod survives node failures.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A simple initial version of the Website controller is available at docker.io/luksa/website-controller:latest, with source code at https://github.com/luksa/k8s-website-controller.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".rellortnoc-etisbew-s8k/askul/moc.buhtig//:sptth ta edoc ecruos htiw ,tsetal:rellortnoc-etisbew/askul/oi.rekcod ta elbaliava si rellortnoc etisbeW eht fo noisrev laitini elpmis A\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".seruliaf edon sevivrus doP eht erusne ot yltcerid doP deganamnu na fo daetsni ecruoser tnemyolpeD a setaerc rellortnoc ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".tcejbo etisbeW hcae rof doP revres bew a dna ecivreS a fo noitaerc eht etamotua ot dedeen si ,rellortnoc etisbeW a dellac ,rellortnoc motsuc A\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".tcejbo eht ni decnerefer yrotisoper tiG eht fo stnetnoc eht gnivres revres bew a fo pu gninnips eht ni tluser nac tcejbo etisbeW a fo ecnetsixe ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".paMgifnoC a sa hcus msinahcem cireneg erom a gnisu fo daetsni atad erots ot desu eb nac stcejbo IPA motsuC\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"Custom API objects can be used to store data instead of using a more generic mechanism such as a ConfigMap.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The existence of a Website object can result in the spinning up of a web server serving the contents of the Git repository referenced in the object.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A custom controller, called a Website controller, is needed to automate the creation of a Service and a web server Pod for each Website object.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The controller creates a Deployment resource instead of an unmanaged Pod directly to ensure the Pod survives node failures.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A simple initial version of the Website controller is available at docker.io/luksa/website-controller:latest, with source code at https://github.com/luksa/k8s-website-controller.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[{\"highlight\": \"The Kubernetes website controller starts watching Website objects by requesting the URL http://localhost:8001/apis/extensions.example.com/v1/websites?watch=true immediately upon startup.\"}, {\"highlight\": \"The API server sends watch events for every change to any Website object, including an ADDED event when a new Website object is created.\"}, {\"highlight\": \"The website controller extracts the Website's name and Git repository URL from the watch event and creates a Deployment and Service object by posting their JSON manifests to the API server.\"}, {\"highlight\": \"The Deployment resource contains a template for a pod with two containers: one running an nginx server and another running a git-sync process, which keeps a local directory synced with a Git repo.\"}, {\"highlight\": \"A NodePort Service exposes the web server pod through a random port on each node, allowing clients to access the website through the node port.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".trop edon eht hguorht etisbew eht ssecca ot stneilc gniwolla ,edon hcae no trop modnar a hguorht dop revres bew eht sesopxe ecivreS troPedoN A\" :\"thgilhgih\"{ ,}\".oper tiG a htiw decnys yrotcerid lacol a speek hcihw ,ssecorp cnys-tig a gninnur rehtona dna revres xnign na gninnur eno :sreniatnoc owt htiw dop a rof etalpmet a sniatnoc ecruoser tnemyolpeD ehT\" :\"thgilhgih\"{ ,}\".revres IPA eht ot stsefinam NOSJ rieht gnitsop yb tcejbo ecivreS dna tnemyolpeD a setaerc dna tneve hctaw eht morf LRU yrotisoper tiG dna eman s'etisbeW eht stcartxe rellortnoc etisbew ehT\" :\"thgilhgih\"{ ,}\".detaerc si tcejbo etisbeW wen a nehw tneve DEDDA na gnidulcni ,tcejbo etisbeW yna ot egnahc yreve rof stneve hctaw sdnes revres IPA ehT\" :\"thgilhgih\"{ ,}\".putrats nopu yletaidemmi eurt=hctaw?setisbew/1v/moc.elpmaxe.snoisnetxe/sipa/1008:tsohlacol//:ptth LRU eht gnitseuqer yb stcejbo etisbeW gnihctaw strats rellortnoc etisbew setenrebuK ehT\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"The Kubernetes website controller starts watching Website objects by requesting the URL http://localhost:8001/apis/extensions.example.com/v1/websites?watch=true immediately upon startup.\"}, {\"highlight\": \"The API server sends watch events for every change to any Website object, including an ADDED event when a new Website object is created.\"}, {\"highlight\": \"The website controller extracts the Website's name and Git repository URL from the watch event and creates a Deployment and Service object by posting their JSON manifests to the API server.\"}, {\"highlight\": \"The Deployment resource contains a template for a pod with two containers: one running an nginx server and another running a git-sync process, which keeps a local directory synced with a Git repo.\"}, {\"highlight\": \"A NodePort Service exposes the web server pod through a random port on each node, allowing clients to access the website through the node port.\"}]\n",
      "Done for page number:457\n",
      "Raw Output\n",
      "[{\"highlight\": \"The API server sends a DELETED watch event when a Website resource instance is deleted, triggering the controller to delete associated Deployment and Service resources.\"}, {\"highlight\": \"A custom controller should periodically re-list all objects in case any watch events were missed for proper object watching through the API server.\"}, {\"highlight\": \"Running the controller inside Kubernetes itself is the best way to deploy it into production, using a Deployment resource.\"}, {\"highlight\": \"The controller can be deployed through a Deployment resource, such as shown in Listing 18.5.\"}, {\"highlight\": \"A single replica of the controller should be run, serving the website specified in the Website object.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".tcejbo etisbeW eht ni deificeps etisbew eht gnivres ,nur eb dluohs rellortnoc eht fo acilper elgnis A\" :\"thgilhgih\"{ ,}\".5.81 gnitsiL ni nwohs sa hcus ,ecruoser tnemyolpeD a hguorht deyolped eb nac rellortnoc ehT\" :\"thgilhgih\"{ ,}\".ecruoser tnemyolpeD a gnisu ,noitcudorp otni ti yolped ot yaw tseb eht si flesti setenrebuK edisni rellortnoc eht gninnuR\" :\"thgilhgih\"{ ,}\".revres IPA eht hguorht gnihctaw tcejbo reporp rof dessim erew stneve hctaw yna esac ni stcejbo lla tsil-er yllacidoirep dluohs rellortnoc motsuc A\" :\"thgilhgih\"{ ,}\".secruoser ecivreS dna tnemyolpeD detaicossa eteled ot rellortnoc eht gnireggirt ,deteled si ecnatsni ecruoser etisbeW a nehw tneve hctaw DETELED a sdnes revres IPA ehT\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"The API server sends a DELETED watch event when a Website resource instance is deleted, triggering the controller to delete associated Deployment and Service resources.\"}, {\"highlight\": \"A custom controller should periodically re-list all objects in case any watch events were missed for proper object watching through the API server.\"}, {\"highlight\": \"Running the controller inside Kubernetes itself is the best way to deploy it into production, using a Deployment resource.\"}, {\"highlight\": \"The controller can be deployed through a Deployment resource, such as shown in Listing 18.5.\"}, {\"highlight\": \"A single replica of the controller should be run, serving the website specified in the Website object.\"}]\n",
      "Done for page number:458\n",
      "Raw Output\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To deploy the website-controller, you need to create a ServiceAccount with the name 'website-controller' using the command $ kubectl create serviceaccount website-controller\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"If Role Based Access Control (RBAC) is enabled in your cluster, Kubernetes will not allow the controller to watch Website resources or create Deployments or Services.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You need to bind the website-controller ServiceAccount to the cluster-admin ClusterRole by creating a ClusterRoleBinding like this: $ kubectl create clusterrolebinding website-controller --clusterrole=cluster-admin --serviceaccount=default:website-controller\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The controller's Deployment deploys a single replica of a two-container pod, one container runs your controller and the other is the ambassador container used for simpler communication with the API server.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can check the controller's logs to see if it has received the watch event by running $ kubectl logs website-controller-2429717411-q43zs -c main\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\"niam c- sz34q-1147179242-rellortnoc-etisbew sgol ltcebuk $ gninnur yb tneve hctaw eht deviecer sah ti fi ees ot sgol s'rellortnoc eht kcehc nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".revres IPA eht htiw noitacinummoc relpmis rof desu reniatnoc rodassabma eht si rehto eht dna rellortnoc ruoy snur reniatnoc eno ,dop reniatnoc-owt a fo acilper elgnis a syolped tnemyolpeD s'rellortnoc ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\"rellortnoc-etisbew:tluafed=tnuoccaecivres-- nimda-retsulc=elorretsulc-- rellortnoc-etisbew gnidnibelorretsulc etaerc ltcebuk $ :siht ekil gnidniBeloRretsulC a gnitaerc yb eloRretsulC nimda-retsulc eht ot tnuoccAecivreS rellortnoc-etisbew eht dnib ot deen uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".secivreS ro stnemyolpeD etaerc ro secruoser etisbeW hctaw ot rellortnoc eht wolla ton lliw setenrebuK ,retsulc ruoy ni delbane si )CABR( lortnoC sseccA desaB eloR fI\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\"rellortnoc-etisbew tnuoccaecivres etaerc ltcebuk $ dnammoc eht gnisu 'rellortnoc-etisbew' eman eht htiw tnuoccAecivreS a etaerc ot deen uoy ,rellortnoc-etisbew eht yolped oT\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To deploy the website-controller, you need to create a ServiceAccount with the name 'website-controller' using the command $ kubectl create serviceaccount website-controller\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"If Role Based Access Control (RBAC) is enabled in your cluster, Kubernetes will not allow the controller to watch Website resources or create Deployments or Services.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You need to bind the website-controller ServiceAccount to the cluster-admin ClusterRole by creating a ClusterRoleBinding like this: $ kubectl create clusterrolebinding website-controller --clusterrole=cluster-admin --serviceaccount=default:website-controller\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The controller's Deployment deploys a single replica of a two-container pod, one container runs your controller and the other is the ambassador container used for simpler communication with the API server.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can check the controller's logs to see if it has received the watch event by running $ kubectl logs website-controller-2429717411-q43zs -c main\"\n",
      "    }\n",
      "]\n",
      "Done for page number:459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"The controller received the ADDED event and created a Service and a Deployment for the kubia-website Website.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Users of your Kubernetes cluster can now deploy static websites in seconds, without knowing anything about Pods, Services, or any other Kubernetes resources, except your custom Website resource.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The API server doesn't validate the contents of the YAML (except the usual fields like apiVersion, kind, and metadata), so users can create invalid Website objects.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can access the kubia-website Service through port 32589 on all cluster nodes with your browser.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The controller could watch for Service objects and write the URL the website is accessible at into the status section of the Website resource instance itself.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".flesti ecnatsni ecruoser etisbeW eht fo noitces sutats eht otni ta elbissecca si etisbew eht LRU eht etirw dna stcejbo ecivreS rof hctaw dluoc rellortnoc ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".resworb ruoy htiw sedon retsulc lla no 98523 trop hguorht ecivreS etisbew-aibuk eht ssecca nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".stcejbo etisbeW dilavni etaerc nac sresu os ,)atadatem dna ,dnik ,noisreVipa ekil sdleif lausu eht tpecxe( LMAY eht fo stnetnoc eht etadilav t'nseod revres IPA ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ecruoser etisbeW motsuc ruoy tpecxe ,secruoser setenrebuK rehto yna ro ,secivreS ,sdoP tuoba gnihtyna gniwonk tuohtiw ,sdnoces ni setisbew citats yolped won nac retsulc setenrebuK ruoy fo sresU\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".etisbeW etisbew-aibuk eht rof tnemyolpeD a dna ecivreS a detaerc dna tneve DEDDA eht deviecer rellortnoc ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"The controller received the ADDED event and created a Service and a Deployment for the kubia-website Website.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Users of your Kubernetes cluster can now deploy static websites in seconds, without knowing anything about Pods, Services, or any other Kubernetes resources, except your custom Website resource.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The API server doesn't validate the contents of the YAML (except the usual fields like apiVersion, kind, and metadata), so users can create invalid Website objects.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can access the kubia-website Service through port 32589 on all cluster nodes with your browser.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The controller could watch for Service objects and write the URL the website is accessible at into the status section of the Website resource instance itself.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:460\n",
      "Raw Output\n",
      "[{\"highlight\": \"Kubernetes version 1.8 introduced validation of custom objects as an alpha feature.\"}, \n",
      " {\"highlight\": \"To enable CustomResourceValidation, you need to specify a JSON schema in the CRD and enable the CustomResourceValidation feature gate in the API server.\"}, \n",
      " {\"highlight\": \"API server aggregation allows integrating multiple API servers at a single location, enabling clients to connect to the aggregated API without knowing about multiple servers handling different objects.\"}, \n",
      " {\"highlight\": \"Each API server is responsible for storing its own resources and can run its own instance of etcd or use CustomResourceDefinitions in the main API server as storage mechanism.\"}, \n",
      " {\"highlight\": \"Implementing a custom API server allows validating custom objects directly without creating a CRD, enabling more control over object validation and storage.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".egarots dna noitadilav tcejbo revo lortnoc erom gnilbane ,DRC a gnitaerc tuohtiw yltcerid stcejbo motsuc gnitadilav swolla revres IPA motsuc a gnitnemelpmI\" :\"thgilhgih\"{ \n",
      " ,}\".msinahcem egarots sa revres IPA niam eht ni snoitinifeDecruoseRmotsuC esu ro dcte fo ecnatsni nwo sti nur nac dna secruoser nwo sti gnirots rof elbisnopser si revres IPA hcaE\" :\"thgilhgih\"{ \n",
      " ,}\".stcejbo tnereffid gnildnah srevres elpitlum tuoba gniwonk tuohtiw IPA detagergga eht ot tcennoc ot stneilc gnilbane ,noitacol elgnis a ta srevres IPA elpitlum gnitargetni swolla noitagergga revres IPA\" :\"thgilhgih\"{ \n",
      " ,}\".revres IPA eht ni etag erutaef noitadilaVecruoseRmotsuC eht elbane dna DRC eht ni amehcs NOSJ a yficeps ot deen uoy ,noitadilaVecruoseRmotsuC elbane oT\" :\"thgilhgih\"{ \n",
      " ,}\".erutaef ahpla na sa stcejbo motsuc fo noitadilav decudortni 8.1 noisrev setenrebuK\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"Kubernetes version 1.8 introduced validation of custom objects as an alpha feature.\"}, \n",
      " {\"highlight\": \"To enable CustomResourceValidation, you need to specify a JSON schema in the CRD and enable the CustomResourceValidation feature gate in the API server.\"}, \n",
      " {\"highlight\": \"API server aggregation allows integrating multiple API servers at a single location, enabling clients to connect to the aggregated API without knowing about multiple servers handling different objects.\"}, \n",
      " {\"highlight\": \"Each API server is responsible for storing its own resources and can run its own instance of etcd or use CustomResourceDefinitions in the main API server as storage mechanism.\"}, \n",
      " {\"highlight\": \"Implementing a custom API server allows validating custom objects directly without creating a CRD, enabling more control over object validation and storage.\"}]\n",
      "Done for page number:461\n",
      "Raw Output\n",
      "Here are the 5 most important and informative highlights extracted from the document page:\n",
      "\n",
      "```\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To extend Kubernetes, you can create a CRD instance in the core API server's etcd store by creating a CRD object first.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A custom API server can be added to your cluster by deploying it as a pod and exposing it through a Service, then integrating it into the main API server using an APIService resource.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Client requests sent to the main API server that contain resources from a custom API group and version will be forwarded to the custom API server pod(s) exposed through a Service.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Custom clients can be built to make deployment of custom objects easier, allowing dedicated commands for manipulating those objects similar to kubectl.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Kubernetes Service Catalog API server will be added to Kubernetes through API server aggregation, enabling pods to consume services and making it a hot topic in the Kubernetes community.\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Reversed JSON OUTPUT:\n",
      "```\n",
      "]\n",
      "}    \n",
      "\".ytinummoc setenrebuK eht ni cipot toh a ti gnikam dna secivres emusnoc ot sdop gnilbane ,noitagergga revres IPA hguorht setenrebuK ot dedda eb lliw revres IPA golataC ecivreS setenrebuK ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ltcebuk ot ralimis stcejbo esoht gnitalupinam rof sdnammoc detacided gniwolla ,reisae stcejbo motsuc fo tnemyolped ekam ot tliub eb nac stneilc motsuC\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ecivreS a hguorht desopxe )s(dop revres IPA motsuc eht ot dedrawrof eb lliw noisrev dna puorg IPA motsuc a morf secruoser niatnoc taht revres IPA niam eht ot tnes stseuqer tneilC\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ecruoser ecivreSIPA na gnisu revres IPA niam eht otni ti gnitargetni neht ,ecivreS a hguorht ti gnisopxe dna dop a sa ti gniyolped yb retsulc ruoy ot dedda eb nac revres IPA motsuc A\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".tsrif tcejbo DRC a gnitaerc yb erots dcte s'revres IPA eroc eht ni ecnatsni DRC a etaerc nac uoy ,setenrebuK dnetxe oT\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To extend Kubernetes, you can create a CRD instance in the core API server's etcd store by creating a CRD object first.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A custom API server can be added to your cluster by deploying it as a pod and exposing it through a Service, then integrating it into the main API server using an APIService resource.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Client requests sent to the main API server that contain resources from a custom API group and version will be forwarded to the custom API server pod(s) exposed through a Service.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Custom clients can be built to make deployment of custom objects easier, allowing dedicated commands for manipulating those objects similar to kubectl.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Kubernetes Service Catalog API server will be added to Kubernetes through API server aggregation, enabling pods to consume services and making it a hot topic in the Kubernetes community.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"Kubernetes is supposed to be an easy-to-use, self-service system where users can provision services like PostgreSQL databases without manual configuration and deployment.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Kubernetes Service Catalog introduces four generic API resources: ClusterServiceBroker, ClusterServiceClass, ServiceInstance, and ServiceBinding, which enable users to browse and provision services without dealing with underlying resources.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A cluster admin creates a ClusterServiceBroker resource for each service broker, which is then used to create a ClusterServiceClass resource for each available service, allowing users to request a ServiceInstance and bind it to client pods using a ServiceBinding.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog aims to provide a self-service system where users can provision services without manual configuration and deployment, making Kubernetes easier to use.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Users will be able to request a service like PostgreSQL database and get it provisioned with a ServiceInstance, which can then be bound to client pods using a ServiceBinding, eliminating the need for manual configuration and deployment.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".tnemyolped dna noitarugifnoc launam rof deen eht gnitanimile ,gnidniBecivreS a gnisu sdop tneilc ot dnuob eb neht nac hcihw ,ecnatsnIecivreS a htiw denoisivorp ti teg dna esabatad LQSergtsoP ekil ecivres a tseuqer ot elba eb lliw sresU\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".esu ot reisae setenrebuK gnikam ,tnemyolped dna noitarugifnoc launam tuohtiw secivres noisivorp nac sresu erehw metsys ecivres-fles a edivorp ot smia golataC ecivreS ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".gnidniBecivreS a gnisu sdop tneilc ot ti dnib dna ecnatsnIecivreS a tseuqer ot sresu gniwolla ,ecivres elbaliava hcae rof ecruoser ssalCecivreSretsulC a etaerc ot desu neht si hcihw ,rekorb ecivres hcae rof ecruoser rekorBecivreSretsulC a setaerc nimda retsulc A\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".secruoser gniylrednu htiw gnilaed tuohtiw secivres noisivorp dna esworb ot sresu elbane hcihw ,gnidniBecivreS dna ,ecnatsnIecivreS ,ssalCecivreSretsulC ,rekorBecivreSretsulC :secruoser IPA cireneg ruof secudortni golataC ecivreS setenrebuK ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".tnemyolped dna noitarugifnoc launam tuohtiw sesabatad LQSergtsoP ekil secivres noisivorp nac sresu erehw metsys ecivres-fles ,esu-ot-ysae na eb ot desoppus si setenrebuK\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"Kubernetes is supposed to be an easy-to-use, self-service system where users can provision services like PostgreSQL databases without manual configuration and deployment.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Kubernetes Service Catalog introduces four generic API resources: ClusterServiceBroker, ClusterServiceClass, ServiceInstance, and ServiceBinding, which enable users to browse and provision services without dealing with underlying resources.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A cluster admin creates a ClusterServiceBroker resource for each service broker, which is then used to create a ClusterServiceClass resource for each available service, allowing users to request a ServiceInstance and bind it to client pods using a ServiceBinding.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog aims to provide a self-service system where users can provision services without manual configuration and deployment, making Kubernetes easier to use.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Users will be able to request a service like PostgreSQL database and get it provisioned with a ServiceInstance, which can then be bound to client pods using a ServiceBinding, eliminating the need for manual configuration and deployment.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:463\n",
      "Raw Output\n",
      "[{\"highlight\": \"The Kubernetes Service Catalog is a distributed system composed of three components: Service Catalog API Server, etcd as storage, and Controller Manager.\"}, \n",
      " {\"highlight\": \"The Service Catalog API server stores resources in its own etcd instance or uses CustomResourceDefinitions in the main API server as an alternative storage mechanism.\"}, \n",
      " {\"highlight\": \"Controllers running in the Controller Manager talk to the Service Catalog API server and provision services through external service brokers registered by creating ServiceBroker resources.\"}, \n",
      " {\"highlight\": \"Client pods use the provisioned services provided by external systems, such as Broker A and Broker B, which are connected to a Kubernetes cluster via the Service Catalog.\"}, \n",
      " {\"highlight\": \"The architecture of the Service Catalog is shown in Figure 18.7, illustrating the components and their relationships.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".spihsnoitaler rieht dna stnenopmoc eht gnitartsulli ,7.81 erugiF ni nwohs si golataC ecivreS eht fo erutcetihcra ehT\" :\"thgilhgih\"{ \n",
      " ,}\".golataC ecivreS eht aiv retsulc setenrebuK a ot detcennoc era hcihw ,B rekorB dna A rekorB sa hcus ,smetsys lanretxe yb dedivorp secivres denoisivorp eht esu sdop tneilC\" :\"thgilhgih\"{ \n",
      " ,}\".secruoser rekorBecivreS gnitaerc yb deretsiger srekorb ecivres lanretxe hguorht secivres noisivorp dna revres IPA golataC ecivreS eht ot klat reganaM rellortnoC eht ni gninnur srellortnoC\" :\"thgilhgih\"{ \n",
      " ,}\".msinahcem egarots evitanretla na sa revres IPA niam eht ni snoitinifeDecruoseRmotsuC sesu ro ecnatsni dcte nwo sti ni secruoser serots revres IPA golataC ecivreS ehT\" :\"thgilhgih\"{ \n",
      " ,}\".reganaM rellortnoC dna ,egarots sa dcte ,revreS IPA golataC ecivreS :stnenopmoc eerht fo desopmoc metsys detubirtsid a si golataC ecivreS setenrebuK ehT\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"The Kubernetes Service Catalog is a distributed system composed of three components: Service Catalog API Server, etcd as storage, and Controller Manager.\"}, \n",
      " {\"highlight\": \"The Service Catalog API server stores resources in its own etcd instance or uses CustomResourceDefinitions in the main API server as an alternative storage mechanism.\"}, \n",
      " {\"highlight\": \"Controllers running in the Controller Manager talk to the Service Catalog API server and provision services through external service brokers registered by creating ServiceBroker resources.\"}, \n",
      " {\"highlight\": \"Client pods use the provisioned services provided by external systems, such as Broker A and Broker B, which are connected to a Kubernetes cluster via the Service Catalog.\"}, \n",
      " {\"highlight\": \"The architecture of the Service Catalog is shown in Figure 18.7, illustrating the components and their relationships.\"}]\n",
      "Done for page number:464\n",
      "Raw Output\n",
      "[{\"highlight\": \"The Service Catalog talks to the broker through the OpenServiceBroker API, which is a REST API providing operations for retrieving services, provisioning service instances, updating and binding services.\"}, {\"highlight\": \"A cluster administrator can register one or more external ServiceBrokers in the Service Catalog by posting a ServiceBroker resource manifest to the Service Catalog API.\"}, {\"highlight\": \"The OpenServiceBroker API spec can be found at https://github.com/openservicebrokerapi/servicebroker.\"}, {\"highlight\": \"Each ClusterServiceClass resource describes a single type of service that can be provisioned, and each has one or more service plans associated with it.\"}, {\"highlight\": \"The Service Catalog creates a ClusterService-Class resource for each service this broker can provision after retrieving the list of services from the broker's OpenServiceBroker API URL.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".LRU IPA rekorBecivreSnepO s'rekorb eht morf secivres fo tsil eht gniveirter retfa noisivorp nac rekorb siht ecivres hcae rof ecruoser ssalC-ecivreSretsulC a setaerc golataC ecivreS ehT\" :\"thgilhgih\"{ ,}\".ti htiw detaicossa snalp ecivres erom ro eno sah hcae dna ,denoisivorp eb nac taht ecivres fo epyt elgnis a sebircsed ecruoser ssalCecivreSretsulC hcaE\" :\"thgilhgih\"{ ,}\".rekorbecivres/iparekorbecivresnepo/moc.buhtig//:sptth ta dnuof eb nac ceps IPA rekorBecivreSnepO ehT\" :\"thgilhgih\"{ ,}\".IPA golataC ecivreS eht ot tsefinam ecruoser rekorBecivreS a gnitsop yb golataC ecivreS eht ni srekorBecivreS lanretxe erom ro eno retsiger nac rotartsinimda retsulc A\" :\"thgilhgih\"{ ,}\".secivres gnidnib dna gnitadpu ,secnatsni ecivres gninoisivorp ,secivres gniveirter rof snoitarepo gnidivorp IPA TSER a si hcihw ,IPA rekorBecivreSnepO eht hguorht rekorb eht ot sklat golataC ecivreS ehT\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"The Service Catalog talks to the broker through the OpenServiceBroker API, which is a REST API providing operations for retrieving services, provisioning service instances, updating and binding services.\"}, {\"highlight\": \"A cluster administrator can register one or more external ServiceBrokers in the Service Catalog by posting a ServiceBroker resource manifest to the Service Catalog API.\"}, {\"highlight\": \"The OpenServiceBroker API spec can be found at https://github.com/openservicebrokerapi/servicebroker.\"}, {\"highlight\": \"Each ClusterServiceClass resource describes a single type of service that can be provisioned, and each has one or more service plans associated with it.\"}, {\"highlight\": \"The Service Catalog creates a ClusterService-Class resource for each service this broker can provision after retrieving the list of services from the broker's OpenServiceBroker API URL.\"}]\n",
      "Done for page number:465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[{\"highlight\": \"Users can retrieve a list of all services that can be provisioned in the cluster with kubectl get serviceclasses.\"}, {\"highlight\": \"ClusterServiceClasses allow you to select the type of service, similar to StorageClasses which allow you to select the type of storage for your pods.\"}, {\"highlight\": \"A ClusterServiceClass contains two plansa free plan and a premium plan, with unlimited size and SSD storage.\"}, {\"highlight\": \"The ClusterServiceClass is provided by the database-broker broker.\"}, {\"highlight\": \"You can retrieve details of one of the ClusterServiceClasses by retrieving its YAML using kubectl get serviceclass.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".ssalcecivres teg ltcebuk gnisu LMAY sti gniveirter yb sessalCecivreSretsulC eht fo eno fo sliated eveirter nac uoY\" :\"thgilhgih\"{ ,}\".rekorb rekorb-esabatad eht yb dedivorp si ssalCecivreSretsulC ehT\" :\"thgilhgih\"{ ,}\".egarots DSS dna ezis detimilnu htiw ,nalp muimerp a dna nalp eerf asnalp owt sniatnoc ssalCecivreSretsulC A\" :\"thgilhgih\"{ ,}\".sdop ruoy rof egarots fo epyt eht tceles ot uoy wolla hcihw sessalCegarotS ot ralimis ,ecivres fo epyt eht tceles ot uoy wolla sessalCecivreSretsulC\" :\"thgilhgih\"{ ,}\".sessalcecivres teg ltcebuk htiw retsulc eht ni denoisivorp eb nac taht secivres lla fo tsil a eveirter nac sresU\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"Users can retrieve a list of all services that can be provisioned in the cluster with kubectl get serviceclasses.\"}, {\"highlight\": \"ClusterServiceClasses allow you to select the type of service, similar to StorageClasses which allow you to select the type of storage for your pods.\"}, {\"highlight\": \"A ClusterServiceClass contains two plansa free plan and a premium plan, with unlimited size and SSD storage.\"}, {\"highlight\": \"The ClusterServiceClass is provided by the database-broker broker.\"}, {\"highlight\": \"You can retrieve details of one of the ClusterServiceClasses by retrieving its YAML using kubectl get serviceclass.\"}]\n",
      "Done for page number:466\n",
      "Raw Output\n",
      "Here are the 5 most important and informative highlights extracted from the document page, wrapped in JSON with the key \"highlight\":\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To have the database provisioned for you, all you need to do is create a Service-Instance resource, as shown in the following listing.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog will contact the broker the ClusterServiceClass belongs to and ask it to provision the service. It will pass on the chosen ClusterServiceClass and plan names, as well as all the parameters you specified.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can check if the service has been provisioned successfully by inspecting the status section of the my-postgres-db ServiceInstance you created, as shown in the following listing.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A ServiceInstance manifest: database-instance.yaml\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog doesnt care, and neither does the user requesting the service. The broker is responsible for provisioning the service according to the provided parameters.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".sretemarap dedivorp eht ot gnidrocca ecivres eht gninoisivorp rof elbisnopser si rekorb ehT .ecivres eht gnitseuqer resu eht seod rehtien dna ,erac tnseod golataC ecivreS ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\"lmay.ecnatsni-esabatad :tsefinam ecnatsnIecivreS A\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".gnitsil gniwollof eht ni nwohs sa ,detaerc uoy ecnatsnIecivreS bd-sergtsop-ym eht fo noitces sutats eht gnitcepsni yb yllufsseccus denoisivorp neeb sah ecivres eht fi kcehc nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".deificeps uoy sretemarap eht lla sa llew sa ,seman nalp dna ssalCecivreSretsulC nesohc eht no ssap lliw tI .ecivres eht noisivorp ot ti ksa dna ot sgnoleb ssalCecivreSretsulC eht rekorb eht tcatnoc lliw golataC ecivreS ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".gnitsil gniwollof eht ni nwohs sa ,ecruoser ecnatsnI-ecivreS a etaerc si od ot deen uoy lla ,uoy rof denoisivorp esabatad eht evah oT\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To have the database provisioned for you, all you need to do is create a Service-Instance resource, as shown in the following listing.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog will contact the broker the ClusterServiceClass belongs to and ask it to provision the service. It will pass on the chosen ClusterServiceClass and plan names, as well as all the parameters you specified.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can check if the service has been provisioned successfully by inspecting the status section of the my-postgres-db ServiceInstance you created, as shown in the following listing.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A ServiceInstance manifest: database-instance.yaml\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog doesnt care, and neither does the user requesting the service. The broker is responsible for provisioning the service according to the provided parameters.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:467\n",
      "Raw Output\n",
      "Here are the 5 most important and informative highlights extracted from the document page:\n",
      "\n",
      "```\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To use a provisioned ServiceInstance in your pods, you need to bind it by creating a ServiceBinding resource.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog creates a new Secret with the specified name and stores all data necessary for connecting to the database instance in it.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Currently, the Service Catalog doesn't make it possible to inject pods with the ServiceInstance's credentials directly.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can manually mount the newly created Secret into your client pods so they can read its contents and use them to connect to the provisioned service instance.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The PodPresets feature in Kubernetes will make it possible to inject pods with the ServiceInstance's credentials, but it is not available yet.\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "Reversed JSON OUTPUT:\n",
      "```\n",
      "]\n",
      "}    \n",
      "\".tey elbaliava ton si ti tub ,slaitnederc s'ecnatsnIecivreS eht htiw sdop tcejni ot elbissop ti ekam lliw setenrebuK ni erutaef steserPdoP ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ecnatsni ecivres denoisivorp eht ot tcennoc ot meht esu dna stnetnoc sti daer nac yeht os sdop tneilc ruoy otni terceS detaerc ylwen eht tnuom yllaunam nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".yltcerid slaitnederc s'ecnatsnIecivreS eht htiw sdop tcejni ot elbissop ti ekam t'nseod golataC ecivreS eht ,yltnerruC\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ti ni ecnatsni esabatad eht ot gnitcennoc rof yrassecen atad lla serots dna eman deificeps eht htiw terceS wen a setaerc golataC ecivreS ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ecruoser gnidniBecivreS a gnitaerc yb ti dnib ot deen uoy ,sdop ruoy ni ecnatsnIecivreS denoisivorp a esu oT\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"To use a provisioned ServiceInstance in your pods, you need to bind it by creating a ServiceBinding resource.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog creates a new Secret with the specified name and stores all data necessary for connecting to the database instance in it.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Currently, the Service Catalog doesn't make it possible to inject pods with the ServiceInstance's credentials directly.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"You can manually mount the newly created Secret into your client pods so they can read its contents and use them to connect to the provisioned service instance.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The PodPresets feature in Kubernetes will make it possible to inject pods with the ServiceInstance's credentials, but it is not available yet.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:468\n",
      "Raw Output\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"You can choose the name of the Secret yourself, and deploy pods before provisioning or binding the service.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Multiple bindings can be created for different pods, with a new set of credentials for every binding instance.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When you delete a ServiceBinding, the Service Catalog controller will delete the Secret and call the broker to perform an unbinding operation.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Deleting the ServiceInstance resource causes the Service Catalog to perform a deprovisioning operation on the service broker.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog enables service providers to expose services in any Kubernetes cluster by registering the broker in that cluster.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".retsulc taht ni rekorb eht gniretsiger yb retsulc setenrebuK yna ni secivres esopxe ot sredivorp ecivres selbane golataC ecivreS ehT\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".rekorb ecivres eht no noitarepo gninoisivorped a mrofrep ot golataC ecivreS eht sesuac ecruoser ecnatsnIecivreS eht gniteleD\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".noitarepo gnidnibnu na mrofrep ot rekorb eht llac dna terceS eht eteled lliw rellortnoc golataC ecivreS eht ,gnidniBecivreS a eteled uoy nehW\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ecnatsni gnidnib yreve rof slaitnederc fo tes wen a htiw ,sdop tnereffid rof detaerc eb nac sgnidnib elpitluM\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".ecivres eht gnidnib ro gninoisivorp erofeb sdop yolped dna ,flesruoy terceS eht fo eman eht esoohc nac uoY\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"You can choose the name of the Secret yourself, and deploy pods before provisioning or binding the service.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Multiple bindings can be created for different pods, with a new set of credentials for every binding instance.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"When you delete a ServiceBinding, the Service Catalog controller will delete the Secret and call the broker to perform an unbinding operation.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Deleting the ServiceInstance resource causes the Service Catalog to perform a deprovisioning operation on the service broker.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"The Service Catalog enables service providers to expose services in any Kubernetes cluster by registering the broker in that cluster.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"Service brokers allow easy provisioning and exposing of services in Kubernetes, making it an even more awesome platform for deploying applications.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Kubernetes is becoming a widely accepted foundation for the new generation of Platform-as-a-Service offerings, with Deis Workflow and Red Hat's OpenShift being among the best-known PaaS systems built on top of it.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Red Hat OpenShift provides a strong focus on developer experience, enabling rapid development, easy deployment, scaling, and long-term maintenance of applications, and automates rollouts, application scaling, image building, and deployment without requiring a Continuous Integration solution.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"OpenShift also provides user and group management, allowing for properly secured multi-tenant Kubernetes clusters with individual users only accessing their own namespaces and apps running in those namespaces being fully network-isolated from each other by default.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"OpenShift provides additional API objects beyond those available in Kubernetes, including Users & Groups and Projects, which are explained in the next few paragraphs to give a good overview of what OpenShift does and provides.\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\".sedivorp dna seod tfihSnepO tahw fo weivrevo doog a evig ot shpargarap wef txen eht ni denialpxe era hcihw ,stcejorP dna spuorG & sresU gnidulcni ,setenrebuK ni elbaliava esoht dnoyeb stcejbo IPA lanoitidda sedivorp tfihSnepO\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".tluafed yb rehto hcae morf detalosi-krowten ylluf gnieb secapseman esoht ni gninnur sppa dna secapseman nwo rieht gnissecca ylno sresu laudividni htiw sretsulc setenrebuK tnanet-itlum deruces ylreporp rof gniwolla ,tnemeganam puorg dna resu sedivorp osla tfihSnepO\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".noitulos noitargetnI suounitnoC a gniriuqer tuohtiw tnemyolped dna ,gnidliub egami ,gnilacs noitacilppa ,stuollor setamotua dna ,snoitacilppa fo ecnanetniam mret-gnol dna ,gnilacs ,tnemyolped ysae ,tnempoleved dipar gnilbane ,ecneirepxe repoleved no sucof gnorts a sedivorp tfihSnepO taH deR\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".ti fo pot no tliub smetsys SaaP nwonk-tseb eht gnoma gnieb tfihSnepO s'taH deR dna wolfkroW sieD htiw ,sgnireffo ecivreS-a-sa-mroftalP fo noitareneg wen eht rof noitadnuof detpecca ylediw a gnimoceb si setenrebuK\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".snoitacilppa gniyolped rof mroftalp emosewa erom neve na ti gnikam ,setenrebuK ni secivres fo gnisopxe dna gninoisivorp ysae wolla srekorb ecivreS\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"Service brokers allow easy provisioning and exposing of services in Kubernetes, making it an even more awesome platform for deploying applications.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Kubernetes is becoming a widely accepted foundation for the new generation of Platform-as-a-Service offerings, with Deis Workflow and Red Hat's OpenShift being among the best-known PaaS systems built on top of it.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Red Hat OpenShift provides a strong focus on developer experience, enabling rapid development, easy deployment, scaling, and long-term maintenance of applications, and automates rollouts, application scaling, image building, and deployment without requiring a Continuous Integration solution.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"OpenShift also provides user and group management, allowing for properly secured multi-tenant Kubernetes clusters with individual users only accessing their own namespaces and apps running in those namespaces being fully network-isolated from each other by default.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"OpenShift provides additional API objects beyond those available in Kubernetes, including Users & Groups and Projects, which are explained in the next few paragraphs to give a good overview of what OpenShift does and provides.\"\n",
      "  }\n",
      "]\n",
      "Done for page number:470\n",
      "Raw Output\n",
      "[{\"highlight\": \"OpenShift provides a proper multi-tenant environment to its users, with powerful user management features that allow specifying what each user can do and what they cannot.\"}, {\"highlight\": \"Each user has access to certain Projects, which are Kubernetes Namespaces with additional annotations, and can only act on resources within those projects.\"}, {\"highlight\": \"OpenShift allows parameterizable manifests through Templates, which are JSON or YAML files containing placeholders for parameter values.\"}, {\"highlight\": \"Templates can be stored in the API server like any other object and need to be processed before instantiation.\"}, {\"highlight\": \"Template parameters can reference resources defined in the same JSON/YAML file, allowing for dynamic configuration of deployments.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".stnemyolped fo noitarugifnoc cimanyd rof gniwolla ,elif LMAY/NOSJ emas eht ni denifed secruoser ecnerefer nac sretemarap etalpmeT\" :\"thgilhgih\"{ ,}\".noitaitnatsni erofeb dessecorp eb ot deen dna tcejbo rehto yna ekil revres IPA eht ni derots eb nac setalpmeT\" :\"thgilhgih\"{ ,}\".seulav retemarap rof sredlohecalp gniniatnoc selif LMAY ro NOSJ era hcihw ,setalpmeT hguorht stsefinam elbaziretemarap swolla tfihSnepO\" :\"thgilhgih\"{ ,}\".stcejorp esoht nihtiw secruoser no tca ylno nac dna ,snoitatonna lanoitidda htiw secapsemaN setenrebuK era hcihw ,stcejorP niatrec ot ssecca sah resu hcaE\" :\"thgilhgih\"{ ,}\".tonnac yeht tahw dna od nac resu hcae tahw gniyficeps wolla taht serutaef tnemeganam resu lufrewop htiw ,sresu sti ot tnemnorivne tnanet-itlum reporp a sedivorp tfihSnepO\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"OpenShift provides a proper multi-tenant environment to its users, with powerful user management features that allow specifying what each user can do and what they cannot.\"}, {\"highlight\": \"Each user has access to certain Projects, which are Kubernetes Namespaces with additional annotations, and can only act on resources within those projects.\"}, {\"highlight\": \"OpenShift allows parameterizable manifests through Templates, which are JSON or YAML files containing placeholders for parameter values.\"}, {\"highlight\": \"Templates can be stored in the API server like any other object and need to be processed before instantiation.\"}, {\"highlight\": \"Template parameters can reference resources defined in the same JSON/YAML file, allowing for dynamic configuration of deployments.\"}]\n",
      "Done for page number:471\n",
      "Raw Output\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"OpenShift provides a long list of pre-fabricated templates that allow users to quickly run complex applications by specifying a few arguments\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"OpenShift can build and deploy an application in the OpenShift cluster by pointing it to a Git repository holding the applications source code\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A BuildConfig object can be created to trigger builds of container images immediately after a change is committed to the source Git repository\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Once a new container image is built, it can automatically be deployed in the cluster by creating a DeploymentConfig object and pointing it to an ImageStream\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"OpenShift takes care of building, deploying, and managing apps from code committed to a Git repository, allowing developers to focus on development rather than container management\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\"tnemeganam reniatnoc naht rehtar tnempoleved no sucof ot srepoleved gniwolla ,yrotisoper tiG a ot dettimmoc edoc morf sppa gniganam dna ,gniyolped ,gnidliub fo erac sekat tfihSnepO\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\"maertSegamI na ot ti gnitniop dna tcejbo gifnoCtnemyolpeD a gnitaerc yb retsulc eht ni deyolped eb yllacitamotua nac ti ,tliub si egami reniatnoc wen a ecnO\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\"yrotisoper tiG ecruos eht ot dettimmoc si egnahc a retfa yletaidemmi segami reniatnoc fo sdliub reggirt ot detaerc eb nac tcejbo gifnoCdliuB A\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\"edoc ecruos snoitacilppa eht gnidloh yrotisoper tiG a ot ti gnitniop yb retsulc tfihSnepO eht ni noitacilppa na yolped dna dliub nac tfihSnepO\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\"stnemugra wef a gniyficeps yb snoitacilppa xelpmoc nur ylkciuq ot sresu wolla taht setalpmet detacirbaf-erp fo tsil gnol a sedivorp tfihSnepO\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"OpenShift provides a long list of pre-fabricated templates that allow users to quickly run complex applications by specifying a few arguments\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"OpenShift can build and deploy an application in the OpenShift cluster by pointing it to a Git repository holding the applications source code\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"A BuildConfig object can be created to trigger builds of container images immediately after a change is committed to the source Git repository\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Once a new container image is built, it can automatically be deployed in the cluster by creating a DeploymentConfig object and pointing it to an ImageStream\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"OpenShift takes care of building, deploying, and managing apps from code committed to a Git repository, allowing developers to focus on development rather than container management\"\n",
      "    }\n",
      "]\n",
      "Done for page number:472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "Here are the extracted highlights wrapped in JSON:\n",
      "\n",
      "[{\"highlight\": \"A DeploymentConfig is almost identical to the Deployment object in Kubernetes, but it pre-dates it.\"}, \n",
      " {\"highlight\": \"To expose Services to the outside world, you needed to use NodePort or LoadBalancer-type Services before OpenShift provided a better option through a Route resource.\"}, \n",
      " {\"highlight\": \"OpenShift provides a Router out of the box, which is a controller that provides the load balancer or proxy.\"}, \n",
      " {\"highlight\": \"Deis Workflow and Helm are also built on top of Kubernetes, providing a PaaS solution.\"}, \n",
      " {\"highlight\": \"BuildConfigs in OpenShift clones Git repo, builds new image from source, and adds it to the ImageStream, while DeploymentConfigs watches for new images and rolls out new version.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".noisrev wen tuo sllor dna segami wen rof sehctaw sgifnoCtnemyolpeD elihw ,maertSegamI eht ot ti sdda dna ,ecruos morf egami wen sdliub ,oper tiG senolc tfihSnepO ni sgifnoCdliuB\" :\"thgilhgih\"{ \n",
      " ,}\".noitulos SaaP a gnidivorp ,setenrebuK fo pot no tliub osla era mleH dna wolfkroW sieD\" :\"thgilhgih\"{ \n",
      " ,}\".yxorp ro recnalab daol eht sedivorp taht rellortnoc a si hcihw ,xob eht fo tuo retuoR a sedivorp tfihSnepO\" :\"thgilhgih\"{ \n",
      " ,}\".ecruoser etuoR a hguorht noitpo retteb a dedivorp tfihSnepO erofeb secivreS epyt-recnalaBdaoL ro troPedoN esu ot dedeen uoy ,dlrow edistuo eht ot secivreS esopxe oT\" :\"thgilhgih\"{ \n",
      " ,}\".ti setad-erp ti tub ,setenrebuK ni tcejbo tnemyolpeD eht ot lacitnedi tsomla si gifnoCtnemyolpeD A\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"A DeploymentConfig is almost identical to the Deployment object in Kubernetes, but it pre-dates it.\"}, \n",
      " {\"highlight\": \"To expose Services to the outside world, you needed to use NodePort or LoadBalancer-type Services before OpenShift provided a better option through a Route resource.\"}, \n",
      " {\"highlight\": \"OpenShift provides a Router out of the box, which is a controller that provides the load balancer or proxy.\"}, \n",
      " {\"highlight\": \"Deis Workflow and Helm are also built on top of Kubernetes, providing a PaaS solution.\"}, \n",
      " {\"highlight\": \"BuildConfigs in OpenShift clones Git repo, builds new image from source, and adds it to the ImageStream, while DeploymentConfigs watches for new images and rolls out new version.\"}]\n",
      "Done for page number:473\n",
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"Deis Workflow can be deployed on any existing Kubernetes cluster, creating a set of Services and ReplicationControllers that provide developers with a simple environment.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Helm is a package manager for Kubernetes that allows you to deploy and manage application packages in a Kubernetes cluster using Charts, Configs, and Releases.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Tiller is the server component of Helm that runs as a Pod inside the Kubernetes cluster and creates all necessary Kubernetes resources defined in the Chart.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Helm Charts are available on GitHub at https://github.com/kubernetes/charts, including charts for popular applications such as PostgreSQL, MySQL, and WordPress.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"You can use Helm to deploy and manage application packages without building and installing Kubernetes manifests manually, similar to how you install apps on a Linux system.\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\".metsys xuniL a no sppa llatsni uoy woh ot ralimis ,yllaunam stsefinam setenrebuK gnillatsni dna gnidliub tuohtiw segakcap noitacilppa eganam dna yolped ot mleH esu nac uoY\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".sserPdroW dna ,LQSyM ,LQSergtsoP sa hcus snoitacilppa ralupop rof strahc gnidulcni ,strahc/setenrebuk/moc.buhtig//:sptth ta buHtiG no elbaliava era strahC mleH\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".trahC eht ni denifed secruoser setenrebuK yrassecen lla setaerc dna retsulc setenrebuK eht edisni doP a sa snur taht mleH fo tnenopmoc revres eht si relliT\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".sesaeleR dna ,sgifnoC ,strahC gnisu retsulc setenrebuK a ni segakcap noitacilppa eganam dna yolped ot uoy swolla taht setenrebuK rof reganam egakcap a si mleH\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".tnemnorivne elpmis a htiw srepoleved edivorp taht srellortnoCnoitacilpeR dna secivreS fo tes a gnitaerc ,retsulc setenrebuK gnitsixe yna no deyolped eb nac wolfkroW sieD\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"Deis Workflow can be deployed on any existing Kubernetes cluster, creating a set of Services and ReplicationControllers that provide developers with a simple environment.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Helm is a package manager for Kubernetes that allows you to deploy and manage application packages in a Kubernetes cluster using Charts, Configs, and Releases.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Tiller is the server component of Helm that runs as a Pod inside the Kubernetes cluster and creates all necessary Kubernetes resources defined in the Chart.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Helm Charts are available on GitHub at https://github.com/kubernetes/charts, including charts for popular applications such as PostgreSQL, MySQL, and WordPress.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"You can use Helm to deploy and manage application packages without building and installing Kubernetes manifests manually, similar to how you install apps on a Linux system.\"\n",
      "  }\n",
      "]\n",
      "Done for page number:474\n",
      "Raw Output\n",
      "Here are the extracted highlights wrapped in JSON:\n",
      "\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"When running a PostgreSQL or MySQL database in a Kubernetes cluster, check if someone has already prepared a Helm chart for it instead of writing manifests.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Installing an application with a Helm chart takes only one line command, e.g., $ helm install --name my-database stable/mysql to run MySQL in the cluster.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Helm charts can create necessary Deployments, Services, Secrets, and PersistentVolumeClaims needed to run applications properly without manual configuration.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"An OpenVPN chart allows accessing Services as if a local machine was a pod in the Kubernetes cluster through VPN, useful for developing apps locally.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Helm combines charts and configurations into Releases that create Kubernetes objects defined in the Release, managed by the helm CLI tool and Tiller.\"\n",
      "    }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}    \n",
      "\".relliT dna loot ILC mleh eht yb deganam ,esaeleR eht ni denifed stcejbo setenrebuK etaerc taht sesaeleR otni snoitarugifnoc dna strahc senibmoc mleH\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".yllacol sppa gnipoleved rof lufesu ,NPV hguorht retsulc setenrebuK eht ni dop a saw enihcam lacol a fi sa secivreS gnissecca swolla trahc NPVnepO nA\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".noitarugifnoc launam tuohtiw ylreporp snoitacilppa nur ot dedeen smialCemuloVtnetsisreP dna ,sterceS ,secivreS ,stnemyolpeD yrassecen etaerc nac strahc mleH\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".retsulc eht ni LQSyM nur ot lqsym/elbats esabatad-ym eman-- llatsni mleh $ ,.g.e ,dnammoc enil eno ylno sekat trahc mleH a htiw noitacilppa na gnillatsnI\" :\"thgilhgih\"        \n",
      "{    \n",
      ",}    \n",
      "\".stsefinam gnitirw fo daetsni ti rof trahc mleH a deraperp ydaerla sah enoemos fi kcehc ,retsulc setenrebuK a ni esabatad LQSyM ro LQSergtsoP a gninnur nehW\" :\"thgilhgih\"        \n",
      "{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\n",
      "        \"highlight\": \"When running a PostgreSQL or MySQL database in a Kubernetes cluster, check if someone has already prepared a Helm chart for it instead of writing manifests.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Installing an application with a Helm chart takes only one line command, e.g., $ helm install --name my-database stable/mysql to run MySQL in the cluster.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Helm charts can create necessary Deployments, Services, Secrets, and PersistentVolumeClaims needed to run applications properly without manual configuration.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"An OpenVPN chart allows accessing Services as if a local machine was a pod in the Kubernetes cluster through VPN, useful for developing apps locally.\"\n",
      "    },\n",
      "    {\n",
      "        \"highlight\": \"Helm combines charts and configurations into Releases that create Kubernetes objects defined in the Release, managed by the helm CLI tool and Tiller.\"\n",
      "    }\n",
      "]\n",
      "Done for page number:475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Output\n",
      "[{\"highlight\": \"Custom resources can be registered in the API server by creating a Custom-ResourceDefinition object.\"}, {\"highlight\": \"Instances of custom objects can be stored, retrieved, updated, and deleted without having to change the API server code.\"}, {\"highlight\": \"A custom controller can be implemented to bring those objects to life.\"}, {\"highlight\": \"Kubernetes Service Catalog makes it possible to self-provision external services and expose them to pods running in the Kubernetes cluster.\"}, {\"highlight\": \"Platforms-as-a-Service built on top of Kubernetes make it easy to build containerized applications inside the same Kubernetes cluster that then runs them.\"}]\n",
      "Reversed JSON OUTPUT:\n",
      "]}\".meht snur neht taht retsulc setenrebuK emas eht edisni snoitacilppa dezireniatnoc dliub ot ysae ti ekam setenrebuK fo pot no tliub ecivreS-a-sa-smroftalP\" :\"thgilhgih\"{ ,}\".retsulc setenrebuK eht ni gninnur sdop ot meht esopxe dna secivres lanretxe noisivorp-fles ot elbissop ti sekam golataC ecivreS setenrebuK\" :\"thgilhgih\"{ ,}\".efil ot stcejbo esoht gnirb ot detnemelpmi eb nac rellortnoc motsuc A\" :\"thgilhgih\"{ ,}\".edoc revres IPA eht egnahc ot gnivah tuohtiw deteled dna ,detadpu ,deveirter ,derots eb nac stcejbo motsuc fo secnatsnI\" :\"thgilhgih\"{ ,}\".tcejbo noitinifeDecruoseR-motsuC a gnitaerc yb revres IPA eht ni deretsiger eb nac secruoser motsuC\" :\"thgilhgih\"{[\n",
      "JSON OUTPUT:\n",
      "[{\"highlight\": \"Custom resources can be registered in the API server by creating a Custom-ResourceDefinition object.\"}, {\"highlight\": \"Instances of custom objects can be stored, retrieved, updated, and deleted without having to change the API server code.\"}, {\"highlight\": \"A custom controller can be implemented to bring those objects to life.\"}, {\"highlight\": \"Kubernetes Service Catalog makes it possible to self-provision external services and expose them to pods running in the Kubernetes cluster.\"}, {\"highlight\": \"Platforms-as-a-Service built on top of Kubernetes make it easy to build containerized applications inside the same Kubernetes cluster that then runs them.\"}]\n",
      "Done for page number:476\n",
      "Raw Output\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"You can run examples in this book either in a Minikube cluster or a Google Kubernetes Engine (GKE) cluster.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"To switch between Minikube and GKE, you need to reconfigure kubectl using the 'minikube start' command for Minikube and the 'gcloud container clusters get-credentials' command for GKE.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Minikube automatically sets up kubectl every time you start a new cluster.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"To switch back to Minikube from GKE, stop Minikube and restart it, which will reconfigure kubectl to use the Minikube cluster again.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"You can switch to using a GKE cluster by running the 'gcloud container clusters get-credentials' command with the name of your GKE cluster.\"\n",
      "  }\n",
      "]\n",
      "Reversed JSON OUTPUT:\n",
      "]\n",
      "}  \n",
      "\".retsulc EKG ruoy fo eman eht htiw dnammoc 'slaitnederc-teg sretsulc reniatnoc duolcg' eht gninnur yb retsulc EKG a gnisu ot hctiws nac uoY\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".niaga retsulc ebukiniM eht esu ot ltcebuk erugifnocer lliw hcihw ,ti tratser dna ebukiniM pots ,EKG morf ebukiniM ot kcab hctiws oT\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".retsulc wen a trats uoy emit yreve ltcebuk pu stes yllacitamotua ebukiniM\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".EKG rof dnammoc 'slaitnederc-teg sretsulc reniatnoc duolcg' eht dna ebukiniM rof dnammoc 'trats ebukinim' eht gnisu ltcebuk erugifnocer ot deen uoy ,EKG dna ebukiniM neewteb hctiws oT\" :\"thgilhgih\"    \n",
      "{  \n",
      ",}  \n",
      "\".retsulc )EKG( enignE setenrebuK elgooG a ro retsulc ebukiniM a ni rehtie koob siht ni selpmaxe nur nac uoY\" :\"thgilhgih\"    \n",
      "{  \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "  {\n",
      "    \"highlight\": \"You can run examples in this book either in a Minikube cluster or a Google Kubernetes Engine (GKE) cluster.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"To switch between Minikube and GKE, you need to reconfigure kubectl using the 'minikube start' command for Minikube and the 'gcloud container clusters get-credentials' command for GKE.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"Minikube automatically sets up kubectl every time you start a new cluster.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"To switch back to Minikube from GKE, stop Minikube and restart it, which will reconfigure kubectl to use the Minikube cluster again.\"\n",
      "  },\n",
      "  {\n",
      "    \"highlight\": \"You can switch to using a GKE cluster by running the 'gcloud container clusters get-credentials' command with the name of your GKE cluster.\"\n",
      "  }\n",
      "]\n",
      "Done for page number:477\n",
      "Raw Output\n",
      "Here are the 5 most important and informative highlights extracted from the document page:\n",
      "\n",
      "```\n",
      "[\n",
      "    {\"highlight\": \"You can use multiple config files and have kubectl use them all at once by specifying all of them in the KUBECONFIG environment variable (separate them with a colon).\"},\n",
      "    {\"highlight\": \"The kubeconfig file consists of four sections: A list of clusters, A list of users, A list of contexts, and The name of the current context.\"},\n",
      "    {\"highlight\": \"An example config file is shown in the following listing.\"},\n",
      "    {\"highlight\": \"You can switch between different Kubernetes clusters or work in a different namespace than the default without specifying the --namespace option every time you run kubectl.\"},\n",
      "    {\"highlight\": \"The KUBECONFIG environment variable needs to point to the location of the kubeconfig file if it's stored somewhere else than the usual ~/.kube/config file.\"}\n",
      "]\n",
      "```\n",
      "Reversed JSON OUTPUT:\n",
      "```\n",
      "]\n",
      "}\".elif gifnoc/ebuk./~ lausu eht naht esle erehwemos derots s'ti fi elif gifnocebuk eht fo noitacol eht ot tniop ot sdeen elbairav tnemnorivne GIFNOCEBUK ehT\" :\"thgilhgih\"{    \n",
      ",}\".ltcebuk nur uoy emit yreve noitpo ecapseman-- eht gniyficeps tuohtiw tluafed eht naht ecapseman tnereffid a ni krow ro sretsulc setenrebuK tnereffid neewteb hctiws nac uoY\" :\"thgilhgih\"{    \n",
      ",}\".gnitsil gniwollof eht ni nwohs si elif gifnoc elpmaxe nA\" :\"thgilhgih\"{    \n",
      ",}\".txetnoc tnerruc eht fo eman ehT dna ,stxetnoc fo tsil A ,sresu fo tsil A ,sretsulc fo tsil A :snoitces ruof fo stsisnoc elif gifnocebuk ehT\" :\"thgilhgih\"{    \n",
      ",}\".)noloc a htiw meht etarapes( elbairav tnemnorivne GIFNOCEBUK eht ni meht fo lla gniyficeps yb ecno ta lla meht esu ltcebuk evah dna selif gifnoc elpitlum esu nac uoY\" :\"thgilhgih\"{    \n",
      "[\n",
      "JSON OUTPUT:\n",
      "[\n",
      "    {\"highlight\": \"You can use multiple config files and have kubectl use them all at once by specifying all of them in the KUBECONFIG environment variable (separate them with a colon).\"},\n",
      "    {\"highlight\": \"The kubeconfig file consists of four sections: A list of clusters, A list of users, A list of contexts, and The name of the current context.\"},\n",
      "    {\"highlight\": \"An example config file is shown in the following listing.\"},\n",
      "    {\"highlight\": \"You can switch between different Kubernetes clusters or work in a different namespace than the default without specifying the --namespace option every time you run kubectl.\"},\n",
      "    {\"highlight\": \"The KUBECONFIG environment variable needs to point to the location of the kubeconfig file if it's stored somewhere else than the usual ~/.kube/config file.\"}\n",
      "]\n",
      "Done for page number:478\n"
     ]
    }
   ],
   "source": [
    "for idx in range(start_page_idx,end_page_index):\n",
    "   \n",
    "        enrich_page(idx)\n",
    "        print(\"Done for page number:\"+str(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c44d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Store data (serialize in a pickle) upto page 102\n",
    "with open('./pdf_enriched_output/pdf_enriched_content_dict_stage2_phase2_final.pickle', 'wb') as handle:\n",
    "    pickle.dump(document_dict_deserialized_stage2, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dbf33a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search_agent_poc",
   "language": "python",
   "name": "search_agent_poc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
