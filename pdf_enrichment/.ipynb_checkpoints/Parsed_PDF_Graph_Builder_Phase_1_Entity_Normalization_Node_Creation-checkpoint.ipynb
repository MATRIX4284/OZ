{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Python venv: search_agent_poc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4375a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This module will take the serialized dictionary got out of PDF Parsing ann try to extract\n",
    "##Semantic Knowldge like identifying \n",
    "## 1.Important Objects/Entities\n",
    "## 2.Deduplicate Entities\n",
    "## 3.Extracting Relations\n",
    "## 4.Extract the main Ideas/Topics around Each Page\n",
    "## 5.Link the different topics via diffrent entities/Objects\n",
    "## 6.Break down the document by pages instead of Chunks .\n",
    "## 7.If a page does not fit a chunk then chunk them extract information and then deduplicate the information across\n",
    "## the page.\n",
    "\n",
    "#Next Steps:\n",
    "## 5.Try to Seggregate the BigPDF on Sections.\n",
    "## 8.Try To Find Common Objects or ideas that link these sections.\n",
    "## 9.Try "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2787f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona=\"\"\"You are a computer technology expert who has mastery in Kubernetes,Docker,Machine Learning,Generative AI,\\n\n",
    "    Natural Language Understanding,Software Engineering,Networking and Computer Vision.\"\"\"\n",
    "\n",
    "instruction=\"\"\"You have to deeply study a list of entities and deduplicate the entity following rules below:\\n\n",
    "            1.if there is any entities wich is plural replace it by its singular term. \\n\n",
    "            2.Synonyms must be addressed by any one of the names throughout the list.\n",
    "            3.Entities followed by unique ids to represent entity instance must be replaced by entity name.\\n\n",
    "            4.The entity which will get deduplicated by a single term their description \\n\n",
    "            must be merged.\n",
    "            5.In case of their category in case both the categories are same any one can be used\"\"\"\n",
    "\n",
    "formater=\"\"\"After deduplicating all the entities along with their description and category format the entities per rules below: \\n\n",
    "            1.For each entity create a json with 3 keys \"dedup_entity\",\"dedup_description\" and \"dedup_category\". \\n\n",
    "            2.Collate all the entity json into a list of json where each json represents an entity. \\n\n",
    "            Output the collated list of json. \\n\n",
    "            Do not output anything other than the list of json neither heading/decsription before the list of json\\n\n",
    "            nor any decsription/footer below the json \\n\"\"\"\n",
    "input_template=\"\"\"\\n Output should only contain the list of json and no oter words or character or sentences. \\n\n",
    "            Here are the entities: \\n\\n {entities} \\n\\n \"\"\"\n",
    "            \n",
    "template=persona+instruction+formater+input_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15191ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "#rag_test_input_path='/home/matrix4284/MY_GEN_AI_PROJECTS/RAG/GraphRAG/graphrag-local-ollama/ragtest/input/'+file_name\n",
    "import os\n",
    "# importing shutil module\n",
    "import shutil\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "#embeddings = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import XMLOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01aaca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"llama3.1\"\n",
    "book_text=''\n",
    "page_text=''\n",
    "file_name='Kubernetes_in_action_text_only'\n",
    "extension='.txt'\n",
    "start_page_idx=0\n",
    "end_page_index=479\n",
    "pdf_enrichment_output_dir = './pdf_enriched_output/'\n",
    "pdf_enrichment_phase1_output_file = 'pdf_enriched_content_dict_phase1_entity_extraction_478_final.pickle'\n",
    "pdf_enrichment_phase2_output_file = 'pdf_enriched_content_dict_phase2_entity_normalization_478_final.pickle'\n",
    "#full_filename=file_name+'_'+str(page_idx)+extension\n",
    "#full_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbcded8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM Model for Prompt Tuning\n",
    "llm = ChatOllama(base_url=\"http://192.168.50.100:11434\",model=model_name,temperature=0.2)\n",
    "\n",
    "#embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\",model_kwargs = model_kwargs)\n",
    "\n",
    "##Define Vectorstore\n",
    "vectorstore = Chroma(embedding_function=embeddings, persist_directory=\"./chroma_kubernetes_in_action\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a648bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (deserialized data)\n",
    "with open(pdf_enrichment_output_dir+pdf_enrichment_phase1_output_file, 'rb') as handle:\n",
    "    document_dict_deserialized = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da4eb885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_dict_deserialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2101caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'Pods',\n",
       "  'description': 'logical hosts that behave much like physical hosts or VMs',\n",
       "  'category': 'container'},\n",
       " {'entity': 'Kubernetes',\n",
       "  'description': 'cluster management system',\n",
       "  'category': 'software'},\n",
       " {'entity': 'Flat inter-pod network',\n",
       "  'description': 'single flat, shared network-address space for all pods',\n",
       "  'category': 'network'},\n",
       " {'entity': 'Pod',\n",
       "  'description': 'logical host that hosts a certain app',\n",
       "  'category': 'container'},\n",
       " {'entity': 'Container',\n",
       "  'description': 'lightweight process that runs an application',\n",
       "  'category': 'process'},\n",
       " {'entity': 'IP address',\n",
       "  'description': 'unique identifier for each pod',\n",
       "  'category': 'network'},\n",
       " {'entity': 'NAT (Network Address Translation)',\n",
       "  'description': 'gateway between pods that translates IP addresses',\n",
       "  'category': 'software'},\n",
       " {'entity': 'Worker nodes',\n",
       "  'description': 'physical or virtual machines that run pods',\n",
       "  'category': 'hardware'},\n",
       " {'entity': 'LAN (Local Area Network)',\n",
       "  'description': 'network for computers on the same physical location',\n",
       "  'category': 'network'},\n",
       " {'entity': 'Software-defined network',\n",
       "  'description': 'additional network layered on top of actual network',\n",
       "  'category': 'software'},\n",
       " {'entity': 'VM (Virtual Machine)',\n",
       "  'description': 'virtualized environment for running operating systems',\n",
       "  'category': 'hardware'},\n",
       " {'entity': 'Process',\n",
       "  'description': 'instance of a program that is being executed',\n",
       "  'category': 'process'},\n",
       " {'entity': 'App',\n",
       "  'description': 'application or service that runs in a pod',\n",
       "  'category': 'software'},\n",
       " {'entity': 'Node',\n",
       "  'description': 'physical or virtual machine that runs pods',\n",
       "  'category': 'hardware'},\n",
       " {'entity': 'Container 1',\n",
       "  'description': 'instance of a container running an application',\n",
       "  'category': 'process'},\n",
       " {'entity': 'Container 2',\n",
       "  'description': 'instance of a container running an application',\n",
       "  'category': 'process'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_dict_deserialized[1]['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60212f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Definitions of Individual Enrichment Modules######\n",
    "\n",
    "# Function to reverse a string\n",
    "def reverse(string):\n",
    "    string = string[::-1]\n",
    "    return string\n",
    "\n",
    "def entity_collector_per_page(entity_lst):\n",
    "\n",
    "    entities=[]\n",
    "    \n",
    "    for entity in entity_lst:\n",
    "        #print(\"Entity:\")\n",
    "        #print(entity)\n",
    "        entity_name=entity['entity']\n",
    "        entities.append(entity_name)\n",
    "    return list(set(entities))\n",
    "\n",
    "\n",
    "def normalize_entity_document_level(entity_lst):\n",
    "\n",
    "# Prompt\n",
    "    prompt = PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"entities\"],\n",
    "    )\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Score\n",
    "    #filtered_docs = []\n",
    "\n",
    "    output = chain.invoke(\n",
    "        {\n",
    "                \"context\": page_text,\"entities\":entity_lst\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    #print('Relationship Output from LLM\"')\n",
    "    #print(output)\n",
    "    \n",
    "    if '[' in output:\n",
    "        json_output=output.split('[')[1]\n",
    "        json_output='['+json_output\n",
    "    else:    \n",
    "        json_output='['+output\n",
    "    \n",
    "    #print('JSON OUTPUT:')\n",
    "    #print(json_output)\n",
    "    \n",
    "    \n",
    "\n",
    "    json_output=reverse(json_output)\n",
    "    \n",
    "    if ']' in json_output:\n",
    "        json_output=json_output.split(']')[1]\n",
    "        json_output=reverse(json_output)\n",
    "        json_output= json_output + ']'\n",
    "    else:\n",
    "        json_output=reverse(json_output)\n",
    "        json_output= json_output + ']'\n",
    "        \n",
    "    \n",
    "    \n",
    "    #page_output_json=json.loads(output)\n",
    "    #return page_output_json\n",
    "    return json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d155a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "######This code enrcihes the PDF page by page and while doing so it fails after processing 20 to 50 pages####\n",
    "######currently we are manually tackling this problem by making the pdf dict list into aglobal variable######\n",
    "######After the llm fails we take the index of the last page done and save the pdf dict list uptil that ####\n",
    "#####Then as of now i am manually restarting the by loading the saved pdf dict list as the source pdf and ###\n",
    "#####Using the last done pdf page index +1 as the starting index.So (last Done page Index + 1) is the ######\n",
    "###starting index###\n",
    "####The maximum page has been given as 565 as that is the last page where the main content of the document###\n",
    "####resides.In case of the book Kubernetes in action it is 565.##############################################\n",
    "####If this is batch process then the last page can be manually seen and used as the variable else one can ####\n",
    "#####also go for the pdf enrichment of all the pages of the book#############################################\n",
    "\n",
    "###This manual thing needs to be automated by either langraph or by using agents framework##################\n",
    "\n",
    "def normalize_doc(document_dict_deserialized):\n",
    "    \n",
    "    ##########################Entity Collection across Document############################################\n",
    "    entity_lst_doc=[]\n",
    "    \n",
    "    for idx in range(0,len(document_dict_deserialized)):\n",
    "        entity_lst_per_page=[]\n",
    "        entity_lst=document_dict_deserialized[idx]['entities']\n",
    "        entity_lst_per_page=entity_collector_per_page(entity_lst)\n",
    "        #print(document_dict_deserialized)\n",
    "        entity_lst_doc.extend(entity_lst_per_page)\n",
    "    \n",
    "    print('Total Entities:')\n",
    "    print(len(entity_lst_doc))\n",
    "    \n",
    "    entity_lst_stage1=list(set(entity_lst_doc))\n",
    "    \n",
    "    print('Total Entities:')\n",
    "    print(len(entity_lst_stage1))\n",
    "        \n",
    "        #for entity in entity_lst_page:\n",
    "            #entity_lst_doc.append(entity)\n",
    "    \n",
    "    #print(\"Page Number\")\n",
    "    #print(idx)\n",
    "    \n",
    "    \n",
    "    #print(entity_lst_doc[0:1])\n",
    "    \n",
    "    #page_text=document_dict_deserialized[page_idx]['text']\n",
    "    \n",
    "    ##Entity Extraction Enrichment\n",
    "    #page_entity_lst_dict=extract_entities_per_page(page_text)\n",
    "    \n",
    "    #print(\"Page Entity List Dictionary\")\n",
    "    #print(page_entity_lst_dict)\n",
    "    \n",
    "    #print(\"Page Entity List Dictionary Cleaned\")\n",
    "    #print(page_entity_lst_dict)\n",
    "    \n",
    "    #page_entity_lst_json=json.loads(page_entity_lst_dict)\n",
    "    #document_dict_deserialized[page_idx]['entities']=page_entity_lst_json\n",
    "    \n",
    "    #################################Entity Normalization###################################\n",
    "    ##Collate entity list per page into unique Entities\n",
    "    \n",
    "    #entity_lst=entity_collector_per_page(page_entity_lst_json)\n",
    "    \n",
    "    ##Relationship Extraction Enrichment\n",
    "    page_normalized_lst_dict=normalize_entity_document_level(entity_lst_stage1)\n",
    "    \n",
    "    print(\"Document Normalized List\")\n",
    "    print(len(list(set(page_normalized_lst_dict))))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #document_dict_deserialized[page_idx]['relationships']=page_relationship_lst_dict\n",
    "    print(\"Done for page \"+str(idx))\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0a6784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Entities:\n",
      "6087\n",
      "Total Entities:\n",
      "2595\n",
      "Document Normalized List\n",
      "3556\n",
      "Done for page 478\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#for idx in range(start_page_idx,end_page_index):\n",
    "   \n",
    "normalize_doc(document_dict_deserialized)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0934e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 556,\n",
       " 'img_cnt': 0,\n",
       " 'img_flag': 0,\n",
       " 'img_npy_lst': [],\n",
       " 'text': '524\\nCHAPTER 18\\nExtending Kubernetes\\n18.2.4 Provisioning and using a service\\nLet’s imagine the pods you’re deploying need to use a database. You’ve inspected the\\nlist of available ClusterServiceClasses and have chosen to use the free plan of the\\npostgres-database ClusterServiceClass. \\nPROVISIONING A SERVICEINSTANCE\\nTo have the database provisioned for you, all you need to do is create a Service-\\nInstance resource, as shown in the following listing.\\napiVersion: servicecatalog.k8s.io/v1alpha1\\nkind: ServiceInstance\\nmetadata:\\n  name: my-postgres-db                     \\nspec:\\n  clusterServiceClassName: postgres-database        \\n  clusterServicePlanName: free                             \\n  parameters:\\n    init-db-args: --data-checksums         \\nYou created a ServiceInstance called my-postgres-db (that will be the name of the\\nresource you’re deploying) and specified the ClusterServiceClass and the chosen\\nplan. You’re also specifying a parameter, which is specific for each broker and Cluster-\\nServiceClass. Let’s imagine you looked up the possible parameters in the broker’s doc-\\numentation.\\n As soon as you create this resource, the Service Catalog will contact the broker the\\nClusterServiceClass belongs to and ask it to provision the service. It will pass on the\\nchosen ClusterServiceClass and plan names, as well as all the parameters you specified.\\n It’s then completely up to the broker to know what to do with this information. In\\nyour case, your database broker will probably spin up a new instance of a PostgreSQL\\ndatabase somewhere—not necessarily in the same Kubernetes cluster or even in\\nKubernetes at all. It could run a Virtual Machine and run the database in there. The\\nService Catalog doesn’t care, and neither does the user requesting the service. \\n You can check if the service has been provisioned successfully by inspecting the\\nstatus section of the my-postgres-db ServiceInstance you created, as shown in the\\nfollowing listing.\\n$ kubectl get instance my-postgres-db -o yaml\\napiVersion: servicecatalog.k8s.io/v1alpha1\\nkind: ServiceInstance\\n...\\nstatus:\\n  asyncOpInProgress: false\\n  conditions:\\nListing 18.12\\nA ServiceInstance manifest: database-instance.yaml\\nListing 18.13\\nInspecting the status of a ServiceInstance\\nYou’re giving this \\nInstance a name.\\nThe ServiceClass \\nand Plan you want\\nAdditional parameters \\npassed to the broker\\n \\n',\n",
       " 'tables_flag': 0,\n",
       " 'tables': [],\n",
       " 'entities': [{'entity': 'Kubernetes',\n",
       "   'description': 'Container orchestration system',\n",
       "   'category': 'software'},\n",
       "  {'entity': 'Service Catalog',\n",
       "   'description': 'API for provisioning and managing services',\n",
       "   'category': 'software'},\n",
       "  {'entity': 'ClusterServiceClass',\n",
       "   'description': 'Template for a service instance',\n",
       "   'category': 'software'},\n",
       "  {'entity': 'postgres-database',\n",
       "   'description': 'ClusterServiceClass for PostgreSQL database',\n",
       "   'category': 'software'},\n",
       "  {'entity': 'ServiceInstance',\n",
       "   'description': 'Resource representing a provisioned service',\n",
       "   'category': 'software'},\n",
       "  {'entity': 'parameters',\n",
       "   'description': 'Additional data passed to the broker during provisioning',\n",
       "   'category': 'process'},\n",
       "  {'entity': 'init-db-args',\n",
       "   'description': 'Parameter for initializing database',\n",
       "   'category': 'parameter'},\n",
       "  {'entity': 'kubectl',\n",
       "   'description': 'Command-line tool for interacting with Kubernetes',\n",
       "   'category': 'command'},\n",
       "  {'entity': 'get instance',\n",
       "   'description': 'Command for retrieving information about a service instance',\n",
       "   'category': 'command'},\n",
       "  {'entity': 'yaml',\n",
       "   'description': 'Format for outputting data in human-readable format',\n",
       "   'category': 'format'},\n",
       "  {'entity': 'apiVersion',\n",
       "   'description': 'Field specifying the API version of a resource',\n",
       "   'category': 'field'},\n",
       "  {'entity': 'kind',\n",
       "   'description': 'Field specifying the type of a resource',\n",
       "   'category': 'field'},\n",
       "  {'entity': 'metadata',\n",
       "   'description': 'Field containing metadata about a resource',\n",
       "   'category': 'field'},\n",
       "  {'entity': 'name',\n",
       "   'description': 'Field specifying the name of a resource',\n",
       "   'category': 'field'},\n",
       "  {'entity': 'spec',\n",
       "   'description': 'Field specifying the specification of a service instance',\n",
       "   'category': 'field'},\n",
       "  {'entity': 'clusterServiceClassName',\n",
       "   'description': 'Field specifying the ClusterServiceClass for a service instance',\n",
       "   'category': 'field'},\n",
       "  {'entity': 'clusterServicePlanName',\n",
       "   'description': 'Field specifying the plan for a service instance',\n",
       "   'category': 'field'},\n",
       "  {'entity': 'parameters',\n",
       "   'description': 'Field containing additional parameters for a service instance',\n",
       "   'category': 'field'}],\n",
       " 'relationships': '[{\"source_entity\": \"You\", \"description\": \"create a ServiceInstance resource\", \"destination_entity\": \"my-postgres-db\"},\\n {\"source_entity\": \"You\", \"description\": \"specify the ClusterServiceClass and chosen plan\", \"destination_entity\": \"postgres-database\"},\\n {\"source_entity\": \"You\", \"description\": \"specify a parameter\", \"destination_entity\": \"init-db-args\"},\\n {\"source_entity\": \"The Service Catalog\", \"description\": \"contact the broker to provision the service\", \"destination_entity\": \"the ClusterServiceClass\"},\\n {\"source_entity\": \"The Service Catalog\", \"description\": \"pass on the chosen ClusterServiceClass and plan names, as well as all parameters\", \"destination_entity\": \"the broker\"},\\n {\"source_entity\": \"The broker\", \"description\": \"know what to do with the information\", \"destination_entity\": \"the ServiceInstance\"},\\n {\"source_entity\": \"Your database broker\", \"description\": \"spin up a new instance of a PostgreSQL database\", \"destination_entity\": \"a Virtual Machine\"},\\n {\"source_entity\": \"You\", \"description\": \"check if the service has been provisioned successfully\", \"destination_entity\": \"the status section of the my-postgres-db ServiceInstance\"},\\n {\"source_entity\": \"kubectl\", \"description\": \"get the instance\", \"destination_entity\": \"my-postgres-db\"}]',\n",
       " 'summary': 'To use a service like a database in Kubernetes, create a Service-Instance resource specifying the ClusterServiceClass and chosen plan, along with any required parameters. The Service Catalog will then provision the service by contacting the broker, which may spin up a new instance of the database in a VM or elsewhere. Successful provisioning can be checked by inspecting the status section of the ServiceInstance.',\n",
       " 'highlights': [{'highlight': 'To have the database provisioned for you, all you need to do is create a Service-Instance resource, as shown in the following listing.'},\n",
       "  {'highlight': 'The Service Catalog will contact the broker the ClusterServiceClass belongs to and ask it to provision the service. It will pass on the chosen ClusterServiceClass and plan names, as well as all the parameters you specified.'},\n",
       "  {'highlight': 'You can check if the service has been provisioned successfully by inspecting the status section of the my-postgres-db ServiceInstance you created, as shown in the following listing.'},\n",
       "  {'highlight': 'A ServiceInstance manifest: database-instance.yaml'},\n",
       "  {'highlight': 'The Service Catalog doesn’t care, and neither does the user requesting the service. The broker is responsible for provisioning the service according to the provided parameters.'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_dict_deserialized[467]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c44d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Store data (serialize in a pickle) upto page 102\n",
    "with open('./pdf_enriched_output/pdf_enriched_content_dict_stage2_phase3_final_478.pickle', 'wb') as handle:\n",
    "    pickle.dump(document_dict_deserialized, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e5c94a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 244,\n",
       " 'img_cnt': 0,\n",
       " 'img_flag': 0,\n",
       " 'img_npy_lst': [],\n",
       " 'text': '212\\nCHAPTER 7\\nConfigMaps and Secrets: configuring applications\\nEDITING A CONFIGMAP\\nLet’s see how you can change a ConfigMap and have the process running in the pod\\nreload the files exposed in the configMap volume. You’ll modify the Nginx config file\\nfrom your previous example and make Nginx use the new config without restarting\\nthe pod. Try switching gzip compression off by editing the fortune-config Config-\\nMap with kubectl edit:\\n$ kubectl edit configmap fortune-config\\nOnce your editor opens, change the gzip on line to gzip off, save the file, and then\\nclose the editor. The ConfigMap is then updated, and soon afterward, the actual file\\nin the volume is updated as well. You can confirm this by printing the contents of the\\nfile with kubectl exec:\\n$ kubectl exec fortune-configmap-volume -c web-server\\n➥  cat /etc/nginx/conf.d/my-nginx-config.conf\\nIf you don’t see the update yet, wait a while and try again. It takes a while for the\\nfiles to get updated. Eventually, you’ll see the change in the config file, but you’ll\\nfind this has no effect on Nginx, because it doesn’t watch the files and reload them\\nautomatically. \\nSIGNALING NGINX TO RELOAD THE CONFIG\\nNginx will continue to compress its responses until you tell it to reload its config files,\\nwhich you can do with the following command:\\n$ kubectl exec fortune-configmap-volume -c web-server -- nginx -s reload\\nNow, if you try hitting the server again with curl, you should see the response is no\\nlonger compressed (it no longer contains the Content-Encoding: gzip header).\\nYou’ve effectively changed the app’s config without having to restart the container or\\nrecreate the pod. \\nUNDERSTANDING HOW THE FILES ARE UPDATED ATOMICALLY\\nYou may wonder what happens if an app can detect config file changes on its own and\\nreloads them before Kubernetes has finished updating all the files in the configMap\\nvolume. Luckily, this can’t happen, because all the files are updated atomically, which\\nmeans all updates occur at once. Kubernetes achieves this by using symbolic links. If\\nyou list all the files in the mounted configMap volume, you’ll see something like the\\nfollowing listing.\\n$ kubectl exec -it fortune-configmap-volume -c web-server -- ls -lA \\n➥  /etc/nginx/conf.d\\ntotal 4\\ndrwxr-xr-x  ... 12:15 ..4984_09_04_12_15_06.865837643\\nListing 7.19\\nFiles in a mounted configMap volume\\n \\n',\n",
       " 'tables_flag': 0,\n",
       " 'tables': [],\n",
       " 'entities': [{'entity': 'ConfigMaps',\n",
       "   'description': 'A feature in Kubernetes that allows you to store and manage configuration data as key-value pairs.',\n",
       "   'category': 'software'},\n",
       "  {'entity': 'kubectl edit',\n",
       "   'description': 'A command used to edit a ConfigMap or other Kubernetes resource directly from the terminal.',\n",
       "   'category': 'command'},\n",
       "  {'entity': 'fortune-config Config-Map',\n",
       "   'description': 'A specific ConfigMap used in the example to store configuration data for an Nginx server.',\n",
       "   'category': 'software'},\n",
       "  {'entity': 'gzip compression',\n",
       "   'description': 'A feature of Nginx that compresses responses to reduce bandwidth usage.',\n",
       "   'category': 'process'},\n",
       "  {'entity': 'Nginx config file',\n",
       "   'description': 'A configuration file used by the Nginx server to determine how to handle requests.',\n",
       "   'category': 'file'},\n",
       "  {'entity': 'kubectl exec',\n",
       "   'description': 'A command used to execute a command inside a running container or pod.',\n",
       "   'category': 'command'},\n",
       "  {'entity': 'nginx -s reload',\n",
       "   'description': 'A command used to signal the Nginx server to reload its configuration files.',\n",
       "   'category': 'command'},\n",
       "  {'entity': 'ConfigMap volume',\n",
       "   'description': 'A directory in a pod that is mounted from a ConfigMap, containing configuration data for an application.',\n",
       "   'category': 'directory'},\n",
       "  {'entity': 'symbolic links',\n",
       "   'description': 'A feature used by Kubernetes to update files in a ConfigMap volume atomically.',\n",
       "   'category': 'process'},\n",
       "  {'entity': 'kubectl exec -it',\n",
       "   'description': 'A command used to execute a command inside a running container or pod, with interactive shell.',\n",
       "   'category': 'command'}],\n",
       " 'relationships': '[\\n  {\\n    \"source_entity\": \"kubectl edit\",\\n    \"description\": \"edit a ConfigMap and have the process running in the pod reload the files exposed in the configMap volume\",\\n    \"destination_entity\": \"ConfigMap\"\\n  },\\n  {\\n    \"source_entity\": \"fortune-config Config-Map\",\\n    \"description\": \"update the gzip compression setting to \\'gzip off\\'\",\\n    \"destination_entity\": \"Nginx config file\"\\n  },\\n  {\\n    \"source_entity\": \"kubectl exec\",\\n    \"description\": \"print the contents of a file in the volume\",\\n    \"destination_entity\": \"/etc/nginx/conf.d/my-nginx-config.conf\"\\n  },\\n  {\\n    \"source_entity\": \"nginx -s reload\",\\n    \"description\": \"reload Nginx config files and update the app\\'s config without restarting the container or recreating the pod\",\\n    \"destination_entity\": \"Nginx\"\\n  },\\n  {\\n    \"source_entity\": \"kubectl exec\",\\n    \"description\": \"execute a command in a container to reload Nginx config files\",\\n    \"destination_entity\": \"fortune-config Config-Map volume\"\\n  },\\n  {\\n    \"source_entity\": \"ConfigMaps\",\\n    \"description\": \"configure applications using ConfigMaps and Secrets\",\\n    \"destination_entity\": \"applications\"\\n  },\\n  {\\n    \"source_entity\": \"kubectl exec\",\\n    \"description\": \"execute a command in a container to list files in the mounted configMap volume\",\\n    \"destination_entity\": \"/etc/nginx/conf.d\"\\n  },\\n  {\\n    \"source_entity\": \"symbolic links\",\\n    \"description\": \"achieve atomic updates of all files in the configMap volume using symbolic links\",\\n    \"destination_entity\": \"ConfigMaps\"\\n  },\\n  {\\n    \"source_entity\": \"gzip compression\",\\n    \"description\": \"update the gzip compression setting to \\'gzip off\\' and observe its effect on Nginx responses\",\\n    \"destination_entity\": \"Nginx responses\"\\n  }\\n]',\n",
       " 'summary': 'A ConfigMap can be edited using kubectl edit to change its contents, and the changes will propagate to the actual file in the volume. However, the application may not automatically reload the updated files. To force Nginx to reload its config files, use the command `nginx -s reload`. Kubernetes achieves atomic updates by using symbolic links.',\n",
       " 'highlights': [{'highlight': 'You can change a ConfigMap and have the process running in the pod reload the files exposed in the configMap volume by editing the Nginx config file with kubectl edit.'},\n",
       "  {'highlight': 'To signal Nginx to reload its config files, you can use the command $ kubectl exec fortune-configmap-volume -c web-server -- nginx -s reload'},\n",
       "  {'highlight': 'All the files in a mounted configMap volume are updated atomically, which means all updates occur at once, thanks to Kubernetes using symbolic links.'},\n",
       "  {'highlight': 'You can confirm that the ConfigMap has been updated by printing the contents of the file with kubectl exec and checking for changes in the config file.'},\n",
       "  {'highlight': 'Editing a ConfigMap does not require restarting the container or recreating the pod, as the changes are applied atomically and Nginx will reload its config files automatically.'}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_dict_deserialized[155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "####The main contents of Kubernets In Action book is contained from page 87 to 565####\n",
    "####Thats why we will only take the sliced portion i.e. from page 87 to 565 of the pdf dictionary list#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc9ff2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (deserialize)\n",
    "with open('pdf_content_dict_page_final.pickle', 'rb') as handle:\n",
    "    document_dict_deserialized = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f565b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data (serialize in a pickle) upto page 102\n",
    "with open('../pdf_enrichment/pdf_enriched_output/pdf_enriched_content_dict_stage1.pickle', 'wb') as handle:\n",
    "    pickle.dump(document_dict_deserialized, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search_agent_poc",
   "language": "python",
   "name": "search_agent_poc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
