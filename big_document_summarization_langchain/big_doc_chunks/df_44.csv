,page,img_cnt,img_npy_lst,text,tables,entities,relationships,summary_rel,summary,highlights
440,529,0,[],"497
Making your apps easy to run and manage in Kubernetes
This way, you don’t need to modify the code of your app at all. If your app already
ensures all in-flight requests are processed completely, this pre-stop delay may be all
you need.
17.4
Making your apps easy to run and manage in Kubernetes
I hope you now have a better sense of how to make your apps handle clients nicely.
Now we’ll look at other aspects of how an app should be built to make it easier to man-
age in Kubernetes.
17.4.1 Making manageable container images
When you package your app into an image, you can choose to include the app’s
binary executable and any additional libraries it needs, or you can package up a whole
OS filesystem along with the app. Way too many people do this, even though it’s usu-
ally unnecessary.
 Do you need every single file from an OS distribution in your image? Probably not.
Most of the files will never be used and will make your image larger than it needs to
be. Sure, the layering of images makes sure each individual layer is downloaded only
once, but even having to wait longer than necessary the first time a pod is scheduled
to a node is undesirable.
 Deploying new pods and scaling them should be fast. This demands having small
images without unnecessary cruft. If you’re building apps using the Go language, your
images don’t need to include anything else apart from the app’s single binary execut-
able file. This makes Go-based container images extremely small and perfect for
Kubernetes.
TIP
Use the FROM scratch directive in the Dockerfile for these images.
But in practice, you’ll soon see these minimal images are extremely difficult to debug.
The first time you need to run a tool such as ping, dig, curl, or something similar
inside the container, you’ll realize how important it is for container images to also
include at least a limited set of these tools. I can’t tell you what to include and what
not to include in your images, because it depends on how you do things, so you’ll
need to find the sweet spot yourself.
17.4.2 Properly tagging your images and using imagePullPolicy wisely
You’ll also soon learn that referring to the latest image tag in your pod manifests will
cause problems, because you can’t tell which version of the image each individual pod
replica is running. Even if initially all your pod replicas run the same image version, if
you push a new version of the image under the latest tag, and then pods are resched-
uled (or you scale up your Deployment), the new pods will run the new version,
whereas the old ones will still be running the old one. Also, using the latest tag
makes it impossible to roll back to a previous version (unless you push the old version
of the image again).
 
",[],"[{'entity': 'Kubernetes', 'description': 'Container orchestration system', 'category': 'software'}, {'entity': 'Docker', 'description': 'Containerization platform', 'category': 'software'}, {'entity': 'pod', 'description': 'Lightweight and portable container', 'category': 'container'}, {'entity': 'node', 'description': 'Physical or virtual machine running a pod', 'category': 'hardware'}, {'entity': 'image', 'description': 'Read-only template for creating containers', 'category': 'software'}, {'entity': 'Dockerfile', 'description': 'Script used to build Docker images', 'category': 'software'}, {'entity': 'FROM scratch directive', 'description': 'Instruction in a Dockerfile for creating an empty image', 'category': 'software'}, {'entity': 'ping', 'description': 'Network diagnostic tool', 'category': 'software'}, {'entity': 'dig', 'description': 'DNS lookup tool', 'category': 'software'}, {'entity': 'curl', 'description': 'Tool for transferring data over HTTP', 'category': 'software'}, {'entity': 'imagePullPolicy', 'description': 'Policy for pulling images from a registry', 'category': 'software'}, {'entity': 'latest tag', 'description': 'Tag used to refer to the most recent image version', 'category': 'software'}, {'entity': 'Deployment', 'description': 'Kubernetes resource for managing replicas of a pod', 'category': 'software'}]","[{'source_entity': 'Kubernetes', 'description': 'manages', 'destination_entity': 'pod'}, {'source_entity': 'Kubernetes', 'description': 'orchestrates', 'destination_entity': 'Deployment'}, {'source_entity': 'Kubernetes', 'description': 'deploys', 'destination_entity': 'image'}, {'source_entity': 'Docker', 'description': 'builds', 'destination_entity': 'image'}, {'source_entity': 'Docker', 'description': 'pulls', 'destination_entity': 'FROM scratch directive'}, {'source_entity': 'Kubernetes', 'description': 'uses', 'destination_entity': 'node'}, {'source_entity': 'curl', 'description': 'requests', 'destination_entity': 'image'}, {'source_entity': 'dig', 'description': 'resolves', 'destination_entity': 'latest tag'}, {'source_entity': 'ping', 'description': 'checks', 'destination_entity': 'node'}]","['[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""manages"",\n    ""summary_er"": ""Kubernetes manages pods, ensuring efficient resource allocation and scaling.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""orchestrates"",\n    ""summary_er"": ""Kubernetes manages and coordinates the execution of pods, ensuring efficient resource utilization and scalability.""\n  },\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""Deployment"",\n    ""relation_description"": ""manages"",\n    ""summary_er"": ""Kubernetes manages Deployments, which provide a way to rollout new versions of applications with zero downtime and minimal disruption.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""deploys"",\n    ""summary_er"": ""Kubernetes deploys a containerized application as a pod, managing its lifecycle and resources.""\n  }\n]', '[\n  {\n    ""source"": ""Docker"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""builds"",\n    ""summary_er"": ""Docker builds an image for a pod, creating a containerized environment for application deployment.""\n  }\n]', '[\n  {\n    ""source"": ""Docker"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""pulls"",\n    ""summary_er"": ""Docker pulls an image from a registry, which is then used to create a pod in Kubernetes.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""uses"",\n    ""summary_er"": ""Kubernetes manages and orchestrates containerized applications, utilizing pods as the basic execution unit.""\n  },\n  {\n    ""source"": ""pod"",\n    ""destination"": ""node"",\n    ""relation_description"": ""runs on"",\n    ""summary_er"": ""Pods are scheduled to run on a node within a Kubernetes cluster, leveraging the node\'s resources for execution.""\n  }\n]', '[\n  {\n    ""source"": ""curl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""requests"",\n    ""summary_er"": ""The curl command sends HTTP requests to a pod, which can be an application or service running in a Kubernetes cluster.""\n  }\n]', '[\n  {\n    ""source"": ""dig"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""resolves"",\n    ""summary_er"": ""The \'dig\' command resolves a DNS query to determine the IP address of a pod with the latest tag.""\n  }\n]', '[\n  {\n    ""source"": ""ping"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""checks"",\n    ""summary_er"": ""The \'ping\' command checks the status of a \'pod\', ensuring it\'s running and responding as expected.""\n  }\n]']","To make apps easy to run and manage in Kubernetes, focus on creating small, minimal container images without unnecessary cruft. This includes using the FROM scratch directive in Dockerfiles and avoiding the latest image tag, which can cause versioning issues. Proper tagging of images and using imagePullPolicy wisely is also crucial to ensure smooth deployment and scaling.","[{'highlight': ""You don't need to modify the code of your app at all to make it easy to run and manage in Kubernetes.""}, {'highlight': 'Including unnecessary files in container images can make them larger than necessary, which can slow down deploying new pods and scaling them.'}, {'highlight': ""Using the FROM scratch directive in the Dockerfile for minimal images can be difficult to debug because they don't include essential tools like ping or curl.""}, {'highlight': ""Referring to the latest image tag in pod manifests can cause problems because it's unclear which version of the image each individual pod replica is running.""}, {'highlight': ""Using a specific image tag instead of 'latest' and configuring imagePullPolicy wisely can help ensure that all pod replicas run the same version of the image.""}]"
441,530,0,[],"498
CHAPTER 17
Best practices for developing apps
 It’s almost mandatory to use tags containing a proper version designator instead
of latest, except maybe in development. Keep in mind that if you use mutable tags
(you push changes to the same tag), you’ll need to set the imagePullPolicy field in
the pod spec to Always. But if you use that in production pods, be aware of the big
caveat associated with it. If the image pull policy is set to Always, the container run-
time will contact the image registry every time a new pod is deployed. This slows
down pod startup a bit, because the node needs to check if the image has been mod-
ified. Worse yet, this policy prevents the pod from starting up when the registry can-
not be contacted.
17.4.3 Using multi-dimensional instead of single-dimensional labels
Don’t forget to label all your resources, not only Pods. Make sure you add multiple
labels to each resource, so they can be selected across each individual dimension. You
(or the ops team) will be grateful you did it when the number of resources increases.
 Labels may include things like
The name of the application (or perhaps microservice) the resource belongs to
Application tier (front-end, back-end, and so on)
Environment (development, QA, staging, production, and so on)
Version
Type of release (stable, canary, green or blue for green/blue deployments, and
so on)
Tenant (if you’re running separate pods for each tenant instead of using name-
spaces)
Shard for sharded systems
This will allow you to manage resources in groups instead of individually and make it
easy to see where each resource belongs.
17.4.4 Describing each resource through annotations
To add additional information to your resources use annotations. At the least,
resources should contain an annotation describing the resource and an annotation
with contact information of the person responsible for it. 
 In a microservices architecture, pods could contain an annotation that lists the
names of the other services the pod is using. This makes it possible to show dependen-
cies between pods. Other annotations could include build and version information
and metadata used by tooling or graphical user interfaces (icon names, and so on).
 Both labels and annotations make managing running applications much easier, but
nothing is worse than when an application starts crashing and you don’t know why.
17.4.5 Providing information on why the process terminated
Nothing is more frustrating than having to figure out why a container terminated
(or is even terminating continuously), especially if it happens at the worst possible
 
",[],"[{'entity': 'tags', 'description': 'container tags with version designator', 'category': 'software'}, {'entity': 'imagePullPolicy', 'description': 'field in pod spec to control image pull', 'category': 'software'}, {'entity': 'latest', 'description': 'tag name for latest container version', 'category': 'software'}, {'entity': 'labels', 'description': 'metadata attached to resources like pods', 'category': 'software'}, {'entity': 'multi-dimensional labels', 'description': 'multiple labels per resource for selection across dimensions', 'category': 'software'}, {'entity': 'annotations', 'description': 'additional metadata attached to resources like pods', 'category': 'software'}, {'entity': 'pods', 'description': 'lightweight and ephemeral containers in Kubernetes', 'category': 'container'}, {'entity': 'containers', 'description': 'processes running within a pod', 'category': 'container'}, {'entity': 'registry', 'description': 'image repository for storing container images', 'category': 'software'}, {'entity': 'Kubernetes', 'description': 'container orchestration system', 'category': 'software'}, {'entity': 'labels', 'description': 'metadata attached to resources like pods', 'category': 'software'}, {'entity': 'annotations', 'description': 'additional metadata attached to resources like pods', 'category': 'software'}]","[{'source_entity': 'registry', 'description': 'stores', 'destination_entity': 'tags'}, {'source_entity': 'registry', 'description': 'manages', 'destination_entity': 'pods'}, {'source_entity': 'registry', 'description': 'pulls', 'destination_entity': 'image'}, {'source_entity': 'registry', 'description': 'pushes', 'destination_entity': 'image'}, {'source_entity': 'Kubernetes', 'description': 'uses', 'destination_entity': 'pods'}, {'source_entity': 'Kubernetes', 'description': 'manages', 'destination_entity': 'containers'}, {'source_entity': 'registry', 'description': 'labels', 'destination_entity': 'multi-dimensional labels'}, {'source_entity': 'registry', 'description': 'sets', 'destination_entity': 'annotations'}, {'source_entity': 'registry', 'description': 'specifies', 'destination_entity': 'imagePullPolicy'}, {'source_entity': 'registry', 'description': 'tags', 'destination_entity': 'latest'}]","['[\n  {\n    ""source"": ""registry"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""stores"",\n    ""summary_er"": ""A container registry stores Docker images for a pod to use.""\n  }\n]', '[\n  {\n    ""source"": ""registry"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""manages"",\n    ""summary_er"": ""The container registry manages a collection of pods, ensuring they are properly configured and running as expected.""\n  }\n]', '[\n  {\n    ""source"": ""registry"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""pulls"",\n    ""summary_er"": ""A container registry pulls an image to create a new pod in Kubernetes.""\n  }\n]', '[\n  {\n    ""source"": ""registry"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""pushes"",\n    ""summary_er"": ""The container registry pushes images to a running pod, allowing for deployment and scaling of applications.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""uses"",\n    ""summary_er"": ""Kubernetes manages and orchestrates multiple containers (pods) to ensure efficient resource utilization.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""manages"",\n    ""summary_er"": ""Kubernetes manages a collection of containerized applications, referred to as pods.""\n  }\n]', '[\n  {\n    ""source"": ""registry"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""labels"",\n    ""summary_er"": ""A container registry stores metadata about images, including labels that describe their characteristics.""\n  },\n  {\n    ""source"": ""registry"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""multi-dimensional labels"",\n    ""summary_er"": ""A container registry can store complex labels with multiple dimensions to categorize and filter images.""\n  }\n]', '[\n  {\n    ""source"": ""registry"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""sets"",\n    ""summary_er"": ""A Kubernetes registry sets up a pod with specific configurations.""\n  },\n  {\n    ""source"": ""pod"",\n    ""destination"": ""annotations"",\n    ""relation_description"": ""sets"",\n    ""summary_er"": ""A pod sets annotations to store metadata and labels.""\n  }\n]', '[\n  {\n    ""source"": ""registry"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""specifies"",\n    ""summary_er"": ""The registry specifies the location of the container image for a pod, allowing it to be pulled from a remote repository.""\n  }\n]', '[\n  {\n    ""source"": ""Registry"",\n    ""destination"": ""Tags"",\n    ""relation_description"": ""Associated with"",\n    ""summary_er"": ""The registry is associated with a set of tags that describe its contents.""\n  },\n  {\n    ""source"": ""Registry"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""Pulls from"",\n    ""summary_er"": ""The registry pulls the latest version of a pod from its repository.""\n  },\n  {\n    ""source"": ""Tags"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""Labels"",\n    ""summary_er"": ""The tags label the pod with metadata that describes its contents.""\n  }\n]']","Use tags with version designators, label resources with multiple dimensions, add annotations for resource descriptions and dependencies. Set imagePullPolicy to Always only in development. Use labels and annotations to manage resources and show dependencies between pods, and include contact information and build/version metadata.","[{'highlight': 'Use tags containing a proper version designator instead of latest, except in development. Set imagePullPolicy field to Always for mutable tags.'}, {'highlight': 'Label all resources with multiple labels across each individual dimension, including application name, tier, environment, version, and type of release.'}, {'highlight': 'Use annotations to add additional information to resources, such as contact information, dependencies between pods, build and version info, and metadata for tooling or GUIs.'}, {'highlight': 'Set imagePullPolicy field to Always can slow down pod startup and prevent pod from starting up when registry cannot be contacted.'}, {'highlight': 'Provide information on why a container terminated through annotations or labels to make it easier to manage running applications.'}]"
442,531,0,[],"499
Making your apps easy to run and manage in Kubernetes
moment. Be nice to the ops people and make their lives easier by including all the
necessary debug information in your log files. 
 But to make triage even easier, you can use one other Kubernetes feature that
makes it possible to show the reason why a container terminated in the pod’s status.
You do this by having the process write a termination message to a specific file in the
container’s filesystem. The contents of this file are read by the Kubelet when the con-
tainer terminates and are shown in the output of kubectl describe pod. If an applica-
tion uses this mechanism, an operator can quickly see why the app terminated without
even having to look at the container logs. 
 The default file the process needs to write the message to is /dev/termination-log,
but it can be changed by setting the terminationMessagePath field in the container
definition in the pod spec. 
 You can see this in action by running a pod whose container dies immediately, as
shown in the following listing.
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-termination-message
spec:
  containers:
  - image: busybox
    name: main
    terminationMessagePath: /var/termination-reason         
    command:
    - sh
    - -c
    - 'echo ""I''ve had enough"" > /var/termination-reason ; exit 1'   
When running this pod, you’ll soon see the pod’s status shown as CrashLoopBackOff.
If you then use kubectl describe, you can see why the container died, without having
to dig down into its logs, as shown in the following listing.
$ kubectl describe po
Name:           pod-with-termination-message
...
Containers:
...
    State:      Waiting
      Reason:   CrashLoopBackOff
    Last State: Terminated
      Reason:   Error
      Message:  I've had enough          
      Exit Code:        1
      Started:          Tue, 21 Feb 2017 21:38:31 +0100
      Finished:         Tue, 21 Feb 2017 21:38:31 +0100
Listing 17.8
Pod writing a termination message: termination-message.yaml
Listing 17.9
Seeing the container’s termination message with kubectl describe
You’re overriding the 
default path of the 
termination message file.
The container
will write the
message to
the file just
before exiting.
You can see the reason 
why the container died 
without having to 
inspect its logs.
 
",[],"[{'entity': 'Kubernetes', 'description': 'Container orchestration system', 'category': 'software'}, {'entity': 'Pod', 'description': 'Basic execution unit in Kubernetes', 'category': 'software'}, {'entity': '/dev/termination-log', 'description': 'Default file for termination message', 'category': 'file'}, {'entity': 'Kubelet', 'description': 'Agent that runs on each node in a cluster', 'category': 'software'}, {'entity': 'kubectl', 'description': 'Command-line tool for interacting with Kubernetes', 'category': 'command'}, {'entity': 'Pod spec', 'description': 'Configuration file for a pod', 'category': 'file'}, {'entity': 'Container definition', 'description': 'Section in the pod spec that defines a container', 'category': 'software'}, {'entity': 'terminationMessagePath', 'description': 'Field in the container definition for specifying termination message path', 'category': 'field'}, {'entity': '/var/termination-reason', 'description': 'Custom file for termination message', 'category': 'file'}, {'entity': 'CrashLoopBackOff', 'description': 'Pod status indicating a crash loop', 'category': 'software'}, {'entity': 'Error', 'description': 'Reason for container termination', 'category': 'error'}, {'entity': 'Exit Code', 'description': 'Code returned by the container when it exits', 'category': 'field'}]","[{'source_entity': '""Container definition""', 'description': 'defines', 'destination_entity': '""Pod spec""'}, {'source_entity': '""Exit Code""', 'description': 'indicates', 'destination_entity': '""Error""'}, {'source_entity': '""/dev/termination-log""', 'description': 'contains', 'destination_entity': '""terminationMessagePath""'}, {'source_entity': '""terminationMessagePath""', 'description': 'specifies', 'destination_entity': '""Kubelet""'}, {'source_entity': '""Pod""', 'description': 'is managed by', 'destination_entity': '""Kubernetes""'}, {'source_entity': '""Error""', 'description': 'causes', 'destination_entity': '""CrashLoopBackOff""'}, {'source_entity': '""kubectl""', 'description': 'interacts with', 'destination_entity': '""Pod""'}, {'source_entity': '""Kubelet""', 'description': 'monitors', 'destination_entity': '""Pod spec""'}, {'source_entity': '""/var/termination-reason""', 'description': 'stores', 'destination_entity': '""terminationMessagePath""'}]","['[\n  {\n    ""source"": ""Container definition"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""defines"",\n    ""summary_er"": ""A container definition specifies the configuration for a pod, including the image to use and any necessary environment variables.""\n  }\n]', '[\n  {\n    ""source"": ""Exit Code"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""indicates"",\n    ""summary_er"": ""The exit code of a process indicates its termination status, which can be used to determine if a pod has completed successfully or encountered an error.""\n  }\n]', '[\n  {\n    ""source"": ""/dev/termination-log"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""contains"",\n    ""summary_er"": ""/dev/termination-log contains termination message path for pod""\n  }\n]', '[\n  {\n    ""source"": ""terminationMessagePath"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""specifies"",\n    ""summary_er"": ""The termination message path in a Kubelet specifies the destination pod.""\n  }\n]', '[\n  {\n    ""source"": ""Pod"",\n    ""destination"": ""Kubernetes"",\n    ""relation_description"": ""is managed by"",\n    ""summary_er"": ""A Pod in Kubernetes is a logical host for one or more application containers, with its own IP address and resources.""\n  }\n]', '[\n  {\n    ""source"": ""Pod"",\n    ""destination"": ""Error"",\n    ""relation_description"": ""causes"",\n    ""summary_er"": ""A Pod\'s CrashLoopBackOff error causes it to continuously restart, indicating a problem with its container or configuration.""\n  },\n  {\n    ""source"": ""CrashLoopBackOff"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""causes"",\n    ""summary_er"": ""A CrashLoopBackOff event in Kubernetes causes a Pod to repeatedly restart due to failed container startup.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""interacts with"",\n    ""summary_er"": ""Kubectl, a command-line tool, interacts with pods to manage and deploy containerized applications.""\n  }\n]', '[\n  {\n    ""source"": ""Kubelet"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""monitors"",\n    ""summary_er"": ""The Kubelet monitors Pod specs to ensure proper container execution and resource management.""\n  }\n]', '[\n  {\n    ""source"": ""/var/termination-reason"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""stores"",\n    ""summary_er"": ""/var/termination-reason stores information about the reason for a pod\'s termination.""\n  },\n  {\n    ""source"": ""terminationMessagePath"",\n    ""destination"": ""/var/termination-reason"",\n    ""relation_description"": ""stores"",\n    ""summary_er"": ""terminationMessagePath stores the message that describes why a pod terminated, in /var/termination-reason.""\n  }\n]']","In Kubernetes, you can make triage easier by having a container write a termination message to a specific file before exiting. This message is then shown in the output of kubectl describe pod without needing to inspect container logs. The default path for this message is /dev/termination-log but can be overridden with the terminationMessagePath field in the container definition. An example of this is provided, where a busybox container writes a message to /var/termination-reason and dies immediately, causing the pod's status to show CrashLoopBackOff, which can then be seen using kubectl describe.","[{'highlight': 'You can use one other Kubernetes feature that makes it possible to show the reason why a container terminated in the pod’s status.'}, {'highlight': 'The process needs to write the message to /dev/termination-log, but it can be changed by setting the terminationMessagePath field in the container definition in the pod spec.'}, {'highlight': 'When running this pod, you’ll soon see the pod’s status shown as CrashLoopBackOff. If you then use kubectl describe, you can see why the container died,'}, {'highlight': 'The container will write the message to the file just before exiting.'}, {'highlight': 'You’re overriding the default path of the termination message file.'}]"
443,532,0,[],"500
CHAPTER 17
Best practices for developing apps
    Ready:              False
    Restart Count:      6
As you can see, the “I’ve had enough” message the process wrote to the file /var/ter-
mination-reason is shown in the container’s Last State section. Note that this mecha-
nism isn’t limited only to containers that crash. It can also be used in pods that run a
completable task and terminate successfully (you’ll find an example in the file termi-
nation-message-success.yaml). 
 This mechanism is great for terminated containers, but you’ll probably agree that
a similar mechanism would also be useful for showing app-specific status messages of
running, not only terminated, containers. Kubernetes currently doesn’t provide any
such functionality and I’m not aware of any plans to introduce it.
NOTE
If the container doesn’t write the message to any file, you can set the
terminationMessagePolicy field to FallbackToLogsOnError. In that case,
the last few lines of the container’s log are used as its termination message
(but only when the container terminates unsuccessfully).
17.4.6 Handling application logs
While we’re on the subject of application logging, let’s reiterate that apps should write
to the standard output instead of files. This makes it easy to view logs with the kubectl
logs command. 
TIP
If a container crashes and is replaced with a new one, you’ll see the new
container’s log. To see the previous container’s logs, use the --previous
option with kubectl logs.
If the application logs to a file instead of the standard output, you can display the log
file using an alternative approach: 
$ kubectl exec <pod> cat <logfile>
This executes the cat command inside the container and streams the logs back to
kubectl, which prints them out in your terminal. 
COPYING LOG AND OTHER FILES TO AND FROM A CONTAINER
You can also copy the log file to your local machine using the kubectl cp command,
which we haven’t looked at yet. It allows you to copy files from and into a container. For
example, if a pod called foo-pod and its single container contains a file at /var/log/
foo.log, you can transfer it to your local machine with the following command:
$ kubectl cp foo-pod:/var/log/foo.log foo.log
To copy a file from your local machine into the pod, specify the pod’s name in the sec-
ond argument:
$ kubectl cp localfile foo-pod:/etc/remotefile
 
",[],"[{'entity': 'container', 'description': 'a process running within a pod', 'category': 'process'}, {'entity': 'pod', 'description': 'the basic execution unit in Kubernetes', 'category': 'application'}, {'entity': 'kubectl logs command', 'description': 'a command to view container logs', 'category': 'command'}, {'entity': 'terminationMessagePolicy field', 'description': 'a field that determines how a termination message is handled', 'category': 'field'}, {'entity': 'FallbackToLogsOnError policy', 'description': ""a policy that uses the last few lines of a container's log as its termination message when it terminates unsuccessfully"", 'category': 'policy'}, {'entity': 'standard output', 'description': 'the default output stream for an application', 'category': 'output'}, {'entity': 'kubernetes logs command', 'description': 'a command to view container logs', 'category': 'command'}, {'entity': 'kubectl exec command', 'description': 'a command to execute a command inside a container', 'category': 'command'}, {'entity': 'cat command', 'description': 'a command to display the contents of a file', 'category': 'command'}, {'entity': 'kubectl cp command', 'description': 'a command to copy files from and into a container', 'category': 'command'}, {'entity': 'file', 'description': 'a collection of data stored on disk', 'category': 'data storage'}, {'entity': 'log file', 'description': 'a file containing application logs', 'category': 'data storage'}, {'entity': 'termination message', 'description': 'a message written to a file by a container when it terminates', 'category': 'message'}, {'entity': 'application logging', 'description': 'the process of writing logs from an application', 'category': 'logging'}]","[{'source_entity': '""kubectl logs command""', 'description': 'executes', 'destination_entity': '""termination message""'}, {'source_entity': '""kubectl logs command""', 'description': 'displays', 'destination_entity': '""standard output""'}, {'source_entity': '""container""', 'description': 'generates', 'destination_entity': '""log file""'}, {'source_entity': '""kubectl exec command""', 'description': 'executes', 'destination_entity': '""application logging""'}, {'source_entity': '""terminationMessagePolicy field""', 'description': 'configures', 'destination_entity': '""container""'}, {'source_entity': '""cat command""', 'description': 'reads', 'destination_entity': '""file""'}, {'source_entity': '""kubectl cp command""', 'description': 'copies', 'destination_entity': '""file""'}, {'source_entity': '""kubectl logs command""', 'description': 'displays', 'destination_entity': '""log file""'}, {'source_entity': '""FallbackToLogsOnError policy""', 'description': 'configures', 'destination_entity': '""container""'}, {'source_entity': '""kubectl exec command""', 'description': 'executes', 'destination_entity': '""pod""'}]","['[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""executes"",\n    ""summary_er"": ""The Kubernetes command-line tool (kubectl) executes a command on a pod, which can be used to retrieve logs or other information from the container.""\n  },\n  {\n    ""source"": ""logs"",\n    ""destination"": ""termination message"",\n    ""relation_description"": ""command"",\n    ""summary_er"": ""A termination message is generated when a container or pod is terminated due to an error or other issue, which can be retrieved using the logs command in Kubernetes.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""displays standard output"",\n    ""summary_er"": ""The kubectl logs command displays the standard output of a pod, allowing users to view log messages and other output generated by the container.""\n  }\n]', '[\n  {\n    ""source"": ""container"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""generates"",\n    ""summary_er"": ""A container generates a log file for its corresponding pod, providing insights into its execution and any errors encountered.""\n  },\n  {\n    ""source"": ""log file"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""related to"",\n    ""summary_er"": ""A log file is related to the pod it belongs to, containing information about the container\'s activity and any issues that may have occurred.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""executes"",\n    ""summary_er"": ""The Kubernetes command-line tool (kubectl) executes commands on a running container within a pod, allowing for direct interaction with the application.""\n  },\n  {\n    ""source"": ""application"",\n    ""destination"": ""logging"",\n    ""relation_description"": ""related to"",\n    ""summary_er"": ""Application logging refers to the process of recording and monitoring events, errors, or other significant occurrences within an application, providing valuable insights for debugging and optimization.""\n  }\n]', '[\n  {\n    ""source"": ""terminationMessagePolicy field"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""configures"",\n    ""summary_er"": ""The termination message policy field configures how a container in a pod handles termination messages.""\n  }\n]', '[\n  {\n    ""source"": ""cat command"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""reads"",\n    ""summary_er"": ""The cat command in Linux reads the contents of a file, displaying its contents on the terminal.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl cp command"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""copies"",\n    ""summary_er"": ""The kubectl cp command copies files from a local machine to a pod in a Kubernetes cluster.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl logs command"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""displays log file"",\n    ""summary_er"": ""The kubectl logs command displays the log file of a pod, allowing users to view and analyze the system\'s activity.""\n  }\n]', '[\n  {\n    ""source"": ""FallbackToLogsOnError policy"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""configures"",\n    ""summary_er"": ""The FallbackToLogsOnError policy configures a pod to fall back to logging on error.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""executes"",\n    ""summary_er"": ""The Kubernetes command-line tool (kubectl) executes a command directly on a pod, allowing for interactive shell sessions or executing commands within the container.""\n  }\n]']","The chapter discusses best practices for developing apps in Kubernetes. It highlights the importance of writing app-specific status messages to a file or using the standard output, which can be easily viewed with the `kubectl logs` command. If an application crashes and is replaced, the new container's log is displayed, but using the `--previous` option shows the previous container's logs. The chapter also covers copying files from/to containers using `kubectl cp`, including logging files.","[{'highlight': 'Kubernetes currently doesn’t provide any functionality for showing app-specific status messages of running containers.'}, {'highlight': 'If the container doesn’t write the message to any file, you can set the terminationMessagePolicy field to FallbackToLogsOnError.'}, {'highlight': 'Apps should write to the standard output instead of files for easy log viewing with kubectl logs command.'}, {'highlight': 'You can copy the log file to your local machine using the kubectl cp command, which allows you to copy files from and into a container.'}, {'highlight': 'To see the previous container’s logs, use the --previous option with kubectl logs command if a container crashes and is replaced with a new one.'}]"
444,533,0,[],"501
Making your apps easy to run and manage in Kubernetes
This copies the file localfile to /etc/remotefile inside the pod’s container. If the pod has
more than one container, you specify the container using the -c containerName option.
USING CENTRALIZED LOGGING
In a production system, you’ll want to use a centralized, cluster-wide logging solution,
so all your logs are collected and (permanently) stored in a central location. This
allows you to examine historical logs and analyze trends. Without such a system, a
pod’s logs are only available while the pod exists. As soon as it’s deleted, its logs are
deleted also. 
 Kubernetes by itself doesn’t provide any kind of centralized logging. The compo-
nents necessary for providing a centralized storage and analysis of all the container
logs must be provided by additional components, which usually run as regular pods in
the cluster. 
 Deploying centralized logging solutions is easy. All you need to do is deploy a few
YAML/JSON manifests and you’re good to go. On Google Kubernetes Engine, it’s
even easier. Check the Enable Stackdriver Logging checkbox when setting up the clus-
ter. Setting up centralized logging on an on-premises Kubernetes cluster is beyond the
scope of this book, but I’ll give you a quick overview of how it’s usually done.
 You may have already heard of the ELK stack composed of ElasticSearch, Logstash,
and Kibana. A slightly modified variation is the EFK stack, where Logstash is replaced
with FluentD. 
 When using the EFK stack for centralized logging, each Kubernetes cluster node
runs a FluentD agent (usually as a pod deployed through a DaemonSet), which is
responsible for gathering the logs from the containers, tagging them with pod-specific
information, and delivering them to ElasticSearch, which stores them persistently.
ElasticSearch is also deployed as a pod somewhere in the cluster. The logs can then be
viewed and analyzed in a web browser through Kibana, which is a web tool for visualiz-
ing ElasticSearch data. It also usually runs as a pod and is exposed through a Service.
The three components of the EFK stack are shown in the following figure.
NOTE
In the next chapter, you’ll learn about Helm charts. You can use charts
created by the Kubernetes community to deploy the EFK stack instead of cre-
ating your own YAML manifests. 
Node 1
Container logs
Kibana
Web
browser
FluentD
Node 2
Container logs
FluentD
Node 3
Container logs
FluentD
ElasticSearch
Figure 17.10
Centralized logging with FluentD, ElasticSearch, and Kibana
 
",[],"[{'entity': 'Kubernetes', 'description': 'container orchestration system', 'category': 'software'}, {'entity': 'pod', 'description': 'lightweight and portable container', 'category': 'application'}, {'entity': 'container', 'description': 'isolated process with its own resources', 'category': 'process'}, {'entity': 'file', 'description': 'data stored on disk', 'category': 'hardware'}, {'entity': 'logging', 'description': 'process of recording events and errors', 'category': 'application'}, {'entity': 'centralized logging', 'description': 'system for collecting and storing logs in a central location', 'category': 'software'}, {'entity': 'cluster-wide logging', 'description': 'system for collecting and storing logs across multiple nodes', 'category': 'software'}, {'entity': 'YAML/JSON manifests', 'description': 'configuration files used to deploy applications', 'category': 'software'}, {'entity': 'Google Kubernetes Engine', 'description': 'managed container orchestration service', 'category': 'cloud service'}, {'entity': 'ELK stack', 'description': 'collection of tools for logging and analytics', 'category': 'software'}, {'entity': 'EFK stack', 'description': 'modified version of ELK stack using FluentD instead of Logstash', 'category': 'software'}, {'entity': 'FluentD', 'description': 'logging agent that collects and processes logs', 'category': 'application'}, {'entity': 'ElasticSearch', 'description': 'search and analytics engine for log data', 'category': 'database'}, {'entity': 'Kibana', 'description': 'web interface for visualizing ElasticSearch data', 'category': 'application'}, {'entity': 'DaemonSet', 'description': 'deployment strategy that ensures a pod is running on every node', 'category': 'software'}, {'entity': 'Service', 'description': ' abstraction layer for accessing applications', 'category': 'networking'}]","[{'source_entity': '""Google Kubernetes Engine""', 'description': 'provides', 'destination_entity': '""cluster-wide logging""'}, {'source_entity': '""DaemonSet""', 'description': 'implements', 'destination_entity': '""FluentD""'}, {'source_entity': '""FluentD""', 'description': 'collects', 'destination_entity': '""logging""'}, {'source_entity': '""Service""', 'description': 'exposes', 'destination_entity': '""logging""'}, {'source_entity': '""centralized logging""', 'description': 'integrates', 'destination_entity': '""container""'}, {'source_entity': '""ElasticSearch""', 'description': 'stores', 'destination_entity': '""logging""'}, {'source_entity': '""ELK stack""', 'description': 'includes', 'destination_entity': '""ElasticSearch""'}, {'source_entity': '""EFK stack""', 'description': 'extends', 'destination_entity': '""ELK stack""'}, {'source_entity': '""Kibana""', 'description': 'visualizes', 'destination_entity': '""logging""'}, {'source_entity': '""Kubernetes""', 'description': 'manages', 'destination_entity': '""pod""'}, {'source_entity': '""YAML/JSON manifests""', 'description': 'defines', 'destination_entity': '""pod""'}]","['[\n  {\n    ""source"": ""Google Kubernetes Engine"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""provides"",\n    ""summary_er"": ""Google Kubernetes Engine provides a managed environment for running pods, enabling cluster-wide logging and other features.""\n  }\n]', '[\n  {\n    ""source"": ""DaemonSet"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""implements"",\n    ""summary_er"": ""A DaemonSet ensures a specified number of replicas (pods) are running at any given time, in this case implementing FluentD.""\n  }\n]', '[\n  {\n    ""source"": ""FluentD"",\n    ""destination"": ""pod logging"",\n    ""relation_description"": ""collects"",\n    ""summary_er"": ""FluentD collects logs from various sources and stores them in a pod named \'logging\'.""\n  }\n]', '[\n  {\n    ""source"": ""Service"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""exposes"",\n    ""summary_er"": ""A Service in Kubernetes exposes a Pod\'s port to the outside world, allowing external traffic to reach the Pod.""\n  },\n  {\n    ""source"": ""Service"",\n    ""destination"": ""logging"",\n    ""relation_description"": ""related to"",\n    ""summary_er"": ""Logging is related to Services in Kubernetes as it helps monitor and troubleshoot Service-related issues.""\n  }\n]', '[\n  {\n    ""source"": ""centralized logging"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""integrates"",\n    ""summary_er"": ""Centralized logging integrates with pods to collect and manage logs from containerized applications.""\n  }\n]', '[\n  {\n    ""source"": ""ElasticSearch"",\n    ""destination"": ""pod logging"",\n    ""relation_description"": ""stores"",\n    ""summary_er"": ""ElasticSearch stores logs in a pod named logging.""\n  }\n]', '[\n  {\n    ""source"": ""ELK stack"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""includes"",\n    ""summary_er"": ""The ELK stack includes a pod that runs Elasticsearch, a popular search and analytics engine.""\n  },\n  {\n    ""source"": ""ElasticSearch"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""runs on"",\n    ""summary_er"": ""Elasticsearch is a search and analytics engine that can run as a standalone pod in a Kubernetes cluster.""\n  }\n]', '[\n  {\n    ""source"": ""EFK stack"",\n    ""destination"": ""ELK stack"",\n    ""relation_description"": ""extends"",\n    ""summary_er"": ""The EFK stack extends the ELK stack by adding Docker and Kubernetes capabilities.""\n  }\n]', '[\n  {\n    ""source"": ""Kibana"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""visualizes"",\n    ""summary_er"": ""Kibana visualizes data from logging pods, providing real-time insights and analytics.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""manages"",\n    ""summary_er"": ""Kubernetes manages pods by orchestrating their creation, scaling, and termination to ensure efficient resource utilization.""\n  }\n]', '[\n  {\n    ""source"": ""YAML/JSON manifests"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""defines"",\n    ""summary_er"": ""YAML/JSON manifests define the configuration for a Kubernetes pod, specifying its properties and behavior.""\n  }\n]']","Kubernetes provides no centralized logging by itself, requiring additional components to store and analyze container logs. Deploying a centralized logging solution like the EFK stack (FluentD, ElasticSearch, Kibana) is easy through YAML/JSON manifests or Helm charts, allowing for historical log examination and trend analysis.","[{'highlight': 'Kubernetes by itself doesn’t provide any kind of centralized logging.'}, {'highlight': 'Deploying centralized logging solutions is easy. All you need to do is deploy a few YAML/JSON manifests and you’re good to go.'}, {'highlight': 'When using the EFK stack for centralized logging, each Kubernetes cluster node runs a FluentD agent (usually as a pod deployed through a DaemonSet), which is responsible for gathering the logs from the containers,'}, {'highlight': 'ElasticSearch is also deployed as a pod somewhere in the cluster. The logs can then be viewed and analyzed in a web browser through Kibana, which is a web tool for visualizing ElasticSearch data.'}, {'highlight': 'You may have already heard of the ELK stack composed of ElasticSearch, Logstash, and Kibana. A slightly modified variation is the EFK stack, where Logstash is replaced with FluentD.'}]"
445,534,0,[],"502
CHAPTER 17
Best practices for developing apps
HANDLING MULTI-LINE LOG STATEMENTS
The FluentD agent stores each line of the log file as an entry in the ElasticSearch
data store. There’s one problem with that. Log statements spanning multiple lines,
such as exception stack traces in Java, appear as separate entries in the centralized
logging system. 
 To solve this problem, you can have the apps output JSON instead of plain text.
This way, a multiline log statement can be stored and shown in Kibana as a single
entry. But that makes viewing logs with kubectl logs much less human-friendly. 
 The solution may be to keep outputting human-readable logs to standard output,
while writing JSON logs to a file and having them processed by FluentD. This requires
configuring the node-level FluentD agent appropriately or adding a logging sidecar
container to every pod. 
17.5
Best practices for development and testing
We’ve talked about what to be mindful of when developing apps, but we haven’t
talked about the development and testing workflows that will help you streamline
those processes. I don’t want to go into too much detail here, because everyone needs
to find what works best for them, but here are a few starting points.
17.5.1 Running apps outside of Kubernetes during development
When you’re developing an app that will run in a production Kubernetes cluster, does
that mean you also need to run it in Kubernetes during development? Not really. Hav-
ing to build the app after each minor change, then build the container image, push it
to a registry, and then re-deploy the pods would make development slow and painful.
Luckily, you don’t need to go through all that trouble.
 You can always develop and run apps on your local machine, the way you’re used
to. After all, an app running in Kubernetes is a regular (although isolated) process
running on one of the cluster nodes. If the app depends on certain features the
Kubernetes environment provides, you can easily replicate that environment on your
development machine.
 I’m not even talking about running the app in a container. Most of the time, you
don’t need that—you can usually run the app directly from your IDE. 
CONNECTING TO BACKEND SERVICES
In production, if the app connects to a backend Service and uses the BACKEND_SERVICE
_HOST and BACKEND_SERVICE_PORT environment variables to find the Service’s coordi-
nates, you can obviously set those environment variables on your local machine manu-
ally and point them to the backend Service, regardless of if it’s running outside or
inside a Kubernetes cluster. If it’s running inside Kubernetes, you can always (at least
temporarily) make the Service accessible externally by changing it to a NodePort or a
LoadBalancer-type Service. 
 
",[],"[{'entity': 'FluentD', 'description': 'The FluentD agent stores each line of the log file as an entry in the ElasticSearch data store.', 'category': 'software'}, {'entity': 'ElasticSearch', 'description': 'A centralized logging system where FluentD stores log entries.', 'category': 'database'}, {'entity': 'Kibana', 'description': 'A tool for viewing logs stored in ElasticSearch.', 'category': 'application'}, {'entity': 'kubectl', 'description': 'A command-line tool for managing Kubernetes resources, including viewing logs.', 'category': 'software'}, {'entity': 'JSON', 'description': 'A data format used to store log statements instead of plain text.', 'category': 'data format'}, {'entity': 'Java', 'description': 'A programming language where exception stack traces can span multiple lines.', 'category': 'programming language'}, {'entity': 'Kubernetes', 'description': 'An environment for running containerized applications, including development and production clusters.', 'category': 'container orchestration system'}, {'entity': 'node-level FluentD agent', 'description': 'A configuration of the FluentD agent on a node to process JSON logs.', 'category': 'software'}, {'entity': 'logging sidecar container', 'description': 'A container that processes JSON logs and writes them to a file.', 'category': 'container'}, {'entity': 'IDE', 'description': 'An Integrated Development Environment where developers can run apps directly without containers.', 'category': 'application'}, {'entity': 'BACKEND_SERVICE_HOST', 'description': 'An environment variable used to find the coordinates of a backend Service.', 'category': 'environment variable'}, {'entity': 'BACKEND_SERVICE_PORT', 'description': 'An environment variable used to find the port number of a backend Service.', 'category': 'environment variable'}]","[{'source_entity': '""BACKEND_SERVICE_HOST""', 'description': 'is used to configure', 'destination_entity': '""FluentD""'}, {'source_entity': '""FluentD""', 'description': 'collects and processes logs from', 'destination_entity': '""logging sidecar container""'}, {'source_entity': '""kubectl""', 'description': 'is used to manage and deploy', 'destination_entity': '""Kubernetes""'}, {'source_entity': '""node-level FluentD agent""', 'description': 'sends logs to', 'destination_entity': '""ElasticSearch""'}, {'source_entity': '""IDE""', 'description': 'is used for development and debugging of', 'destination_entity': '""Java""'}, {'source_entity': '""Kubernetes""', 'description': 'uses', 'destination_entity': '""BACKEND_SERVICE_PORT""'}, {'source_entity': '""Kibana""', 'description': 'is used to visualize and analyze data from', 'destination_entity': '""ElasticSearch""'}, {'source_entity': '""JSON""', 'description': 'is used as a format for logging and configuration of', 'destination_entity': '""FluentD""'}]","['[{\n    ""source"": ""BACKEND_SERVICE_HOST"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is used to configure"",\n    ""summary_er"": ""The BACKEND_SERVICE_HOST is used to configure a pod.""\n}]', '[\n  {\n    ""source"": ""FluentD"",\n    ""destination"": ""logging sidecar container"",\n    ""relation_description"": ""collects and processes logs from"",\n    ""summary_er"": ""FluentD collects logs from logging sidecar container to process them.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is used to manage and deploy"",\n    ""summary_er"": ""kubectl is a command-line tool for managing Kubernetes resources, including deploying and managing pods.""\n  }\n]', '[\n  {\n    ""source"": ""node-level FluentD agent"",\n    ""destination"": ""ElasticSearch"",\n    ""relation_description"": ""sends logs to"",\n    ""summary_er"": ""The node-level FluentD agent forwards log data to the ElasticSearch pod for storage and analysis.""\n  }\n]', '[\n  {\n    ""source"": ""IDE"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""is used for development and debugging of"",\n    ""summary_er"": ""An Integrated Development Environment (IDE) is used to develop, debug, and deploy software applications in a containerized environment, specifically within a Kubernetes Pod.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""uses"",\n    ""summary_er"": ""Kubernetes manages and orchestrates containerized applications, including pods, which are the basic execution unit in a Kubernetes cluster.""\n  }\n]', '[\n  {\n    ""source"": ""Kibana"",\n    ""destination"": ""ElasticSearch"",\n    ""relation_description"": ""is used to visualize and analyze data from"",\n    ""summary_er"": ""Kibana leverages ElasticSearch for data visualization and analysis, utilizing its capabilities to provide insights.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""is used to manage"",\n    ""summary_er"": ""Kubernetes is used to manage and orchestrate containers, including pods, which are the basic execution unit of a containerized application.""\n  },\n  {\n    ""source"": ""Docker"",\n    ""destination"": ""Container"",\n    ""relation_description"": ""is used to package"",\n    ""summary_er"": ""Docker is used to package applications and their dependencies into a single container that can be run on any system with Docker installed.""\n  },\n  {\n    ""source"": ""JSON"",\n    ""destination"": ""FluentD"",\n    ""relation_description"": ""is used as a format for logging and configuration of"",\n    ""summary_er"": ""JSON is used as a format for logging and configuration of FluentD, which collects, processes, and forwards log data to various destinations.""\n  },\n  {\n    ""source"": ""Machine Learning"",\n    ""destination"": ""Generative AI"",\n    ""relation_description"": ""is related to"",\n    ""summary_er"": ""Machine learning is related to generative AI, which uses algorithms to generate new content, such as images or text, that resembles existing data.""\n  },\n  {\n    ""source"": ""Natural Language Understanding"",\n    ""destination"": ""Computer Vision"",\n    ""relation_description"": ""is complementary to"",\n    ""summary_er"": ""Natural language understanding is complementary to computer vision, which enables machines to interpret and understand visual information from images and videos.""\n  }\n]']","The chapter discusses best practices for developing apps in Kubernetes. It highlights the importance of handling multi-line log statements by outputting JSON logs instead of plain text, which can be stored and shown as a single entry in Kibana. The solution is to keep outputting human-readable logs while writing JSON logs to a file and having them processed by FluentD. Additionally, it suggests running apps outside of Kubernetes during development on local machines or IDEs without the need for containerization. It also advises connecting to backend services manually or temporarily making them accessible externally using NodePort or LoadBalancer-type Services.","[{'highlight': 'The FluentD agent stores each line of the log file as an entry in the ElasticSearch data store, but this can cause issues with multiline log statements.'}, {'highlight': 'Developing and running apps on a local machine during development is a viable option, allowing for faster iteration without the need to build and deploy containers.'}, {'highlight': 'Connecting to backend services in production can be achieved by setting environment variables on a local machine or temporarily exposing a Service externally via NodePort or LoadBalancer-type Service.'}, {'highlight': 'Outputting JSON logs instead of plain text can help solve the issue with multiline log statements, but this may make viewing logs with kubectl logs less human-friendly.'}, {'highlight': 'Configuring the node-level FluentD agent or adding a logging sidecar container to every pod is required to process JSON logs and keep outputting human-readable logs to standard output.'}]"
446,535,0,[],"503
Best practices for development and testing
CONNECTING TO THE API SERVER
Similarly, if your app requires access to the Kubernetes API server when running
inside a Kubernetes cluster, it can easily talk to the API server from outside the cluster
during development. If it uses the ServiceAccount’s token to authenticate itself, you
can always copy the ServiceAccount’s Secret’s files to your local machine with kubectl
cp. The API server doesn’t care if the client accessing it is inside or outside the cluster. 
 If the app uses an ambassador container like the one described in chapter 8, you
don’t even need those Secret files. Run kubectl proxy on your local machine, run
your app locally, and it should be ready to talk to your local kubectl proxy (as long as
it and the ambassador container bind the proxy to the same port).
 In this case, you’ll need to make sure the user account your local kubectl is using
has the same privileges as the ServiceAccount the app will run under.
RUNNING INSIDE A CONTAINER EVEN DURING DEVELOPMENT
When during development you absolutely have to run the app in a container for what-
ever reason, there is a way of avoiding having to build the container image every time.
Instead of baking the binaries into the image, you can always mount your local filesys-
tem into the container through Docker volumes, for example. This way, after you
build a new version of the app’s binaries, all you need to do is restart the container (or
not even that, if hot-redeploy is supported). No need to rebuild the image.
17.5.2 Using Minikube in development
As you can see, nothing forces you to run your app inside Kubernetes during develop-
ment. But you may do that anyway to see how the app behaves in a true Kubernetes
environment.
 You may have used Minikube to run examples in this book. Although a Minikube
cluster runs only a single worker node, it’s nevertheless a valuable method of trying
out your app in Kubernetes (and, of course, developing all the resource manifests that
make up your complete application). Minikube doesn’t offer everything that a proper
multi-node Kubernetes cluster usually provides, but in most cases, that doesn’t matter.
MOUNTING LOCAL FILES INTO THE MINIKUBE VM AND THEN INTO YOUR CONTAINERS
When you’re developing with Minikube and you’d like to try out every change to your
app in your Kubernetes cluster, you can mount your local filesystem into the Minikube
VM using the minikube mount command and then mount it into your containers
through a hostPath volume. You’ll find additional instructions on how to do that
in the Minikube documentation at https:/
/github.com/kubernetes/minikube/tree/
master/docs.
USING THE DOCKER DAEMON INSIDE THE MINIKUBE VM TO BUILD YOUR IMAGES
If you’re developing your app with Minikube and planning to build the container
image after every change, you can use the Docker daemon inside the Minikube VM to
do the building, instead of having to build the image through your local Docker dae-
mon, push it to a registry, and then have it pulled by the daemon in the VM. To use
 
",[],"[{'entity': 'Kubernetes', 'description': 'Container orchestration system', 'category': 'software'}, {'entity': 'API server', 'description': 'Server that provides access to Kubernetes resources', 'category': 'software'}, {'entity': 'ServiceAccount', 'description': 'Account used for authentication and authorization in Kubernetes', 'category': 'software'}, {'entity': 'kubectl', 'description': 'Command-line tool for interacting with Kubernetes clusters', 'category': 'software'}, {'entity': 'Docker', 'description': 'Containerization platform', 'category': 'software'}, {'entity': 'container', 'description': 'Lightweight and portable operating system environment', 'category': 'hardware'}, {'entity': 'Minikube', 'description': 'Tool for running a single-node Kubernetes cluster on a local machine', 'category': 'software'}, {'entity': 'cluster', 'description': 'Group of machines that work together to provide computing resources', 'category': 'hardware'}, {'entity': 'node', 'description': 'Individual machine in a cluster', 'category': 'hardware'}, {'entity': 'worker node', 'description': 'Machine in a cluster that runs containers and performs tasks', 'category': 'hardware'}, {'entity': 'resource manifests', 'description': 'Files that define the resources needed by an application', 'category': 'software'}, {'entity': 'Docker daemon', 'description': 'Service that manages Docker containers on a machine', 'category': 'software'}, {'entity': 'registry', 'description': 'Centralized location for storing and managing container images', 'category': 'hardware'}, {'entity': 'hostPath volume', 'description': ""Type of volume that allows access to the host machine's filesystem from within a container"", 'category': 'hardware'}, {'entity': 'Docker volumes', 'description': 'Feature that allows mounting local filesystems into containers', 'category': 'software'}]","[{'source_entity': '""cluster""', 'description': 'manages', 'destination_entity': '""registry""'}, {'source_entity': '""registry""', 'description': 'stores', 'destination_entity': '""Docker volumes""'}, {'source_entity': '""container""', 'description': 'uses', 'destination_entity': '""Docker volumes""'}, {'source_entity': '""kubectl""', 'description': 'interacts with', 'destination_entity': '""cluster""'}, {'source_entity': '""node""', 'description': 'hosts', 'destination_entity': '""container""'}, {'source_entity': '""Docker daemon""', 'description': 'runs', 'destination_entity': '""container""'}, {'source_entity': '""worker node""', 'description': 'executes', 'destination_entity': '""resource manifests""'}, {'source_entity': '""hostPath volume""', 'description': 'provides', 'destination_entity': '""Docker volumes""'}, {'source_entity': '""kubectl""', 'description': 'deploys', 'destination_entity': '""container""'}, {'source_entity': '""API server""', 'description': 'communicates with', 'destination_entity': '""ServiceAccount""'}, {'source_entity': '""ServiceAccount""', 'description': 'authenticates', 'destination_entity': '""API server""'}]","['[\n  {\n    ""source"": ""cluster"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""manages"",\n    ""summary_er"": ""A cluster manages a collection of pods, ensuring they run smoothly and efficiently.""\n  },\n  {\n    ""source"": ""registry"",\n    ""destination"": ""image"",\n    ""relation_description"": ""stores"",\n    ""summary_er"": ""A registry stores images, making them easily accessible for deployment in containers.""\n  }\n]', '[\n  {\n    ""source"": ""registry"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""stores"",\n    ""summary_er"": ""A Docker registry stores container images, which can then be deployed to a pod for execution.""\n  },\n  {\n    ""source"": ""Docker volumes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""mounts"",\n    ""summary_er"": ""A Docker volume mounts a directory from the host machine into a pod, providing persistent storage.""\n  }\n]', '[{""source"": ""container"", ""destination"": ""pod"", ""relation_description"": ""uses"", ""summary_er"": ""A container uses a pod to run its application.""}, {""source"": ""Docker volumes"", ""destination"": ""container"", ""relation_description"": ""mounts"", ""summary_er"": ""A Docker volume mounts a file system to a container for persistent storage.""}]', '[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""interacts with"",\n    ""summary_er"": ""\\""Kubectl\\"" manages and controls containerized applications and services, interacting directly with \\""pods\\"", which are the basic execution unit in a Kubernetes cluster.""\n  },\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""cluster"",\n    ""relation_description"": ""manages"",\n    ""summary_er"": ""\\""Kubectl\\"" is used to manage and control containerized applications and services within a \\""cluster\\"", which is a group of machines that work together as one system.""\n  }\n]', '[\n  {\n    ""source"": ""node"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""hosts"",\n    ""summary_er"": ""A node in a Kubernetes cluster hosts one or more pods, which are the basic execution units of a containerized application.""\n  },\n  {\n    ""source"": ""pod"",\n    ""destination"": ""container"",\n    ""relation_description"": ""container"",\n    ""summary_er"": ""A pod in a Kubernetes cluster contains one or more containers, which are isolated processes that run an application.""\n  }\n]', '[\n  {\n    ""source"": ""Docker daemon"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""runs"",\n    ""summary_er"": ""The Docker daemon executes containers within a pod, utilizing its resources for efficient operation.""\n  }\n]', '[\n  {\n    ""source"": ""worker node"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""executes"",\n    ""summary_er"": ""A worker node in a Kubernetes cluster executes a pod, which is a containerized application that can run multiple containers.""\n  }\n]', '[\n  {\n    ""source"": ""hostPath volume"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""provides"",\n    ""summary_er"": ""A hostPath volume provides a directory on the host machine to a pod for data storage.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""deploys"",\n    ""summary_er"": ""Kubernetes command-line tool (kubectl) deploys a containerized application to a pod, managing its lifecycle and resources.""\n  }\n]', '[\n  {\n    ""source"": ""API server"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""communicates with"",\n    ""summary_er"": ""The API server interacts with a pod to provide services and manage network traffic.""\n  },\n  {\n    ""source"": ""ServiceAccount"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""communicates with"",\n    ""summary_er"": ""A ServiceAccount authenticates and authorizes interactions between pods, enabling secure communication and resource access.""\n  }\n]', '[\n  {\n    ""source"": ""ServiceAccount"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""authenticates"",\n    ""summary_er"": ""A ServiceAccount authenticates a Pod by verifying its identity, ensuring only authorized access to cluster resources.""\n  }\n]']","When developing an app that requires access to the Kubernetes API server, you can easily talk to the API server from outside the cluster during development using ServiceAccount's token or ambassador container. Alternatively, you can run your app inside a Kubernetes cluster using Minikube, which provides a single worker node but is valuable for trying out your app in Kubernetes and developing resource manifests. You can also mount local files into the Minikube VM and containers using hostPath volume or use the Docker daemon inside the Minikube VM to build container images.","[{'highlight': ""You can easily talk to the Kubernetes API server from outside the cluster during development using the ServiceAccount's token or an ambassador container.""}, {'highlight': 'When developing with Minikube, you can mount your local filesystem into the Minikube VM and then into your containers through a hostPath volume.'}, {'highlight': ""You don't need to rebuild the Docker image every time during development; instead, you can mount your local filesytem into the container using Docker volumes.""}, {'highlight': 'Minikube is a valuable method of trying out your app in Kubernetes and developing resource manifests for your complete application.'}, {'highlight': 'You can use the Docker daemon inside the Minikube VM to build your images instead of building through your local Docker daemon and pushing to a registry.'}]"
447,536,0,[],"504
CHAPTER 17
Best practices for developing apps
Minikube’s Docker daemon, all you need to do is point your DOCKER_HOST environ-
ment variable to it. Luckily, this is much easier than it sounds. All you need to do is
run the following command on your local machine:
$ eval $(minikube docker-env)
This will set all the required environment variables for you. You then build your
images the same way as if the Docker daemon was running on your local machine.
After you build the image, you don’t need to push it anywhere, because it’s already
stored locally on the Minikube VM, which means new pods can use the image immedi-
ately. If your pods are already running, you either need to delete them or kill their
containers so they’re restarted.
BUILDING IMAGES LOCALLY AND COPYING THEM OVER TO THE MINIKUBE VM DIRECTLY
If you can’t use the daemon inside the VM to build the images, you still have a way to
avoid having to push the image to a registry and have the Kubelet running in the
Minikube VM pull it. If you build the image on your local machine, you can copy it
over to the Minikube VM with the following command:
$ docker save <image> | (eval $(minikube docker-env) && docker load)
As before, the image is immediately ready to be used in a pod. But make sure the
imagePullPolicy in your pod spec isn’t set to Always, because that would cause the
image to be pulled from the external registry again and you’d lose the changes you’ve
copied over.
COMBINING MINIKUBE WITH A PROPER KUBERNETES CLUSTER
You have virtually no limit when developing apps with Minikube. You can even com-
bine a Minikube cluster with a proper Kubernetes cluster. I sometimes run my devel-
opment workloads in my local Minikube cluster and have them talk to my other
workloads that are deployed in a remote multi-node Kubernetes cluster thousands of
miles away. 
 Once I’m finished with development, I can move my local workloads to the remote
cluster with no modifications and with absolutely no problems thanks to how Kuber-
netes abstracts away the underlying infrastructure from the app.
17.5.3 Versioning and auto-deploying resource manifests
Because Kubernetes uses a declarative model, you never have to figure out the current
state of your deployed resources and issue imperative commands to bring that state to
what you desire. All you need to do is tell Kubernetes your desired state and it will take
all the necessary actions to reconcile the cluster state with the desired state.
 You can store your collection of resource manifests in a Version Control System,
enabling you to perform code reviews, keep an audit trail, and roll back changes
whenever necessary. After each commit, you can run the kubectl apply command to
have your changes reflected in your deployed resources. 
 
",[],"[{'entity': 'Minikube', 'description': 'A tool for running Kubernetes locally on a machine.', 'category': 'software'}, {'entity': 'DOCKER_HOST', 'description': 'An environment variable that points to the Docker daemon.', 'category': 'environment variable'}, {'entity': 'minikube docker-env', 'description': 'A command that sets up the environment variables for Minikube.', 'category': 'command'}, {'entity': 'Docker daemon', 'description': 'The process that runs on a machine to manage Docker containers.', 'category': 'process'}, {'entity': 'imagePullPolicy', 'description': 'A field in a pod spec that determines how the image is pulled from a registry.', 'category': 'field'}, {'entity': 'Always', 'description': 'A value for the imagePullPolicy field that causes the image to be pulled from an external registry.', 'category': 'value'}, {'entity': 'Kubelet', 'description': 'The component of Kubernetes that runs on a machine and manages pods.', 'category': 'component'}, {'entity': 'kubectl apply', 'description': 'A command that applies changes to deployed resources in a Kubernetes cluster.', 'category': 'command'}, {'entity': 'Version Control System', 'description': 'A system for storing and managing code, such as Git or SVN.', 'category': 'system'}, {'entity': 'resource manifests', 'description': 'The files that define the desired state of resources in a Kubernetes cluster.', 'category': 'file'}, {'entity': 'Kubernetes', 'description': 'An open-source container orchestration system.', 'category': 'software'}]","[{'source_entity': '""kubectl apply""', 'description': 'applies configuration to', 'destination_entity': '""Version Control System""'}, {'source_entity': '""kubectl apply""', 'description': 'configures', 'destination_entity': '""Kubernetes""'}, {'source_entity': '""minikube docker-env""', 'description': 'sets environment variables for', 'destination_entity': '""Docker daemon""'}, {'source_entity': '""minikube docker-env""', 'description': 'configures', 'destination_entity': '""Kubernetes""'}, {'source_entity': '""Kubelet""', 'description': 'pulls images from', 'destination_entity': '""Docker daemon""'}, {'source_entity': '""imagePullPolicy""', 'description': 'specifies policy for pulling', 'destination_entity': '""images""'}, {'source_entity': '""DOCKER_HOST""', 'description': 'sets host for', 'destination_entity': '""Docker daemon""'}, {'source_entity': '""minikube docker-env""', 'description': 'generates environment variables for', 'destination_entity': '""resource manifests""'}]","['[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""applies configuration to"",\n    ""summary_er"": ""Kubectl applies configuration to a running pod, ensuring it meets the desired state.""\n  },\n  {\n    ""source"": ""Version Control System"",\n    ""destination"": null,\n    ""relation_description"": null,\n    ""summary_er"": ""A Version Control System is a software tool that helps manage changes to code over time, tracking revisions and collaborations among developers.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl apply"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""configures"",\n    ""summary_er"": ""The \'kubectl apply\' command configures a Kubernetes pod by applying configuration settings to it.""\n  }\n]', '[\n  {\n    ""source"": ""minikube"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""sets environment variables for"",\n    ""summary_er"": ""Minikube sets environment variables to interact with a pod in a Kubernetes cluster.""\n  },\n  {\n    ""source"": ""Docker daemon"",\n    ""destination"": ""container"",\n    ""relation_description"": ""runs and manages"",\n    ""summary_er"": ""The Docker daemon runs and manages containers, providing a runtime environment for applications.""\n  }\n]', '[\n  {\n    ""source"": ""minikube"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""configures"",\n    ""summary_er"": ""Minikube configures a Kubernetes pod to run Docker containers.""\n  }\n]', '[\n  {\n    ""source"": ""Kubelet"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""pulls images from"",\n    ""summary_er"": ""Kubelet pulls container images from Docker daemon to deploy on a pod.""\n  },\n  {\n    ""source"": ""Docker daemon"",\n    ""destination"": ""Kubelet"",\n    ""relation_description"": ""pushes images to"",\n    ""summary_er"": ""Docker daemon pushes container images to Kubelet for deployment on a pod.""\n  }\n]', '[\n  {\n    ""source"": ""imagePullPolicy"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""specifies policy for pulling"",\n    ""summary_er"": ""Image pull policy determines how a container image is pulled from a registry, affecting pod deployment and security.""\n  },\n  {\n    ""source"": ""images"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""container images"",\n    ""summary_er"": ""Images are used to create containers for pods, providing the necessary software and dependencies for execution.""\n  }\n]', '[\n  {\n    ""source"": ""DOCKER_HOST"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""sets host for"",\n    ""summary_er"": ""The Docker Host variable sets the host for a pod, allowing it to communicate with the Docker daemon.""\n  }\n]', '[\n  {\n    ""source"": ""minikube"",\n    ""destination"": ""docker-env"",\n    ""relation_description"": ""generates environment variables for"",\n    ""summary_er"": ""Minikube generates Docker environment variables to interact with a running Minikube cluster.""\n  },\n  {\n    ""source"": ""resource manifests"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""related to"",\n    ""summary_er"": ""Resource manifests are related to pods in Kubernetes, defining the resources required by each pod.""\n  }\n]']","Minikube allows developers to build apps locally without pushing images to a registry. Environment variables can be set using ""eval $(minikube docker-env)"" to use the Minikube VM's Docker daemon. Images can also be built locally and copied over to the Minikube VM, or combined with a proper Kubernetes cluster for development and deployment.","[{'highlight': ""To use Minikube's Docker daemon, set the DOCKER_HOST environment variable by running $ eval $(minikube docker-env) on your local machine.""}, {'highlight': 'You can build images locally and copy them over to the Minikube VM using the command $ docker save <image> | (eval $(minikube docker-env) && docker load).'}, {'highlight': 'When combining Minikube with a proper Kubernetes cluster, you can develop apps on your local Minikube cluster and deploy them to a remote multi-node cluster without modifications.'}, {'highlight': 'Kubernetes uses a declarative model, so you only need to tell it your desired state, and it will take the necessary actions to reconcile the cluster state with the desired state using kubectl apply command.'}, {'highlight': 'You can store resource manifests in a Version Control System, enabling code reviews, audit trails, and rolling back changes whenever necessary.'}]"
448,537,0,[],"505
Best practices for development and testing
 If you run an agent that periodically (or when it detects a new commit) checks out
your manifests from the Version Control System (VCS), and then runs the apply com-
mand, you can manage your running apps simply by committing changes to the VCS
without having to manually talk to the Kubernetes API server. Luckily, the people at
Box (which coincidently was used to host this book’s manuscript and other materials)
developed and released a tool called kube-applier, which does exactly what I described.
You’ll find the tool’s source code at https:/
/github.com/box/kube-applier.
 You can use multiple branches to deploy the manifests to a development, QA, stag-
ing, and production cluster (or in different namespaces in the same cluster).
17.5.4 Introducing Ksonnet as an alternative to writing YAML/JSON 
manifests
We’ve seen a number of YAML manifests throughout the book. I don’t see writing
YAML as too big of a problem, especially once you learn how to use kubectl explain
to see the available options, but some people do. 
 Just as I was finalizing the manuscript for this book, a new tool called Ksonnet was
announced. It’s a library built on top of Jsonnet, which is a data templating language
for building JSON data structures. Instead of writing the complete JSON by hand, it
lets you define parameterized JSON fragments, give them a name, and then build a
full JSON manifest by referencing those fragments by name, instead of repeating the
same JSON code in multiple locations—much like you use functions or methods in a
programming language. 
 Ksonnet defines the fragments you’d find in Kubernetes resource manifests, allow-
ing you to quickly build a complete Kubernetes resource JSON manifest with much
less code. The following listing shows an example.
local k = import ""../ksonnet-lib/ksonnet.beta.1/k.libsonnet"";
local container = k.core.v1.container;
local deployment = k.apps.v1beta1.deployment;
local kubiaContainer =                              
  container.default(""kubia"", ""luksa/kubia:v1"") +    
  container.helpers.namedPort(""http"", 8080);        
deployment.default(""kubia"", kubiaContainer) +    
deployment.mixin.spec.replicas(3)                
The kubia.ksonnet file shown in the listing is converted to a full JSON Deployment
manifest when you run the following command:
$ jsonnet kubia.ksonnet
Listing 17.10
The kubia Deployment written with Ksonnet: kubia.ksonnet
This defines a container called kubia, 
which uses the luksa/kubia:v1 image 
and includes a port called http.
This will be expanded into a full 
Deployment resource. The kubiaContainer 
defined here will be included in the 
Deployment’s pod template.
 
",[],"[{'entity': 'Kubernetes API server', 'description': 'The central component that manages and controls the cluster', 'category': 'application'}, {'entity': 'kubectl', 'description': 'A command-line tool for interacting with Kubernetes clusters', 'category': 'command'}, {'entity': 'Ksonnet', 'description': 'A library built on top of Jsonnet for building JSON data structures', 'category': 'framework'}, {'entity': 'Jsonnet', 'description': 'A data templating language for building JSON data structures', 'category': 'language'}, {'entity': 'Kube-applier', 'description': 'A tool that automates the deployment of Kubernetes manifests', 'category': 'application'}, {'entity': 'Version Control System (VCS)', 'description': 'A system for managing and tracking changes to code', 'category': 'software'}, {'entity': 'YAML/JSON manifests', 'description': 'Files that define the configuration of Kubernetes resources', 'category': 'database'}, {'entity': 'Kubernetes resource manifests', 'description': 'Files that define the configuration of Kubernetes resources', 'category': 'database'}, {'entity': 'container', 'description': 'A lightweight and standalone execution environment', 'category': 'process'}, {'entity': 'deployment', 'description': 'A mechanism for managing and scaling the deployment of applications', 'category': 'application'}, {'entity': 'replicas', 'description': 'The number of instances of a pod that should be running at any given time', 'category': 'process'}, {'entity': 'port', 'description': 'A mechanism for exposing services to the outside world', 'category': 'network'}]","[{'source_entity': '""Kubernetes resource manifests""', 'description': 'are used to define Kubernetes resources', 'destination_entity': '""deployment""'}, {'source_entity': '""Ksonnet""', 'description': 'is a tool for managing Kubernetes resource manifests', 'destination_entity': '""Kubernetes resource manifests""'}, {'source_entity': '""replicas""', 'description': 'are used to define the number of replicas for a deployment', 'destination_entity': '""deployment""'}, {'source_entity': '""container""', 'description': 'is a component of a pod in Kubernetes', 'destination_entity': '""pod""'}, {'source_entity': '""Version Control System (VCS)""', 'description': 'is used to manage changes to Kubernetes resource manifests', 'destination_entity': '""Kubernetes resource manifests""'}, {'source_entity': '""Jsonnet""', 'description': 'is a configuration language for defining Kubernetes resources', 'destination_entity': '""Kubernetes resource manifests""'}, {'source_entity': '""kubectl""', 'description': 'is a command-line tool used to interact with the Kubernetes API server', 'destination_entity': '""Kubernetes API server""'}, {'source_entity': '""port""', 'description': 'is an attribute of a container in Kubernetes', 'destination_entity': '""container""'}, {'source_entity': '""Kube-applier""', 'description': 'is a tool used to apply Kubernetes resource manifests', 'destination_entity': '""Kubernetes resource manifests""'}, {'source_entity': '""Kubernetes API server""', 'description': 'is responsible for managing and exposing the Kubernetes API', 'destination_entity': '""kubectl""'}, {'source_entity': '""YAML/JSON manifests""', 'description': 'are used to define Kubernetes resources in a human-readable format', 'destination_entity': '""Kubernetes resource manifests""'}]","['[\n  {\n    ""source"": ""Kubernetes resource manifests"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""are used to define Kubernetes resources"",\n    ""summary_er"": ""Manifests are used to create and manage pods in a Kubernetes cluster.""\n  }\n]', '[\n  {\n    ""source"": ""Ksonnet"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is managed by"",\n    ""summary_er"": ""Ksonnet manages Kubernetes resource manifests for pods.""\n  },\n  {\n    ""source"": ""Ksonnet"",\n    ""destination"": ""Kubernetes resource manifests"",\n    ""relation_description"": ""manages"",\n    ""summary_er"": ""Ksonnet manages Kubernetes resource manifests for efficient deployment.""\n  }\n]', '[\n  {\n    ""source"": ""Replica"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""are used to define the number of replicas for a deployment"",\n    ""summary_er"": ""Replicas determine the number of pod instances in a deployment, ensuring scalability and high availability.""\n  }\n]', '[{""source"": ""container"", ""destination"": ""pod"", ""relation_description"": ""is a component of a pod in Kubernetes"", ""summary_er"": ""A container is a fundamental unit of deployment in Kubernetes, encapsulating an application and its dependencies within a single entity.""}]', '[\n  {\n    ""source"": ""Version Control System (VCS)"",\n    ""destination"": ""Kubernetes resource manifests"",\n    ""relation_description"": ""is used to manage changes to"",\n    ""summary_er"": ""A VCS is used to track and manage changes to Kubernetes resource manifests, ensuring version control and consistency.""\n  },\n  {\n    ""source"": ""Kubernetes resource manifests"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""managed by"",\n    ""summary_er"": ""Kubernetes resource manifests are managed by a pod, which is responsible for executing the manifests and managing the application lifecycle.""\n  }\n]', '[\n  {\n    ""source"": ""Jsonnet"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is a configuration language for defining Kubernetes resources"",\n    ""summary_er"": ""Jsonnet is used to define Kubernetes resources, which are then deployed as pods.""\n  },\n  {\n    ""source"": ""Kubernetes resource manifests"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""defines the configuration of a pod"",\n    ""summary_er"": ""Kubernetes resource manifests define the configuration of a pod, which is then deployed and managed by Kubernetes.""\n  }\n]', '[\n  {\n    ""source"": ""kubectl"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is a command-line tool used to interact with the Kubernetes API server"",\n    ""summary_er"": ""kubectl is used to interact with pods through the Kubernetes API server.""\n  },\n  {\n    ""source"": ""Kubernetes API server"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""manages and controls the lifecycle of a pod"",\n    ""summary_er"": ""The Kubernetes API server manages and controls the lifecycle of a pod.""\n  }\n]', '[\n  {\n    ""source"": ""port"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is an attribute of a container in Kubernetes"",\n    ""summary_er"": ""A port is a network endpoint that allows communication between containers and pods in a Kubernetes cluster.""\n  },\n  {\n    ""source"": ""container"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""a pod can have one or more containers"",\n    ""summary_er"": ""A container is a lightweight process that runs within a pod, sharing resources and dependencies.""\n  }\n]', '[\n  {\n    ""source"": ""Kube-applier"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is a tool used to apply Kubernetes resource manifests"",\n    ""summary_er"": ""Kube-applier applies Kubernetes manifests to create pods.""\n  },\n  {\n    ""source"": ""Kubernetes resource manifests"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""are applied by Kube-applier to create"",\n    ""summary_er"": ""Manifests are used to create pods in Kubernetes.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes API server"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is responsible for managing and exposing the Kubernetes API"",\n    ""summary_er"": ""The Kubernetes API server manages and exposes the Kubernetes API to pods, enabling them to interact with the cluster.""\n  }\n]', '[\n  {\n    ""source"": ""YAML/JSON manifests"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""are used to define Kubernetes resources in a human-readable format"",\n    ""summary_er"": ""YAML/JSON manifests are used to define pod configurations in a human-readable format.""\n  },\n  {\n    ""source"": ""Kubernetes resource manifests"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""define Kubernetes resources"",\n    ""summary_er"": ""Kubernetes resource manifests define pod configurations.""\n  }\n]']","The document discusses best practices for development and testing in Kubernetes, including using tools like kube-applier to manage running apps through version control systems. It also introduces Ksonnet as an alternative to writing YAML/JSON manifests, allowing users to define parameterized JSON fragments and build full manifests with much less code.","[{'highlight': 'You can manage your running apps simply by committing changes to the VCS without having to manually talk to the Kubernetes API server.'}, {'highlight': 'Ksonnet is a library built on top of Jsonnet, which allows you to define parameterized JSON fragments and build a full JSON manifest by referencing those fragments by name.'}, {'highlight': ""Ksonnet defines the fragments you'd find in Kubernetes resource manifests, allowing you to quickly build a complete Kubernetes resource JSON manifest with much less code.""}, {'highlight': 'You can use multiple branches to deploy the manifests to a development, QA, staging, and production cluster (or in different namespaces in the same cluster).'}, {'highlight': 'Ksonnet allows you to define a container called kubia, which uses the luksa/kubia:v1 image and includes a port called http, and this will be expanded into a full Deployment resource.'}]"
449,538,0,[],"506
CHAPTER 17
Best practices for developing apps
The power of Ksonnet and Jsonnet becomes apparent when you realize you can define
your own higher-level fragments and make all your manifests consistent and duplica-
tion-free. You’ll find more information on using and installing Ksonnet and Jsonnet at
https:/
/github.com/ksonnet/ksonnet-lib.
17.5.5 Employing Continuous Integration and Continuous Delivery 
(CI/CD)
We’ve touched on automating the deployment of Kubernetes resources two sections
back, but you may want to set up a complete CI/CD pipeline for building your appli-
cation binaries, container images, and resource manifests and then deploying them in
one or more Kubernetes clusters.
 You’ll find many online resources talking about this subject. Here, I’d like to point
you specifically to the Fabric8 project (http:/
/fabric8.io), which is an integrated
development platform for Kubernetes. It includes Jenkins, the well-known, open-
source automation system, and various other tools to deliver a full CI/CD pipeline
for DevOps-style development, deployment, and management of microservices on
Kubernetes.
 If you’d like to build your own solution, I also suggest looking at one of the Google
Cloud Platform’s online labs that talks about this subject. It’s available at https:/
/
github.com/GoogleCloudPlatform/continuous-deployment-on-kubernetes.
17.6
Summary
Hopefully, the information in this chapter has given you an even deeper insight into
how Kubernetes works and will help you build apps that feel right at home when
deployed to a Kubernetes cluster. The aim of this chapter was to
Show you how all the resources covered in this book come together to repre-
sent a typical application running in Kubernetes.
Make you think about the difference between apps that are rarely moved
between machines and apps running as pods, which are relocated much more
frequently.
Help you understand that your multi-component apps (or microservices, if you
will) shouldn’t rely on a specific start-up order.
Introduce init containers, which can be used to initialize a pod or delay the start
of the pod’s main containers until a precondition is met.
Teach you about container lifecycle hooks and when to use them.
Gain a deeper insight into the consequences of the distributed nature of
Kubernetes components and its eventual consistency model.
Learn how to make your apps shut down properly without breaking client
connections.
 
",[],"[{'entity': 'Ksonnet', 'description': 'A templating engine for Kubernetes manifests', 'category': 'software'}, {'entity': 'Jsonnet', 'description': 'A templating language for Kubernetes manifests', 'category': 'software'}, {'entity': 'Kubernetes', 'description': 'An open-source container orchestration system', 'category': 'software'}, {'entity': 'CI/CD', 'description': 'Continuous Integration and Continuous Delivery pipeline', 'category': 'process'}, {'entity': 'Fabric8 project', 'description': 'An integrated development platform for Kubernetes', 'category': 'application'}, {'entity': 'Jenkins', 'description': 'An open-source automation system', 'category': 'software'}, {'entity': 'Google Cloud Platform', 'description': 'A cloud computing platform', 'category': 'hardware'}, {'entity': 'init containers', 'description': 'Containers used to initialize a pod or delay the start of main containers', 'category': 'software'}, {'entity': 'container lifecycle hooks', 'description': 'Hooks that can be used to customize container startup and shutdown', 'category': 'software'}, {'entity': 'pods', 'description': 'The basic execution unit in Kubernetes', 'category': 'software'}, {'entity': 'manifests', 'description': 'Files that define the desired state of a Kubernetes resource', 'category': 'software'}]","[{'source_entity': '""init containers""', 'description': 'are used to perform setup tasks before the main container starts', 'destination_entity': '""container lifecycle hooks""'}, {'source_entity': '""Jenkins""', 'description': 'is a popular CI/CD tool that integrates with Kubernetes', 'destination_entity': '""Kubernetes""'}, {'source_entity': '""Ksonnet""', 'description': 'is a templating engine for Kubernetes manifests', 'destination_entity': '""manifests""'}, {'source_entity': '""Fabric8 project""', 'description': 'provides a set of tools and libraries for building Kubernetes applications', 'destination_entity': '""Kubernetes""'}, {'source_entity': '""Jsonnet""', 'description': 'is a templating language used to generate Kubernetes manifests', 'destination_entity': '""manifests""'}, {'source_entity': '""CI/CD""', 'description': 'integrates with Jenkins and other tools to automate deployment processes', 'destination_entity': '""Jenkins""'}, {'source_entity': '""pods""', 'description': 'are the basic execution unit in Kubernetes, can be managed by init containers', 'destination_entity': '""init containers""'}, {'source_entity': '""Kubernetes""', 'description': 'is an open-source container orchestration system that integrates with CI/CD tools', 'destination_entity': '""CI/CD""'}, {'source_entity': '""Google Cloud Platform""', 'description': 'provides a managed Kubernetes service for deploying and managing applications', 'destination_entity': '""Kubernetes""'}]","['[\n  {\n    ""source"": ""init containers"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""are used to perform setup tasks before the main container starts"",\n    ""summary_er"": ""Init containers run setup tasks before the main container, ensuring a stable environment for execution.""\n  },\n  {\n    ""source"": ""container lifecycle hooks"",\n    ""destination"": ""pod"",\n    ""relation_description"": """",\n    ""summary_er"": ""Container lifecycle hooks manage pod lifecycle events, such as startup and shutdown.""\n  }\n]', '[\n  {\n    ""source"": ""Jenkins"",\n    ""destination"": ""Kubernetes"",\n    ""relation_description"": ""integrates with"",\n    ""summary_er"": ""Jenkins is a CI/CD tool that integrates with Kubernetes to automate software builds and deployments.""\n  }\n]', '[\n  {\n    ""source"": ""Ksonnet"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""templating engine"",\n    ""summary_er"": ""Ksonnet is a templating engine for Kubernetes manifests, generating pod configurations.""\n  },\n  {\n    ""source"": ""Ksonnet"",\n    ""destination"": ""manifests"",\n    ""relation_description"": ""generates"",\n    ""summary_er"": ""Ksonnet generates manifests for Kubernetes deployments, streamlining configuration management.""\n  }\n]', '[\n  {\n    ""source"": ""Fabric8 project"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""provides a set of tools and libraries for building Kubernetes applications"",\n    ""summary_er"": ""The Fabric8 project enables the creation of Kubernetes applications by providing essential tools and libraries.""\n  }\n]', '[\n  {\n    ""source"": ""Jsonnet"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is a templating language used to generate"",\n    ""summary_er"": ""Jsonnet generates Kubernetes manifests for pods.""\n  }\n]', '[\n  {\n    ""source"": ""CI/CD"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""integrates with Jenkins and other tools to automate deployment processes"",\n    ""summary_er"": ""CI/CD automates deployment processes by integrating with Jenkins and other tools, ensuring smooth and efficient pod management.""\n  }\n]', '[\n  {\n    ""source"": ""pods"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""are the basic execution unit in Kubernetes, can be managed by init containers"",\n    ""summary_er"": ""Pods are the basic units of deployment and scaling in Kubernetes, with init containers managing their lifecycle.""\n  },\n  {\n    ""source"": ""init containers"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""can be managed by"",\n    ""summary_er"": ""Init containers run to completion before the main container starts, providing a way to manage pod initialization.""\n  }\n]', '[\n  {\n    ""source"": ""Kubernetes"",\n    ""destination"": ""pod"",\n    ""relation_description"": ""is an open-source container orchestration system that integrates with CI/CD tools"",\n    ""summary_er"": ""Kubernetes manages and orchestrates containers, including pods, to ensure efficient resource utilization.""\n  },\n  {\n    ""source"": ""CI/CD"",\n    ""destination"": ""tools"",\n    ""relation_description"": ""integrates with"",\n    ""summary_er"": ""CI/CD integrates with various tools to automate testing, building, and deployment of software applications.""\n  }\n]', '[\n  {\n    ""source"": ""Google Cloud Platform"",\n    ""destination"": ""Pod"",\n    ""relation_description"": ""provides a managed Kubernetes service for deploying and managing applications"",\n    ""summary_er"": ""Google Cloud Platform provides a managed Kubernetes service to deploy and manage pods, enabling efficient application management.""\n  }\n]']","The chapter emphasizes the importance of using Ksonnet and Jsonnet for consistent manifests, employing Continuous Integration and Continuous Delivery (CI/CD) pipelines with tools like Fabric8 or Google Cloud Platform's online labs to automate deployment, and understanding Kubernetes' distributed nature and eventual consistency model. It also highlights the need for apps to shut down properly without breaking client connections.","[{'highlight': 'The power of Ksonnet and Jsonnet becomes apparent when you can define your own higher-level fragments and make all your manifests consistent and duplication-free.'}, {'highlight': 'Employing Continuous Integration and Continuous Delivery (CI/CD) to build application binaries, container images, and resource manifests and then deploying them in one or more Kubernetes clusters.'}, {'highlight': 'The Fabric8 project is an integrated development platform for Kubernetes that includes Jenkins and various other tools to deliver a full CI/CD pipeline for DevOps-style development, deployment, and management of microservices on Kubernetes.'}, {'highlight': ""Init containers can be used to initialize a pod or delay the start of the pod's main containers until a precondition is met.""}, {'highlight': 'Container lifecycle hooks can be used to make your apps shut down properly without breaking client connections, and understand the consequences of the distributed nature of Kubernetes components and its eventual consistency model.'}]"
