{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c0eab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import ollama\n",
    "import chromadb\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "#rag_test_input_path='/home/matrix4284/MY_GEN_AI_PROJECTS/RAG/GraphRAG/graphrag-local-ollama/ragtest/input/'+file_name\n",
    "import os\n",
    "# importing shutil module\n",
    "import shutil\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "#embeddings = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.output_parsers import XMLOutputParser\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30e7e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_enrichment_output_dir = '../pdf_enrichment/pdf_enriched_output/'  \n",
    "pdf_enrichment_output_file = 'pdf_enriched_content_dict_phase5_extract_highligts_478_final.pickle'\n",
    "\n",
    "with open(pdf_enrichment_output_dir+pdf_enrichment_output_file, 'rb') as handle:\n",
    "    document_dict_deserialized = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7072524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubernetes in Action\n",
      " www.allitebooks.com\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "pdf_file=\"../pdf_parsing/pdf_source/Kubernetes_in_Action.pdf\"\n",
    "pdf_loader = PyPDFLoader(pdf_file)\n",
    "pages = pdf_loader.load_and_split()\n",
    "print(pages[2].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9925e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_doc_summary=[]\n",
    "doc_len=len(document_dict_deserialized)\n",
    "for i in range(0,doc_len):\n",
    "    summary=document_dict_deserialized[i][\"text\"]\n",
    "    full_doc_summary.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd132e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'68\\nCHAPTER 3\\nPods: running containers in Kubernetes\\n(multiple copies of the same component will be deployed) and multiple versions or\\nreleases (stable, beta, canary, and so on) will run concurrently. This can lead to hun-\\ndreds of pods in the system. Without a mechanism for organizing them, you end up\\nwith a big, incomprehensible mess, such as the one shown in figure 3.6. The figure\\nshows pods of multiple microservices, with several running multiple replicas, and others\\nrunning different releases of the same microservice.\\nIt’s evident you need a way of organizing them into smaller groups based on arbitrary\\ncriteria, so every developer and system administrator dealing with your system can eas-\\nily see which pod is which. And you’ll want to operate on every pod belonging to a cer-\\ntain group with a single action instead of having to perform the action for each pod\\nindividually. \\n Organizing pods and all other Kubernetes objects is done through labels.\\n3.3.1\\nIntroducing labels\\nLabels are a simple, yet incredibly powerful, Kubernetes feature for organizing not\\nonly pods, but all other Kubernetes resources. A label is an arbitrary key-value pair you\\nattach to a resource, which is then utilized when selecting resources using label selectors\\n(resources are filtered based on whether they include the label specified in the selec-\\ntor). A resource can have more than one label, as long as the keys of those labels are\\nunique within that resource. You usually attach labels to resources when you create\\nthem, but you can also add additional labels or even modify the values of existing\\nlabels later without having to recreate the resource. \\nUI pod\\nUI pod\\nUI pod\\nAccount\\nService\\npod\\nProduct\\nCatalog\\npod\\nProduct\\nCatalog\\npod\\nProduct\\nCatalog\\npod\\nShopping\\nCart\\npod\\nShopping\\nCart\\npod\\nOrder\\nService\\npod\\nUI pod\\nUI pod\\nProduct\\nCatalog\\npod\\nProduct\\nCatalog\\npod\\nOrder\\nService\\npod\\nAccount\\nService\\npod\\nProduct\\nCatalog\\npod\\nProduct\\nCatalog\\npod\\nOrder\\nService\\npod\\nFigure 3.6\\nUncategorized pods in a microservices architecture\\n \\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_doc_summary[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3df369d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM Model for Prompt Tuning\n",
    "model_name=\"llama3.1\"\n",
    "llm = ChatOllama(base_url=\"http://192.168.50.100:11434\",model=model_name,temperature=0.15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f295595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "\n",
    "\n",
    "question_prompt_template = \"\"\"\n",
    "                  Please provide a summary of the following text.\n",
    "                  TEXT: {text}\n",
    "                  SUMMARY:\n",
    "                  \"\"\"\n",
    "\n",
    "question_prompt = PromptTemplate(\n",
    "    template=question_prompt_template, input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "refine_prompt_template = \"\"\"\n",
    "              Write a concise summary of the following text delimited by triple backquotes.\n",
    "              Return your response in bullet points which covers the key points of the text.\n",
    "              ```{text}```\n",
    "              BULLET POINT SUMMARY:\n",
    "              \"\"\"\n",
    "\n",
    "refine_prompt = PromptTemplate(\n",
    "    template=refine_prompt_template, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab4d9ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=question_prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df1020a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-09-13 03:14:03'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "start_time=strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8807595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-13 03:15:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matrix4284/mambaforge-pypy3/envs/search_agent_poc/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "start_time=strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(start_time)\n",
    "refine_outputs = refine_chain({\"input_documents\": pages})\n",
    "end_time=strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60f8c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24b7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search_agent_poc",
   "language": "python",
   "name": "search_agent_poc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
